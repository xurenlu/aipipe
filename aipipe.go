package main

import (
	"bufio"
	"bytes"
	"context"
	"crypto/sha256"
	"crypto/tls"
	"encoding/json"
	"flag"
	"fmt"
	"html/template"
	"io"
	"log"
	"math/rand"
	"net/http"
	"net/smtp"
	"net/url"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"runtime"
	"sort"
	"strconv"
	"strings"
	"sync"
	"syscall"
	"time"
	"unsafe"

	"github.com/BurntSushi/toml"
	"github.com/fsnotify/fsnotify"
	"gopkg.in/yaml.v3"
)

// é‚®ä»¶é…ç½®
type EmailConfig struct {
	Enabled   bool     `json:"enabled"`
	Provider  string   `json:"provider"`   // "smtp" æˆ– "resend"
	Host      string   `json:"host"`       // SMTPæœåŠ¡å™¨åœ°å€
	Port      int      `json:"port"`       // SMTPç«¯å£
	Username  string   `json:"username"`   // ç”¨æˆ·å
	Password  string   `json:"password"`   // å¯†ç æˆ–APIå¯†é’¥
	FromEmail string   `json:"from_email"` // å‘ä»¶äººé‚®ç®±
	ToEmails  []string `json:"to_emails"`  // æ”¶ä»¶äººé‚®ç®±åˆ—è¡¨
}

// Webhooké…ç½®
type WebhookConfig struct {
	Enabled bool   `json:"enabled"`
	URL     string `json:"url"`
	Secret  string `json:"secret,omitempty"` // å¯é€‰çš„ç­¾åå¯†é’¥
}

// é€šçŸ¥å™¨é…ç½®
type NotifierConfig struct {
	Email          EmailConfig     `json:"email"`
	DingTalk       WebhookConfig   `json:"dingtalk"`
	WeChat         WebhookConfig   `json:"wechat"`
	Feishu         WebhookConfig   `json:"feishu"`
	Slack          WebhookConfig   `json:"slack"`
	CustomWebhooks []WebhookConfig `json:"custom_webhooks,omitempty"`
}

// AI æœåŠ¡é…ç½®
type AIService struct {
	Name     string `json:"name"`     // æœåŠ¡åç§°
	Endpoint string `json:"endpoint"` // API ç«¯ç‚¹
	Token    string `json:"token"`    // API Token
	Model    string `json:"model"`    // æ¨¡å‹åç§°
	Priority int    `json:"priority"` // ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
	Enabled  bool   `json:"enabled"`  // æ˜¯å¦å¯ç”¨
}

// AI æœåŠ¡ç®¡ç†å™¨
type AIServiceManager struct {
	services    []AIService
	current     int
	fallback    bool
	rateLimiter map[string]time.Time
	mutex       sync.RWMutex
}

// è¿‡æ»¤è§„åˆ™
type FilterRule struct {
	ID          string `json:"id"`          // è§„åˆ™ID
	Name        string `json:"name"`        // è§„åˆ™åç§°
	Pattern     string `json:"pattern"`     // æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
	Action      string `json:"action"`      // åŠ¨ä½œ: filter, alert, ignore, highlight
	Priority    int    `json:"priority"`    // ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
	Description string `json:"description"` // è§„åˆ™æè¿°
	Enabled     bool   `json:"enabled"`     // æ˜¯å¦å¯ç”¨
	Category    string `json:"category"`    // è§„åˆ™åˆ†ç±»
	Color       string `json:"color"`       // é«˜äº®é¢œè‰²
}

// è§„åˆ™å¼•æ“
type RuleEngine struct {
	rules         []FilterRule
	compiledRules map[string]*regexp.Regexp
	cache         map[string]bool
	mutex         sync.RWMutex
	stats         RuleStats
}

// è§„åˆ™ç»Ÿè®¡
type RuleStats struct {
	TotalRules       int `json:"total_rules"`
	EnabledRules     int `json:"enabled_rules"`
	CacheHits        int `json:"cache_hits"`
	CacheMisses      int `json:"cache_misses"`
	FilteredLines    int `json:"filtered_lines"`
	AlertedLines     int `json:"alerted_lines"`
	IgnoredLines     int `json:"ignored_lines"`
	HighlightedLines int `json:"highlighted_lines"`
}

// è¿‡æ»¤ç»“æœ
type FilterResult struct {
	Action          string `json:"action"`           // åŠ¨ä½œ
	RuleID          string `json:"rule_id"`          // åŒ¹é…çš„è§„åˆ™ID
	RuleName        string `json:"rule_name"`        // è§„åˆ™åç§°
	Category        string `json:"category"`         // åˆ†ç±»
	Color           string `json:"color"`            // é¢œè‰²
	ShouldProcess   bool   `json:"should_process"`   // æ˜¯å¦åº”è¯¥å¤„ç†
	ShouldAlert     bool   `json:"should_alert"`     // æ˜¯å¦åº”è¯¥å‘Šè­¦
	ShouldIgnore    bool   `json:"should_ignore"`    // æ˜¯å¦åº”è¯¥å¿½ç•¥
	ShouldHighlight bool   `json:"should_highlight"` // æ˜¯å¦åº”è¯¥é«˜äº®
}

// ç¼“å­˜é¡¹
type CacheItem struct {
	Key         string      `json:"key"`
	Value       interface{} `json:"value"`
	ExpiresAt   time.Time   `json:"expires_at"`
	CreatedAt   time.Time   `json:"created_at"`
	AccessCount int         `json:"access_count"`
	Size        int64       `json:"size"`
}

// AIåˆ†æç»“æœç¼“å­˜
type AIAnalysisCache struct {
	LogHash    string    `json:"log_hash"`
	Result     string    `json:"result"`
	Confidence float64   `json:"confidence"`
	Model      string    `json:"model"`
	CreatedAt  time.Time `json:"created_at"`
	ExpiresAt  time.Time `json:"expires_at"`
}

// è§„åˆ™åŒ¹é…ç¼“å­˜
type RuleMatchCache struct {
	LogHash   string        `json:"log_hash"`
	RuleID    string        `json:"rule_id"`
	Matched   bool          `json:"matched"`
	Result    *FilterResult `json:"result"`
	CreatedAt time.Time     `json:"created_at"`
	ExpiresAt time.Time     `json:"expires_at"`
}

// ç¼“å­˜ç»Ÿè®¡
type CacheStats struct {
	TotalItems    int     `json:"total_items"`
	HitCount      int64   `json:"hit_count"`
	MissCount     int64   `json:"miss_count"`
	EvictionCount int64   `json:"eviction_count"`
	MemoryUsage   int64   `json:"memory_usage"`
	HitRate       float64 `json:"hit_rate"`
	ExpiredItems  int     `json:"expired_items"`
}

// ç¼“å­˜ç®¡ç†å™¨
type CacheManager struct {
	aiCache         map[string]*AIAnalysisCache
	ruleCache       map[string]*RuleMatchCache
	configCache     map[string]*CacheItem
	stats           CacheStats
	mutex           sync.RWMutex
	maxSize         int64
	maxItems        int
	cleanupInterval time.Duration
	stopCleanup     chan bool
}

// ç¼“å­˜é…ç½®
type CacheConfig struct {
	MaxSize         int64         `json:"max_size"`         // æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰
	MaxItems        int           `json:"max_items"`        // æœ€å¤§ç¼“å­˜é¡¹æ•°
	DefaultTTL      time.Duration `json:"default_ttl"`      // é»˜è®¤è¿‡æœŸæ—¶é—´
	AITTL           time.Duration `json:"ai_ttl"`           // AIåˆ†æç»“æœè¿‡æœŸæ—¶é—´
	RuleTTL         time.Duration `json:"rule_ttl"`         // è§„åˆ™åŒ¹é…è¿‡æœŸæ—¶é—´
	ConfigTTL       time.Duration `json:"config_ttl"`       // é…ç½®ç¼“å­˜è¿‡æœŸæ—¶é—´
	CleanupInterval time.Duration `json:"cleanup_interval"` // æ¸…ç†é—´éš”
	Enabled         bool          `json:"enabled"`          // æ˜¯å¦å¯ç”¨ç¼“å­˜
}

// å·¥ä½œæ± ç›¸å…³ç»“æ„

// å·¥ä½œæ± é…ç½®
type WorkerPoolConfig struct {
	MaxWorkers   int           `json:"max_workers"`   // æœ€å¤§å·¥ä½œåç¨‹æ•°
	QueueSize    int           `json:"queue_size"`    // é˜Ÿåˆ—å¤§å°
	BatchSize    int           `json:"batch_size"`    // æ‰¹å¤„ç†å¤§å°
	Timeout      time.Duration `json:"timeout"`       // è¶…æ—¶æ—¶é—´
	RetryCount   int           `json:"retry_count"`   // é‡è¯•æ¬¡æ•°
	BackoffDelay time.Duration `json:"backoff_delay"` // é€€é¿å»¶è¿Ÿ
	Enabled      bool          `json:"enabled"`       // æ˜¯å¦å¯ç”¨
}

// å¤„ç†ä»»åŠ¡
type ProcessingJob struct {
	ID        string                 `json:"id"`
	Lines     []string               `json:"lines"`
	Format    string                 `json:"format"`
	Priority  int                    `json:"priority"`
	CreatedAt time.Time              `json:"created_at"`
	Metadata  map[string]interface{} `json:"metadata"`
}

// å¤„ç†ç»“æœ
type ProcessingResult struct {
	JobID          string                 `json:"job_id"`
	ProcessedLines int                    `json:"processed_lines"`
	FilteredLines  int                    `json:"filtered_lines"`
	AlertedLines   int                    `json:"alerted_lines"`
	ErrorCount     int                    `json:"error_count"`
	ProcessingTime time.Duration          `json:"processing_time"`
	CreatedAt      time.Time              `json:"created_at"`
	Results        []LogAnalysis          `json:"results"`
	Errors         []string               `json:"errors"`
	Metadata       map[string]interface{} `json:"metadata"`
}

// å·¥ä½œæ± ç»Ÿè®¡
type WorkerPoolStats struct {
	TotalJobs     int64         `json:"total_jobs"`
	CompletedJobs int64         `json:"completed_jobs"`
	FailedJobs    int64         `json:"failed_jobs"`
	ActiveWorkers int           `json:"active_workers"`
	QueueLength   int           `json:"queue_length"`
	AverageTime   time.Duration `json:"average_time"`
	TotalLines    int64         `json:"total_lines"`
	ErrorRate     float64       `json:"error_rate"`
	Throughput    float64       `json:"throughput"` // æ¯ç§’å¤„ç†è¡Œæ•°
}

// å·¥ä½œæ± 
type WorkerPool struct {
	config     WorkerPoolConfig
	jobQueue   chan ProcessingJob
	resultChan chan ProcessingResult
	workerPool chan chan ProcessingJob
	workers    []*Worker
	quit       chan bool
	stats      WorkerPoolStats
	mutex      sync.RWMutex
	startTime  time.Time
}

// å·¥ä½œåç¨‹
type Worker struct {
	ID            int
	WorkerPool    chan chan ProcessingJob
	JobChannel    chan ProcessingJob
	Quit          chan bool
	WorkerPoolRef *WorkerPool
}

// æ€§èƒ½æŒ‡æ ‡
type PerformanceMetrics struct {
	ProcessedLines int64     `json:"processed_lines"`
	FilteredLines  int64     `json:"filtered_lines"`
	AlertedLines   int64     `json:"alerted_lines"`
	APICalls       int64     `json:"api_calls"`
	ProcessingTime int64     `json:"processing_time_ms"`
	ErrorCount     int64     `json:"error_count"`
	CacheHits      int64     `json:"cache_hits"`
	CacheMisses    int64     `json:"cache_misses"`
	MemoryUsage    int64     `json:"memory_usage_bytes"`
	LastUpdated    time.Time `json:"last_updated"`
	Throughput     float64   `json:"throughput"`      // æ¯ç§’å¤„ç†è¡Œæ•°
	AverageLatency float64   `json:"average_latency"` // å¹³å‡å»¶è¿Ÿ(ms)
	ErrorRate      float64   `json:"error_rate"`      // é”™è¯¯ç‡
	CacheHitRate   float64   `json:"cache_hit_rate"`  // ç¼“å­˜å‘½ä¸­ç‡
}

// å†…å­˜ä¼˜åŒ–ç›¸å…³ç»“æ„

// å†…å­˜é…ç½®
type MemoryConfig struct {
	MaxMemoryUsage      int64         `json:"max_memory_usage"`      // æœ€å¤§å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰
	GCThreshold         int64         `json:"gc_threshold"`          // åƒåœ¾å›æ”¶é˜ˆå€¼
	StreamBufferSize    int           `json:"stream_buffer_size"`    // æµå¼å¤„ç†ç¼“å†²åŒºå¤§å°
	ChunkSize           int           `json:"chunk_size"`            // åˆ†å—å¤„ç†å¤§å°
	MemoryCheckInterval time.Duration `json:"memory_check_interval"` // å†…å­˜æ£€æŸ¥é—´éš”
	AutoGC              bool          `json:"auto_gc"`               // è‡ªåŠ¨åƒåœ¾å›æ”¶
	MemoryLimit         int64         `json:"memory_limit"`          // å†…å­˜é™åˆ¶
	Enabled             bool          `json:"enabled"`               // æ˜¯å¦å¯ç”¨å†…å­˜ä¼˜åŒ–
}

// å†…å­˜ç»Ÿè®¡
type MemoryStats struct {
	CurrentUsage   int64     `json:"current_usage"`   // å½“å‰å†…å­˜ä½¿ç”¨é‡
	PeakUsage      int64     `json:"peak_usage"`      // å³°å€¼å†…å­˜ä½¿ç”¨é‡
	GCCount        int64     `json:"gc_count"`        // åƒåœ¾å›æ”¶æ¬¡æ•°
	GCTime         int64     `json:"gc_time"`         // åƒåœ¾å›æ”¶æ—¶é—´ï¼ˆçº³ç§’ï¼‰
	AllocCount     int64     `json:"alloc_count"`     // åˆ†é…æ¬¡æ•°
	FreeCount      int64     `json:"free_count"`      // é‡Šæ”¾æ¬¡æ•°
	HeapSize       int64     `json:"heap_size"`       // å †å¤§å°
	StackSize      int64     `json:"stack_size"`      // æ ˆå¤§å°
	LastGC         time.Time `json:"last_gc"`         // ä¸Šæ¬¡åƒåœ¾å›æ”¶æ—¶é—´
	MemoryPressure float64   `json:"memory_pressure"` // å†…å­˜å‹åŠ›ï¼ˆ0-1ï¼‰
}

// æµå¼å¤„ç†å™¨
type StreamProcessor struct {
	BufferSize     int
	ChunkSize      int
	ProcessFunc    func([]string) error
	Buffer         []string
	TotalProcessed int64
	mutex          sync.Mutex
}

// å†…å­˜ç®¡ç†å™¨
type MemoryManager struct {
	config          MemoryConfig
	stats           MemoryStats
	streamProcessor *StreamProcessor
	mutex           sync.RWMutex
	lastGC          time.Time
	allocations     map[uintptr]int64
}

// å†…å­˜ç›‘æ§å™¨
type MemoryMonitor struct {
	enabled       bool
	checkInterval time.Duration
	threshold     int64
	callbacks     []func(MemoryStats)
	mutex         sync.RWMutex
	stopChan      chan bool
}

// å†…å­˜æ± 
type MemoryPool struct {
	pool          sync.Pool
	chunkSize     int
	maxChunks     int
	currentChunks int
	allocations   map[uintptr]int64
	mutex         sync.Mutex
}

// å†…å­˜åˆ†é…å™¨
type MemoryAllocator struct {
	pool           *MemoryPool
	allocations    map[uintptr]int64
	totalAllocated int64
	mutex          sync.RWMutex
}

// å¹¶å‘å¤„ç†ç›¸å…³ç»“æ„

// å¹¶å‘æ§åˆ¶é…ç½®
type ConcurrencyConfig struct {
	MaxConcurrency        int           `json:"max_concurrency"`        // æœ€å¤§å¹¶å‘æ•°
	BackpressureThreshold int           `json:"backpressure_threshold"` // èƒŒå‹é˜ˆå€¼
	LoadBalanceStrategy   string        `json:"load_balance_strategy"`  // è´Ÿè½½å‡è¡¡ç­–ç•¥
	AdaptiveScaling       bool          `json:"adaptive_scaling"`       // è‡ªé€‚åº”æ‰©ç¼©å®¹
	ScaleUpThreshold      float64       `json:"scale_up_threshold"`     // æ‰©å®¹é˜ˆå€¼
	ScaleDownThreshold    float64       `json:"scale_down_threshold"`   // ç¼©å®¹é˜ˆå€¼
	MinWorkers            int           `json:"min_workers"`            // æœ€å°å·¥ä½œåç¨‹æ•°
	MaxWorkers            int           `json:"max_workers"`            // æœ€å¤§å·¥ä½œåç¨‹æ•°
	ScalingInterval       time.Duration `json:"scaling_interval"`       // æ‰©ç¼©å®¹æ£€æŸ¥é—´éš”
	Enabled               bool          `json:"enabled"`                // æ˜¯å¦å¯ç”¨å¹¶å‘æ§åˆ¶
}

// èƒŒå‹æ§åˆ¶å™¨
type BackpressureController struct {
	threshold     int
	currentLoad   int64
	blockedCount  int64
	rejectedCount int64
	mutex         sync.RWMutex
	callbacks     []func(int64)
}

// è´Ÿè½½å‡è¡¡å™¨
type LoadBalancer struct {
	strategy     string
	workers      []*Worker
	currentIndex int
	workerStats  map[int]*WorkerStats
	mutex        sync.RWMutex
}

// å·¥ä½œåç¨‹ç»Ÿè®¡
type WorkerStats struct {
	ID            int           `json:"id"`
	ProcessedJobs int64         `json:"processed_jobs"`
	TotalTime     time.Duration `json:"total_time"`
	AverageTime   time.Duration `json:"average_time"`
	ErrorCount    int64         `json:"error_count"`
	LastActivity  time.Time     `json:"last_activity"`
	CurrentLoad   int64         `json:"current_load"`
	IsHealthy     bool          `json:"is_healthy"`
}

// è‡ªé€‚åº”æ‰©ç¼©å®¹å™¨
type AdaptiveScaler struct {
	config         ConcurrencyConfig
	currentWorkers int
	workerStats    map[int]*WorkerStats
	lastScaleTime  time.Time
	mutex          sync.RWMutex
}

// å¹¶å‘ç»Ÿè®¡
type ConcurrencyStats struct {
	TotalJobs        int64         `json:"total_jobs"`
	ProcessedJobs    int64         `json:"processed_jobs"`
	ActiveWorkers    int           `json:"active_workers"`
	BlockedJobs      int64         `json:"blocked_jobs"`
	RejectedJobs     int64         `json:"rejected_jobs"`
	AverageLatency   time.Duration `json:"average_latency"`
	Throughput       float64       `json:"throughput"`
	ErrorRate        float64       `json:"error_rate"`
	BackpressureRate float64       `json:"backpressure_rate"`
	LastUpdated      time.Time     `json:"last_updated"`
}

// å¹¶å‘æ§åˆ¶å™¨
type ConcurrencyController struct {
	config         ConcurrencyConfig
	backpressure   *BackpressureController
	loadBalancer   *LoadBalancer
	adaptiveScaler *AdaptiveScaler
	stats          ConcurrencyStats
	mutex          sync.RWMutex
	stopChan       chan bool
}

// ä»»åŠ¡ä¼˜å…ˆçº§
type TaskPriority int

const (
	PriorityLow      TaskPriority = 1
	PriorityNormal   TaskPriority = 2
	PriorityHigh     TaskPriority = 3
	PriorityCritical TaskPriority = 4
)

// ä¼˜å…ˆçº§é˜Ÿåˆ—
type PriorityQueue struct {
	jobs       []ProcessingJob
	priorities map[string]TaskPriority
	mutex      sync.RWMutex
}

// I/Oä¼˜åŒ–ç›¸å…³ç»“æ„

// I/Oé…ç½®
type IOConfig struct {
	BufferSize       int           `json:"buffer_size"`       // ç¼“å†²åŒºå¤§å°
	BatchSize        int           `json:"batch_size"`        // æ‰¹å¤„ç†å¤§å°
	FlushInterval    time.Duration `json:"flush_interval"`    // åˆ·æ–°é—´éš”
	AsyncIO          bool          `json:"async_io"`          // å¼‚æ­¥I/O
	ReadAhead        int           `json:"read_ahead"`        // é¢„è¯»å¤§å°
	WriteBehind      bool          `json:"write_behind"`      // å†™åç½®
	Compression      bool          `json:"compression"`       // å‹ç¼©
	CompressionLevel int           `json:"compression_level"` // å‹ç¼©çº§åˆ«
	CacheSize        int64         `json:"cache_size"`        // ç¼“å­˜å¤§å°
	Enabled          bool          `json:"enabled"`           // æ˜¯å¦å¯ç”¨I/Oä¼˜åŒ–
}

// å¼‚æ­¥I/Oæ“ä½œ
type AsyncIOOperation struct {
	ID        string
	Type      string // read, write, flush
	Data      []byte
	Callback  func([]byte, error)
	Timestamp time.Time
}

// I/Oç¼“å†²åŒº
type IOBuffer struct {
	buffer    []byte
	size      int
	position  int
	capacity  int
	mutex     sync.RWMutex
	flushChan chan bool
	stopChan  chan bool
}

// æ‰¹é‡I/Oå¤„ç†å™¨
type BatchIOProcessor struct {
	config     IOConfig
	buffers    map[string]*IOBuffer
	operations chan AsyncIOOperation
	results    chan AsyncIOOperation
	stopChan   chan bool
	stats      IOStats
	mutex      sync.RWMutex
}

// I/Oç»Ÿè®¡
type IOStats struct {
	ReadOperations  int64         `json:"read_operations"`
	WriteOperations int64         `json:"write_operations"`
	BytesRead       int64         `json:"bytes_read"`
	BytesWritten    int64         `json:"bytes_written"`
	ReadLatency     time.Duration `json:"read_latency"`
	WriteLatency    time.Duration `json:"write_latency"`
	BufferHits      int64         `json:"buffer_hits"`
	BufferMisses    int64         `json:"buffer_misses"`
	FlushOperations int64         `json:"flush_operations"`
	ErrorCount      int64         `json:"error_count"`
	LastFlush       time.Time     `json:"last_flush"`
	Throughput      float64       `json:"throughput"` // å­—èŠ‚/ç§’
}

// I/Oä¼˜åŒ–å™¨
type IOOptimizer struct {
	config    IOConfig
	processor *BatchIOProcessor
	stats     IOStats
	mutex     sync.RWMutex
	stopChan  chan bool
}

// æ–‡ä»¶ç›‘æ§å™¨
type FileMonitor struct {
	filePath  string
	lastSize  int64
	lastMod   time.Time
	watcher   *fsnotify.Watcher
	callbacks []func(string, []byte)
	mutex     sync.RWMutex
	stopChan  chan bool
}

// å‹ç¼©å™¨
type Compressor struct {
	level      int
	algorithm  string
	compressed map[string][]byte
	mutex      sync.RWMutex
}

// ç¼“å­˜ç®¡ç†å™¨
type IOCacheManager struct {
	cache       map[string][]byte
	maxSize     int64
	currentSize int64
	stats       IOStats
	mutex       sync.RWMutex
}

// ä»»åŠ¡è°ƒåº¦å™¨
type TaskScheduler struct {
	priorityQueue *PriorityQueue
	workers       []*Worker
	loadBalancer  *LoadBalancer
	stats         ConcurrencyStats
	mutex         sync.RWMutex
}

// é…ç½®æ–‡ä»¶ç»“æ„
type Config struct {
	AIEndpoint   string         `json:"ai_endpoint"` // å‘åå…¼å®¹
	Token        string         `json:"token"`       // å‘åå…¼å®¹
	Model        string         `json:"model"`       // å‘åå…¼å®¹
	CustomPrompt string         `json:"custom_prompt"`
	Notifiers    NotifierConfig `json:"notifiers"`

	// æ–°å¢é…ç½®é¡¹
	MaxRetries  int  `json:"max_retries"`  // API é‡è¯•æ¬¡æ•°
	Timeout     int  `json:"timeout"`      // è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
	RateLimit   int  `json:"rate_limit"`   // è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼ˆæ¯åˆ†é’Ÿï¼‰
	LocalFilter bool `json:"local_filter"` // æ˜¯å¦å¯ç”¨æœ¬åœ°è¿‡æ»¤

	// å¤šAIæœåŠ¡æ”¯æŒ
	AIServices []AIService `json:"ai_services"` // AI æœåŠ¡åˆ—è¡¨
	DefaultAI  string      `json:"default_ai"`  // é»˜è®¤AIæœåŠ¡åç§°

	// è§„åˆ™å¼•æ“é…ç½®
	Rules []FilterRule `json:"rules"` // è¿‡æ»¤è§„åˆ™åˆ—è¡¨

	// ç¼“å­˜é…ç½®
	Cache CacheConfig `json:"cache"` // ç¼“å­˜é…ç½®

	// å·¥ä½œæ± é…ç½®
	WorkerPool WorkerPoolConfig `json:"worker_pool"` // å·¥ä½œæ± é…ç½®

	// å†…å­˜ä¼˜åŒ–é…ç½®
	Memory MemoryConfig `json:"memory"` // å†…å­˜ä¼˜åŒ–é…ç½®

	// å¹¶å‘æ§åˆ¶é…ç½®
	Concurrency ConcurrencyConfig `json:"concurrency"` // å¹¶å‘æ§åˆ¶é…ç½®

	// I/Oä¼˜åŒ–é…ç½®
	IO IOConfig `json:"io"`

	// ç”¨æˆ·ä½“éªŒé…ç½®
	OutputFormat OutputFormat   `json:"output_format"`
	LogLevel     LogLevelConfig `json:"log_level"` // I/Oä¼˜åŒ–é…ç½®
}

// é”™è¯¯çº§åˆ«
type ErrorLevel int

const (
	ErrorLevelInfo ErrorLevel = iota
	ErrorLevelWarning
	ErrorLevelError
	ErrorLevelCritical
)

// é”™è¯¯åˆ†ç±»
type ErrorCategory string

const (
	ErrorCategoryConfig     ErrorCategory = "config"
	ErrorCategoryNetwork    ErrorCategory = "network"
	ErrorCategoryAI         ErrorCategory = "ai"
	ErrorCategoryProcessing ErrorCategory = "processing"
	ErrorCategoryOutput     ErrorCategory = "output"
	ErrorCategoryFile       ErrorCategory = "file"
)

// AIPipe é”™è¯¯ç»“æ„
type AIPipeError struct {
	Code       string                 `json:"code"`
	Category   ErrorCategory          `json:"category"`
	Level      ErrorLevel             `json:"level"`
	Message    string                 `json:"message"`
	Suggestion string                 `json:"suggestion"`
	Context    map[string]interface{} `json:"context"`
	Timestamp  time.Time              `json:"timestamp"`
	StackTrace string                 `json:"stack_trace"`
}

func (e *AIPipeError) Error() string {
	return fmt.Sprintf("[%s] %s: %s", e.Category, e.Code, e.Message)
}

// é…ç½®éªŒè¯é”™è¯¯
type ConfigValidationError struct {
	Field   string `json:"field"`
	Message string `json:"message"`
	Value   string `json:"value"`
}

func (e *ConfigValidationError) Error() string {
	return fmt.Sprintf("é…ç½®éªŒè¯å¤±è´¥ [%s]: %s (å½“å‰å€¼: %s)", e.Field, e.Message, e.Value)
}

// é”™è¯¯æ¢å¤ç­–ç•¥
type ErrorRecovery struct {
	strategies map[ErrorCategory]RecoveryStrategy
	maxRetries int
	backoff    time.Duration
}

type RecoveryStrategy interface {
	CanRecover(err error) bool
	Recover(err error) error
}

// ç½‘ç»œé”™è¯¯æ¢å¤ç­–ç•¥
type NetworkErrorRecovery struct {
	maxRetries int
	backoff    time.Duration
}

func (ner *NetworkErrorRecovery) CanRecover(err error) bool {
	// æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œç›¸å…³é”™è¯¯
	return strings.Contains(err.Error(), "timeout") ||
		strings.Contains(err.Error(), "connection") ||
		strings.Contains(err.Error(), "network")
}

func (ner *NetworkErrorRecovery) Recover(err error) error {
	// å®ç°ç½‘ç»œé”™è¯¯æ¢å¤é€»è¾‘
	time.Sleep(ner.backoff)
	return nil
}

// é…ç½®é”™è¯¯æ¢å¤ç­–ç•¥
type ConfigErrorRecovery struct {
	fallbackConfig *Config
	validator      *ConfigValidator
}

func (cer *ConfigErrorRecovery) CanRecover(err error) bool {
	return strings.Contains(err.Error(), "config") || strings.Contains(err.Error(), "é…ç½®æ–‡ä»¶")
}

func (cer *ConfigErrorRecovery) Recover(err error) error {
	// ä½¿ç”¨é»˜è®¤é…ç½®
	globalConfig = *cer.fallbackConfig
	return nil
}

// é”™è¯¯å¤„ç†å™¨
type ErrorHandler struct {
	recovery *ErrorRecovery
	logger   *log.Logger
}

func NewErrorHandler() *ErrorHandler {
	return &ErrorHandler{
		recovery: &ErrorRecovery{
			strategies: make(map[ErrorCategory]RecoveryStrategy),
			maxRetries: 3,
			backoff:    time.Second * 2,
		},
		logger: log.New(os.Stderr, "[ERROR] ", log.LstdFlags),
	}
}

func (eh *ErrorHandler) RegisterStrategy(category ErrorCategory, strategy RecoveryStrategy) {
	eh.recovery.strategies[category] = strategy
}

func (eh *ErrorHandler) Handle(err error, context map[string]interface{}) error {
	// åˆ›å»º AIPipe é”™è¯¯
	aipipeErr := &AIPipeError{
		Code:       "UNKNOWN_ERROR",
		Category:   ErrorCategoryProcessing,
		Level:      ErrorLevelError,
		Message:    err.Error(),
		Context:    context,
		Timestamp:  time.Now(),
		StackTrace: getStackTrace(),
	}

	// æ ¹æ®é”™è¯¯ç±»å‹è®¾ç½®åˆ†ç±»å’Œçº§åˆ«
	eh.classifyError(aipipeErr)

	// è®°å½•é”™è¯¯
	eh.logError(aipipeErr)

	// å°è¯•æ¢å¤
	if strategy, exists := eh.recovery.strategies[aipipeErr.Category]; exists {
		if strategy.CanRecover(err) {
			if recoverErr := strategy.Recover(err); recoverErr == nil {
				if eh.logger != nil {
					eh.logger.Printf("é”™è¯¯å·²æ¢å¤: %s", aipipeErr.Message)
				}
				return nil
			}
		}
	}

	return aipipeErr
}

func (eh *ErrorHandler) classifyError(err *AIPipeError) {
	errMsg := strings.ToLower(err.Message)

	// ç½‘ç»œé”™è¯¯
	if strings.Contains(errMsg, "timeout") || strings.Contains(errMsg, "connection") {
		err.Category = ErrorCategoryNetwork
		err.Level = ErrorLevelWarning
		err.Code = "NETWORK_ERROR"
		err.Suggestion = "æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å™¨çŠ¶æ€"
	}

	// AI æœåŠ¡é”™è¯¯
	if strings.Contains(errMsg, "api") || strings.Contains(errMsg, "ai") {
		err.Category = ErrorCategoryAI
		err.Level = ErrorLevelError
		err.Code = "AI_SERVICE_ERROR"
		err.Suggestion = "æ£€æŸ¥ AI æœåŠ¡é…ç½®å’Œ Token æœ‰æ•ˆæ€§"
	}

	// é…ç½®é”™è¯¯
	if strings.Contains(errMsg, "config") || strings.Contains(errMsg, "é…ç½®æ–‡ä»¶") {
		err.Category = ErrorCategoryConfig
		err.Level = ErrorLevelCritical
		err.Code = "CONFIG_ERROR"
		err.Suggestion = "æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼å’Œå†…å®¹"
	}

	// æ–‡ä»¶é”™è¯¯
	if strings.Contains(errMsg, "file") || strings.Contains(errMsg, "æ–‡ä»¶") {
		err.Category = ErrorCategoryFile
		err.Level = ErrorLevelError
		err.Code = "FILE_ERROR"
		err.Suggestion = "æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæƒé™"
	}
}

func (eh *ErrorHandler) logError(err *AIPipeError) {
	if eh.logger == nil {
		return // å¦‚æœ logger ä¸º nilï¼Œä¸è¾“å‡ºæ—¥å¿—
	}

	levelStr := []string{"INFO", "WARNING", "ERROR", "CRITICAL"}[err.Level]
	eh.logger.Printf("[%s] %s: %s", levelStr, err.Category, err.Message)

	if err.Suggestion != "" {
		eh.logger.Printf("å»ºè®®: %s", err.Suggestion)
	}

	if *debug {
		eh.logger.Printf("ä¸Šä¸‹æ–‡: %+v", err.Context)
		eh.logger.Printf("å †æ ˆè·Ÿè¸ª: %s", err.StackTrace)
	}
}

func getStackTrace() string {
	buf := make([]byte, 1024)
	n := runtime.Stack(buf, false)
	return string(buf[:n])
}

// AI æœåŠ¡ç®¡ç†å™¨æ–¹æ³•

// åˆ›å»ºæ–°çš„AIæœåŠ¡ç®¡ç†å™¨
func NewAIServiceManager(services []AIService) *AIServiceManager {
	// æŒ‰ä¼˜å…ˆçº§æ’åº
	sortedServices := make([]AIService, len(services))
	copy(sortedServices, services)

	// ç®€å•çš„å†’æ³¡æ’åºæŒ‰ä¼˜å…ˆçº§æ’åº
	for i := 0; i < len(sortedServices)-1; i++ {
		for j := 0; j < len(sortedServices)-i-1; j++ {
			if sortedServices[j].Priority > sortedServices[j+1].Priority {
				sortedServices[j], sortedServices[j+1] = sortedServices[j+1], sortedServices[j]
			}
		}
	}

	return &AIServiceManager{
		services:    sortedServices,
		current:     0,
		fallback:    false,
		rateLimiter: make(map[string]time.Time),
	}
}

// è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„AIæœåŠ¡
func (asm *AIServiceManager) GetNextService() (*AIService, error) {
	asm.mutex.Lock()
	defer asm.mutex.Unlock()

	// æŸ¥æ‰¾å¯ç”¨çš„æœåŠ¡
	for i := 0; i < len(asm.services); i++ {
		service := &asm.services[asm.current]
		if service.Enabled {
			// æ£€æŸ¥é¢‘ç‡é™åˆ¶
			if asm.isRateLimited(service.Name) {
				asm.current = (asm.current + 1) % len(asm.services)
				continue
			}

			// æ›´æ–°å½“å‰ç´¢å¼•
			asm.current = (asm.current + 1) % len(asm.services)
			return service, nil
		}
		asm.current = (asm.current + 1) % len(asm.services)
	}

	return nil, fmt.Errorf("æ²¡æœ‰å¯ç”¨çš„AIæœåŠ¡")
}

// æ£€æŸ¥æœåŠ¡æ˜¯å¦è¢«é¢‘ç‡é™åˆ¶
func (asm *AIServiceManager) isRateLimited(serviceName string) bool {
	if lastCall, exists := asm.rateLimiter[serviceName]; exists {
		// æ£€æŸ¥æ˜¯å¦åœ¨é™åˆ¶æ—¶é—´å†…
		if time.Since(lastCall) < time.Minute/time.Duration(globalConfig.RateLimit) {
			return true
		}
	}
	return false
}

// è®°å½•æœåŠ¡è°ƒç”¨æ—¶é—´
func (asm *AIServiceManager) RecordCall(serviceName string) {
	asm.mutex.Lock()
	defer asm.mutex.Unlock()
	asm.rateLimiter[serviceName] = time.Now()
}

// è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
func (asm *AIServiceManager) GetStats() map[string]interface{} {
	asm.mutex.RLock()
	defer asm.mutex.RUnlock()

	stats := map[string]interface{}{
		"total_services":   len(asm.services),
		"enabled_services": 0,
		"current_index":    asm.current,
		"fallback_mode":    asm.fallback,
	}

	for _, service := range asm.services {
		if service.Enabled {
			stats["enabled_services"] = stats["enabled_services"].(int) + 1
		}
	}

	return stats
}

// å¯ç”¨/ç¦ç”¨æœåŠ¡
func (asm *AIServiceManager) SetServiceEnabled(serviceName string, enabled bool) error {
	asm.mutex.Lock()
	defer asm.mutex.Unlock()

	for i := range asm.services {
		if asm.services[i].Name == serviceName {
			asm.services[i].Enabled = enabled
			return nil
		}
	}

	return fmt.Errorf("æœåŠ¡ %s ä¸å­˜åœ¨", serviceName)
}

// è·å–æœåŠ¡åˆ—è¡¨
func (asm *AIServiceManager) GetServices() []AIService {
	asm.mutex.RLock()
	defer asm.mutex.RUnlock()

	services := make([]AIService, len(asm.services))
	copy(services, asm.services)
	return services
}

// è§„åˆ™å¼•æ“æ–¹æ³•

// åˆ›å»ºæ–°çš„è§„åˆ™å¼•æ“
func NewRuleEngine(rules []FilterRule) *RuleEngine {
	// æŒ‰ä¼˜å…ˆçº§æ’åºè§„åˆ™
	sortedRules := make([]FilterRule, len(rules))
	copy(sortedRules, rules)

	// ç®€å•çš„å†’æ³¡æ’åºæŒ‰ä¼˜å…ˆçº§æ’åº
	for i := 0; i < len(sortedRules)-1; i++ {
		for j := 0; j < len(sortedRules)-i-1; j++ {
			if sortedRules[j].Priority > sortedRules[j+1].Priority {
				sortedRules[j], sortedRules[j+1] = sortedRules[j+1], sortedRules[j]
			}
		}
	}

	// ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
	compiledRules := make(map[string]*regexp.Regexp)
	for _, rule := range sortedRules {
		if rule.Enabled && rule.Pattern != "" {
			if compiled, err := regexp.Compile(rule.Pattern); err == nil {
				compiledRules[rule.ID] = compiled
			}
		}
	}

	// ç»Ÿè®¡å¯ç”¨çš„è§„åˆ™
	enabledCount := 0
	for _, rule := range sortedRules {
		if rule.Enabled {
			enabledCount++
		}
	}

	return &RuleEngine{
		rules:         sortedRules,
		compiledRules: compiledRules,
		cache:         make(map[string]bool),
		stats: RuleStats{
			TotalRules:   len(sortedRules),
			EnabledRules: enabledCount,
		},
	}
}

// è¿‡æ»¤æ—¥å¿—è¡Œ
func (re *RuleEngine) Filter(line string) *FilterResult {
	re.mutex.RLock()
	defer re.mutex.RUnlock()

	// æ£€æŸ¥ç¼“å­˜
	if cached, exists := re.cache[line]; exists {
		re.stats.CacheHits++
		if cached {
			return &FilterResult{
				Action:       "ignore",
				ShouldIgnore: true,
			}
		}
	} else {
		re.stats.CacheMisses++
	}

	// éå†è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼‰
	for _, rule := range re.rules {
		if !rule.Enabled {
			continue
		}

		// æ£€æŸ¥æ˜¯å¦åŒ¹é…
		if compiled, exists := re.compiledRules[rule.ID]; exists {
			if compiled.MatchString(line) {
				// æ›´æ–°ç»Ÿè®¡
				re.updateStats(rule.Action)

				// ç¼“å­˜ç»“æœ
				re.cache[line] = (rule.Action == "ignore")

				return re.createFilterResult(rule)
			}
		}
	}

	// æ²¡æœ‰åŒ¹é…çš„è§„åˆ™ï¼Œé»˜è®¤å¤„ç†
	return &FilterResult{
		Action:        "process",
		ShouldProcess: true,
	}
}

// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (re *RuleEngine) updateStats(action string) {
	switch action {
	case "filter":
		re.stats.FilteredLines++
	case "alert":
		re.stats.AlertedLines++
	case "ignore":
		re.stats.IgnoredLines++
	case "highlight":
		re.stats.HighlightedLines++
	}
}

// åˆ›å»ºè¿‡æ»¤ç»“æœ
func (re *RuleEngine) createFilterResult(rule FilterRule) *FilterResult {
	result := &FilterResult{
		Action:   rule.Action,
		RuleID:   rule.ID,
		RuleName: rule.Name,
		Category: rule.Category,
		Color:    rule.Color,
	}

	// è®¾ç½®åŠ¨ä½œæ ‡å¿—
	switch rule.Action {
	case "filter":
		result.ShouldProcess = false
	case "alert":
		result.ShouldProcess = true
		result.ShouldAlert = true
	case "ignore":
		result.ShouldIgnore = true
	case "highlight":
		result.ShouldProcess = true
		result.ShouldHighlight = true
	default:
		result.ShouldProcess = true
	}

	return result
}

// æ·»åŠ è§„åˆ™
func (re *RuleEngine) AddRule(rule FilterRule) error {
	re.mutex.Lock()
	defer re.mutex.Unlock()

	// æ£€æŸ¥IDæ˜¯å¦å·²å­˜åœ¨
	for _, existingRule := range re.rules {
		if existingRule.ID == rule.ID {
			return fmt.Errorf("è§„åˆ™ID %s å·²å­˜åœ¨", rule.ID)
		}
	}

	// ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
	if rule.Pattern != "" {
		compiled, err := regexp.Compile(rule.Pattern)
		if err != nil {
			return fmt.Errorf("æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å¤±è´¥: %w", err)
		}
		re.compiledRules[rule.ID] = compiled
	}

	// æ·»åŠ åˆ°è§„åˆ™åˆ—è¡¨
	re.rules = append(re.rules, rule)

	// é‡æ–°æ’åº
	re.sortRules()

	// æ›´æ–°ç»Ÿè®¡
	re.stats.TotalRules++
	if rule.Enabled {
		re.stats.EnabledRules++
	}

	return nil
}

// åˆ é™¤è§„åˆ™
func (re *RuleEngine) RemoveRule(ruleID string) error {
	re.mutex.Lock()
	defer re.mutex.Unlock()

	for i, rule := range re.rules {
		if rule.ID == ruleID {
			// åˆ é™¤è§„åˆ™
			re.rules = append(re.rules[:i], re.rules[i+1:]...)

			// åˆ é™¤ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼
			delete(re.compiledRules, ruleID)

			// æ›´æ–°ç»Ÿè®¡
			re.stats.TotalRules--
			if rule.Enabled {
				re.stats.EnabledRules--
			}

			return nil
		}
	}

	return fmt.Errorf("è§„åˆ™ID %s ä¸å­˜åœ¨", ruleID)
}

// å¯ç”¨/ç¦ç”¨è§„åˆ™
func (re *RuleEngine) SetRuleEnabled(ruleID string, enabled bool) error {
	re.mutex.Lock()
	defer re.mutex.Unlock()

	for i, rule := range re.rules {
		if rule.ID == ruleID {
			oldEnabled := rule.Enabled
			re.rules[i].Enabled = enabled

			// æ›´æ–°ç»Ÿè®¡
			if oldEnabled && !enabled {
				re.stats.EnabledRules--
			} else if !oldEnabled && enabled {
				re.stats.EnabledRules++
			}

			return nil
		}
	}

	return fmt.Errorf("è§„åˆ™ID %s ä¸å­˜åœ¨", ruleID)
}

// æ’åºè§„åˆ™
func (re *RuleEngine) sortRules() {
	for i := 0; i < len(re.rules)-1; i++ {
		for j := 0; j < len(re.rules)-i-1; j++ {
			if re.rules[j].Priority > re.rules[j+1].Priority {
				re.rules[j], re.rules[j+1] = re.rules[j+1], re.rules[j]
			}
		}
	}
}

// è·å–è§„åˆ™åˆ—è¡¨
func (re *RuleEngine) GetRules() []FilterRule {
	re.mutex.RLock()
	defer re.mutex.RUnlock()

	rules := make([]FilterRule, len(re.rules))
	copy(rules, re.rules)
	return rules
}

// è·å–ç»Ÿè®¡ä¿¡æ¯
func (re *RuleEngine) GetStats() RuleStats {
	re.mutex.RLock()
	defer re.mutex.RUnlock()

	return re.stats
}

// æ¸…ç©ºç¼“å­˜
func (re *RuleEngine) ClearCache() {
	re.mutex.Lock()
	defer re.mutex.Unlock()

	re.cache = make(map[string]bool)
	re.stats.CacheHits = 0
	re.stats.CacheMisses = 0
}

// æµ‹è¯•è§„åˆ™
func (re *RuleEngine) TestRule(ruleID, testLine string) (bool, error) {
	re.mutex.RLock()
	defer re.mutex.RUnlock()

	compiled, exists := re.compiledRules[ruleID]
	if !exists {
		return false, fmt.Errorf("è§„åˆ™ID %s ä¸å­˜åœ¨æˆ–æœªç¼–è¯‘", ruleID)
	}

	return compiled.MatchString(testLine), nil
}

// é…ç½®éªŒè¯å™¨
type ConfigValidator struct {
	errors []ConfigValidationError
}

func NewConfigValidator() *ConfigValidator {
	return &ConfigValidator{
		errors: make([]ConfigValidationError, 0),
	}
}

func (cv *ConfigValidator) Validate(config *Config) error {
	cv.errors = cv.errors[:0] // æ¸…ç©ºä¹‹å‰çš„é”™è¯¯

	// éªŒè¯å¿…å¡«å­—æ®µ
	cv.validateRequired("ai_endpoint", config.AIEndpoint)
	cv.validateRequired("token", config.Token)
	cv.validateRequired("model", config.Model)

	// éªŒè¯ URL æ ¼å¼
	cv.validateURL("ai_endpoint", config.AIEndpoint)

	// éªŒè¯æ•°å€¼èŒƒå›´
	cv.validateRange("max_retries", config.MaxRetries, 0, 10)
	cv.validateRange("timeout", config.Timeout, 5, 300)
	cv.validateRange("rate_limit", config.RateLimit, 1, 1000)

	// éªŒè¯ Token é•¿åº¦
	cv.validateMinLength("token", config.Token, 10)

	if len(cv.errors) > 0 {
		return fmt.Errorf("é…ç½®éªŒè¯å¤±è´¥ï¼Œå‘ç° %d ä¸ªé”™è¯¯", len(cv.errors))
	}

	return nil
}

func (cv *ConfigValidator) validateRequired(field, value string) {
	if strings.TrimSpace(value) == "" {
		cv.errors = append(cv.errors, ConfigValidationError{
			Field:   field,
			Message: "æ­¤å­—æ®µä¸ºå¿…å¡«é¡¹",
			Value:   value,
		})
	}
}

func (cv *ConfigValidator) validateURL(field, value string) {
	if value == "" {
		return
	}

	if !strings.HasPrefix(value, "http://") && !strings.HasPrefix(value, "https://") {
		cv.errors = append(cv.errors, ConfigValidationError{
			Field:   field,
			Message: "å¿…é¡»æ˜¯æœ‰æ•ˆçš„ URL æ ¼å¼",
			Value:   value,
		})
	}
}

func (cv *ConfigValidator) validateRange(field string, value, min, max int) {
	if value < min || value > max {
		cv.errors = append(cv.errors, ConfigValidationError{
			Field:   field,
			Message: fmt.Sprintf("å€¼å¿…é¡»åœ¨ %d åˆ° %d ä¹‹é—´", min, max),
			Value:   fmt.Sprintf("%d", value),
		})
	}
}

func (cv *ConfigValidator) validateMinLength(field, value string, minLen int) {
	if len(value) < minLen {
		cv.errors = append(cv.errors, ConfigValidationError{
			Field:   field,
			Message: fmt.Sprintf("é•¿åº¦è‡³å°‘ä¸º %d ä¸ªå­—ç¬¦", minLen),
			Value:   fmt.Sprintf("%d", len(value)),
		})
	}
}

func (cv *ConfigValidator) GetErrors() []ConfigValidationError {
	return cv.errors
}

// é»˜è®¤é…ç½®
var defaultConfig = Config{
	AIEndpoint:   "https://your-ai-server.com/api/v1/chat/completions",
	Token:        "your-api-token-here",
	Model:        "gpt-4",
	CustomPrompt: "",
	MaxRetries:   3,
	Timeout:      30,
	RateLimit:    100,
	LocalFilter:  true,
	Notifiers: NotifierConfig{
		Email: EmailConfig{
			Enabled:   false,
			Provider:  "smtp",
			Host:      "smtp.gmail.com",
			Port:      587,
			Username:  "",
			Password:  "",
			FromEmail: "",
			ToEmails:  []string{},
		},
		DingTalk: WebhookConfig{
			Enabled: false,
			URL:     "",
		},
		WeChat: WebhookConfig{
			Enabled: false,
			URL:     "",
		},
		Feishu: WebhookConfig{
			Enabled: false,
			URL:     "",
		},
		Slack: WebhookConfig{
			Enabled: false,
			URL:     "",
		},
		CustomWebhooks: []WebhookConfig{},
	},
	Cache: CacheConfig{
		MaxSize:         100 * 1024 * 1024, // 100MB
		MaxItems:        1000,
		DefaultTTL:      1 * time.Hour,
		AITTL:           24 * time.Hour,
		RuleTTL:         1 * time.Hour,
		ConfigTTL:       30 * time.Minute,
		CleanupInterval: 5 * time.Minute,
		Enabled:         true,
	},
	WorkerPool: WorkerPoolConfig{
		MaxWorkers:   4,
		QueueSize:    100,
		BatchSize:    10,
		Timeout:      30 * time.Second,
		RetryCount:   3,
		BackoffDelay: 1 * time.Second,
		Enabled:      true,
	},
	Memory: MemoryConfig{
		MaxMemoryUsage:      512 * 1024 * 1024, // 512MB
		GCThreshold:         256 * 1024 * 1024, // 256MB
		StreamBufferSize:    1000,
		ChunkSize:           100,
		MemoryCheckInterval: 5 * time.Second,
		AutoGC:              true,
		MemoryLimit:         1024 * 1024 * 1024, // 1GB
		Enabled:             true,
	},
	Concurrency: ConcurrencyConfig{
		MaxConcurrency:        100,
		BackpressureThreshold: 80,
		LoadBalanceStrategy:   "round_robin",
		AdaptiveScaling:       true,
		ScaleUpThreshold:      0.8,
		ScaleDownThreshold:    0.3,
		MinWorkers:            2,
		MaxWorkers:            20,
		ScalingInterval:       30 * time.Second,
		Enabled:               true,
	},
	IO: IOConfig{
		BufferSize:       64 * 1024, // 64KB
		BatchSize:        1000,
		FlushInterval:    5 * time.Second,
		AsyncIO:          true,
		ReadAhead:        32 * 1024, // 32KB
		WriteBehind:      true,
		Compression:      false,
		CompressionLevel: 6,
		CacheSize:        10 * 1024 * 1024, // 10MB
		Enabled:          true,
	},

	// ç”¨æˆ·ä½“éªŒé…ç½®
	OutputFormat: OutputFormat{
		Type:     "table",
		Template: "",
		Color:    true,
		Filter:   "",
		Width:    120,
		Headers:  true,
	},
	LogLevel: LogLevelConfig{
		Level:     "info",
		ShowDebug: false,
		ShowInfo:  true,
		ShowWarn:  true,
		ShowError: true,
		ShowFatal: true,
		MinLevel:  "info",
		MaxLevel:  "fatal",
		Enabled:   true,
	},
}

// å…¨å±€é…ç½®å˜é‡
var globalConfig Config

// å…¨å±€é”™è¯¯å¤„ç†å™¨
var errorHandler *ErrorHandler

// å…¨å±€AIæœåŠ¡ç®¡ç†å™¨
var aiServiceManager *AIServiceManager

// å…¨å±€è§„åˆ™å¼•æ“
var ruleEngine *RuleEngine

// å…¨å±€ç¼“å­˜ç®¡ç†å™¨
var cacheManager *CacheManager

// å…¨å±€å·¥ä½œæ± ç®¡ç†å™¨
var workerPool *WorkerPool

// å…¨å±€å†…å­˜ç®¡ç†å™¨
var memoryManager *MemoryManager

// å…¨å±€å¹¶å‘æ§åˆ¶å™¨
var concurrencyController *ConcurrencyController

// å…¨å±€I/Oä¼˜åŒ–å™¨
var ioOptimizer *IOOptimizer

// å…¨å±€é…ç½®å‘å¯¼
var configWizard *ConfigWizard

// æ‰¹å¤„ç†é…ç½®
const (
	BATCH_MAX_SIZE  = 10              // æ‰¹å¤„ç†æœ€å¤§è¡Œæ•°
	BATCH_WAIT_TIME = 3 * time.Second // æ‰¹å¤„ç†ç­‰å¾…æ—¶é—´
)

// OpenAI API è¯·æ±‚å’Œå“åº”ç»“æ„
type ChatMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type ChatRequest struct {
	Model    string        `json:"model"`
	Messages []ChatMessage `json:"messages"`
}

type ChatResponse struct {
	Choices []struct {
		Message ChatMessage `json:"message"`
	} `json:"choices"`
}

// æ—¥å¿—åˆ†æç»“æœï¼ˆå•æ¡ï¼‰
type LogAnalysis struct {
	Line         string  `json:"line"`      // æ—¥å¿—è¡Œå†…å®¹
	Important    bool    `json:"important"` // æ˜¯å¦é‡è¦
	ShouldFilter bool    `json:"should_filter"`
	Summary      string  `json:"summary"`
	Reason       string  `json:"reason"`
	Confidence   float64 `json:"confidence"` // ç½®ä¿¡åº¦
}

// æ‰¹é‡æ—¥å¿—åˆ†æç»“æœ
type BatchLogAnalysis struct {
	Results        []LogAnalysis `json:"results"`         // æ¯è¡Œæ—¥å¿—çš„åˆ†æç»“æœ
	OverallSummary string        `json:"overall_summary"` // æ•´ä½“æ‘˜è¦
	ImportantCount int           `json:"important_count"` // é‡è¦æ—¥å¿—æ•°é‡
}

// æ—¥å¿—æ‰¹å¤„ç†å™¨
type LogBatcher struct {
	lines     []string
	timer     *time.Timer
	mu        sync.Mutex
	processor func([]string)
}

// æ–‡ä»¶çŠ¶æ€ï¼ˆç”¨äºè®°ä½è¯»å–ä½ç½®ï¼‰
type FileState struct {
	Path   string    `json:"path"`
	Offset int64     `json:"offset"`
	Inode  uint64    `json:"inode"`
	Time   time.Time `json:"time"`
}

// æ—¥å¿—è¡Œåˆå¹¶å™¨ï¼ˆç”¨äºåˆå¹¶å¤šè¡Œæ—¥å¿—ï¼Œå¦‚ Java å †æ ˆè·Ÿè¸ªï¼‰
type LogLineMerger struct {
	format      string
	buffer      string
	hasBuffered bool
}

// å¤šæºç›‘æ§é…ç½®
type MultiSourceConfig struct {
	Sources []SourceConfig `json:"sources"`
}

type SourceConfig struct {
	Name        string         `json:"name"`        // æºåç§°
	Type        string         `json:"type"`        // æºç±»å‹: file, journalctl, stdin
	Path        string         `json:"path"`        // æ–‡ä»¶è·¯å¾„ï¼ˆtype=fileæ—¶ï¼‰
	Format      string         `json:"format"`      // æ—¥å¿—æ ¼å¼
	Journal     *JournalConfig `json:"journal"`     // journalctlé…ç½®ï¼ˆtype=journalctlæ—¶ï¼‰
	Enabled     bool           `json:"enabled"`     // æ˜¯å¦å¯ç”¨
	Priority    int            `json:"priority"`    // ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
	Description string         `json:"description"` // æè¿°
}

type JournalConfig struct {
	Services []string `json:"services"` // ç›‘æ§çš„æœåŠ¡
	Priority string   `json:"priority"` // æ—¥å¿—çº§åˆ«
	Since    string   `json:"since"`    // å¼€å§‹æ—¶é—´
	Until    string   `json:"until"`    // ç»“æŸæ—¶é—´
	User     string   `json:"user"`     // ç”¨æˆ·è¿‡æ»¤
	Boot     bool     `json:"boot"`     // å½“å‰å¯åŠ¨
	Kernel   bool     `json:"kernel"`   // å†…æ ¸æ¶ˆæ¯
}

var (
	logFormat        = flag.String("format", "java", "æ—¥å¿—æ ¼å¼ (java, php, nginx, ruby, fastapi, python, go, rust, csharp, kotlin, nodejs, typescript, docker, kubernetes, postgresql, mysql, redis, elasticsearch, git, jenkins, github, journald, macos-console, syslog)")
	verbose          = flag.Bool("verbose", false, "æ˜¾ç¤ºè¯¦ç»†è¾“å‡º")
	filePath         = flag.String("f", "", "è¦ç›‘æ§çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆç±»ä¼¼ tail -fï¼‰")
	debug            = flag.Bool("debug", false, "è°ƒè¯•æ¨¡å¼ï¼Œæ‰“å° HTTP è¯·æ±‚å’Œå“åº”è¯¦æƒ…")
	noBatch          = flag.Bool("no-batch", false, "ç¦ç”¨æ‰¹å¤„ç†ï¼Œé€è¡Œåˆ†æï¼ˆå¢åŠ  API è°ƒç”¨ï¼‰")
	batchSize        = flag.Int("batch-size", BATCH_MAX_SIZE, "æ‰¹å¤„ç†æœ€å¤§è¡Œæ•°")
	batchWait        = flag.Duration("batch-wait", BATCH_WAIT_TIME, "æ‰¹å¤„ç†ç­‰å¾…æ—¶é—´")
	showNotImportant = flag.Bool("show-not-important", false, "æ˜¾ç¤ºè¢«è¿‡æ»¤çš„æ—¥å¿—ï¼ˆé»˜è®¤ä¸æ˜¾ç¤ºï¼‰")
	contextLines     = flag.Int("context", 3, "é‡è¦æ—¥å¿—æ˜¾ç¤ºçš„ä¸Šä¸‹æ–‡è¡Œæ•°ï¼ˆå‰åå„Nè¡Œï¼‰")

	// æ–°å¢é…ç½®ç®¡ç†å‘½ä»¤
	configTest     = flag.Bool("config-test", false, "æµ‹è¯•é…ç½®æ–‡ä»¶")
	configValidate = flag.Bool("config-validate", false, "éªŒè¯é…ç½®æ–‡ä»¶")
	configShow     = flag.Bool("config-show", false, "æ˜¾ç¤ºå½“å‰é…ç½®")

	// AIæœåŠ¡ç®¡ç†å‘½ä»¤
	aiList  = flag.Bool("ai-list", false, "åˆ—å‡ºæ‰€æœ‰AIæœåŠ¡")
	aiTest  = flag.Bool("ai-test", false, "æµ‹è¯•æ‰€æœ‰AIæœåŠ¡")
	aiStats = flag.Bool("ai-stats", false, "æ˜¾ç¤ºAIæœåŠ¡ç»Ÿè®¡ä¿¡æ¯")

	// è§„åˆ™ç®¡ç†å‘½ä»¤
	ruleList    = flag.Bool("rule-list", false, "åˆ—å‡ºæ‰€æœ‰è¿‡æ»¤è§„åˆ™")
	ruleTest    = flag.String("rule-test", "", "æµ‹è¯•è§„åˆ™ (æ ¼å¼: rule_id,test_line)")
	ruleStats   = flag.Bool("rule-stats", false, "æ˜¾ç¤ºè§„åˆ™å¼•æ“ç»Ÿè®¡ä¿¡æ¯")
	ruleAdd     = flag.String("rule-add", "", "æ·»åŠ è§„åˆ™ (JSONæ ¼å¼)")
	ruleRemove  = flag.String("rule-remove", "", "åˆ é™¤è§„åˆ™ (è§„åˆ™ID)")
	ruleEnable  = flag.String("rule-enable", "", "å¯ç”¨è§„åˆ™ (è§„åˆ™ID)")
	ruleDisable = flag.String("rule-disable", "", "ç¦ç”¨è§„åˆ™ (è§„åˆ™ID)")

	// ç¼“å­˜ç®¡ç†å‘½ä»¤
	cacheStats = flag.Bool("cache-stats", false, "æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
	cacheClear = flag.Bool("cache-clear", false, "æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")
	cacheTest  = flag.Bool("cache-test", false, "æµ‹è¯•ç¼“å­˜åŠŸèƒ½")

	// å·¥ä½œæ± ç®¡ç†å‘½ä»¤
	workerStats      = flag.Bool("worker-stats", false, "æ˜¾ç¤ºå·¥ä½œæ± ç»Ÿè®¡ä¿¡æ¯")
	workerTest       = flag.Bool("worker-test", false, "æµ‹è¯•å·¥ä½œæ± åŠŸèƒ½")
	performanceStats = flag.Bool("perf-stats", false, "æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡")

	// å†…å­˜ç®¡ç†å‘½ä»¤
	memoryStats = flag.Bool("memory-stats", false, "æ˜¾ç¤ºå†…å­˜ç»Ÿè®¡ä¿¡æ¯")
	memoryTest  = flag.Bool("memory-test", false, "æµ‹è¯•å†…å­˜ç®¡ç†åŠŸèƒ½")
	memoryGC    = flag.Bool("memory-gc", false, "å¼ºåˆ¶åƒåœ¾å›æ”¶")

	// å¹¶å‘æ§åˆ¶å‘½ä»¤
	concurrencyStats = flag.Bool("concurrency-stats", false, "æ˜¾ç¤ºå¹¶å‘æ§åˆ¶ç»Ÿè®¡ä¿¡æ¯")
	concurrencyTest  = flag.Bool("concurrency-test", false, "æµ‹è¯•å¹¶å‘æ§åˆ¶åŠŸèƒ½")
	backpressureTest = flag.Bool("backpressure-test", false, "æµ‹è¯•èƒŒå‹æ§åˆ¶åŠŸèƒ½")

	// I/Oç®¡ç†å‘½ä»¤
	ioStats = flag.Bool("io-stats", false, "æ˜¾ç¤ºI/Oç»Ÿè®¡ä¿¡æ¯")
	ioTest  = flag.Bool("io-test", false, "æµ‹è¯•I/Oä¼˜åŒ–åŠŸèƒ½")
	ioFlush = flag.Bool("io-flush", false, "å¼ºåˆ¶åˆ·æ–°I/Oç¼“å†²åŒº")

	// ç”¨æˆ·ä½“éªŒå‘½ä»¤
	configInit     = flag.Bool("config-init", false, "å¯åŠ¨é…ç½®å‘å¯¼")
	configTemplate = flag.Bool("config-template", false, "æ˜¾ç¤ºé…ç½®æ¨¡æ¿")
	outputFormat   = flag.String("output-format", "", "è¾“å‡ºæ ¼å¼ (json, csv, table, custom)")
	outputColor    = flag.Bool("output-color", true, "å¯ç”¨é¢œè‰²è¾“å‡º")
	logLevel       = flag.String("log-level", "", "æ—¥å¿—çº§åˆ« (debug, info, warn, error, fatal)")

	// journalctl ç‰¹å®šé…ç½®
	journalServices = flag.String("journal-services", "", "ç›‘æ§çš„systemdæœåŠ¡åˆ—è¡¨ï¼Œé€—å·åˆ†éš” (å¦‚: nginx,docker,postgresql)")
	journalPriority = flag.String("journal-priority", "", "ç›‘æ§çš„æ—¥å¿—çº§åˆ« (emerg,alert,crit,err,warning,notice,info,debug)")
	journalSince    = flag.String("journal-since", "", "ç›‘æ§å¼€å§‹æ—¶é—´ (å¦‚: '1 hour ago', '2023-10-17 10:00:00')")
	journalUntil    = flag.String("journal-until", "", "ç›‘æ§ç»“æŸæ—¶é—´ (å¦‚: 'now', '2023-10-17 18:00:00')")
	journalUser     = flag.String("journal-user", "", "ç›‘æ§ç‰¹å®šç”¨æˆ·çš„æ—¥å¿—")
	journalBoot     = flag.Bool("journal-boot", false, "åªç›‘æ§å½“å‰å¯åŠ¨çš„æ—¥å¿—")
	journalKernel   = flag.Bool("journal-kernel", false, "åªç›‘æ§å†…æ ¸æ¶ˆæ¯")

	// å¤šæºç›‘æ§é…ç½®
	multiSource = flag.String("multi-source", "", "å¤šæºç›‘æ§é…ç½®æ–‡ä»¶è·¯å¾„")
	configFile  = flag.String("config", "", "æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„")

	// å…¨å±€å˜é‡ï¼šå½“å‰ç›‘æ§çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºé€šçŸ¥ï¼‰
	currentLogFile = "stdin"
)

// æ„å»ºjournalctlå‘½ä»¤
func buildJournalctlCommand() []string {
	args := []string{"journalctl", "-f", "--no-pager"}

	// æ·»åŠ æœåŠ¡è¿‡æ»¤
	if *journalServices != "" {
		services := strings.Split(*journalServices, ",")
		for _, service := range services {
			service = strings.TrimSpace(service)
			if service != "" {
				args = append(args, "-u", service)
			}
		}
	}

	// æ·»åŠ ä¼˜å…ˆçº§è¿‡æ»¤
	if *journalPriority != "" {
		args = append(args, "-p", *journalPriority)
	}

	// æ·»åŠ æ—¶é—´èŒƒå›´
	if *journalSince != "" {
		args = append(args, "--since", *journalSince)
	}
	if *journalUntil != "" {
		args = append(args, "--until", *journalUntil)
	}

	// æ·»åŠ ç”¨æˆ·è¿‡æ»¤
	if *journalUser != "" {
		args = append(args, "_UID="+*journalUser)
	}

	// æ·»åŠ å¯åŠ¨è¿‡æ»¤
	if *journalBoot {
		args = append(args, "-b")
	}

	// æ·»åŠ å†…æ ¸è¿‡æ»¤
	if *journalKernel {
		args = append(args, "-k")
	}

	return args
}

// æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨å¤šæºç›‘æ§
func shouldUseMultiSource() bool {
	// å¦‚æœæŒ‡å®šäº†å¤šæºé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨å¤šæºç›‘æ§
	if *multiSource != "" {
		return true
	}

	// æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¤šæºé…ç½®æ–‡ä»¶
	configPath, err := findMultiSourceConfig()
	if err != nil {
		return false
	}

	// æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(configPath); err == nil {
		if *verbose {
			log.Printf("ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°å¤šæºé…ç½®æ–‡ä»¶: %s", configPath)
		}
		return true
	}

	return false
}

func main() {
	flag.Parse()

	// åˆå§‹åŒ–é”™è¯¯å¤„ç†å™¨
	errorHandler = NewErrorHandler()
	errorHandler.RegisterStrategy(ErrorCategoryNetwork, &NetworkErrorRecovery{
		maxRetries: 3,
		backoff:    time.Second * 2,
	})
	errorHandler.RegisterStrategy(ErrorCategoryConfig, &ConfigErrorRecovery{
		fallbackConfig: &defaultConfig,
		validator:      NewConfigValidator(),
	})

	// å¤„ç†é…ç½®ç®¡ç†å‘½ä»¤
	if *configTest {
		handleConfigTest()
		return
	}

	if *configValidate {
		handleConfigValidate()
		return
	}

	if *configShow {
		handleConfigShow()
		return
	}

	if *aiList {
		handleAIList()
		return
	}

	if *aiTest {
		handleAITest()
		return
	}

	if *aiStats {
		handleAIStats()
		return
	}

	if *ruleList {
		handleRuleList()
		return
	}

	if *ruleTest != "" {
		handleRuleTest()
		return
	}

	if *ruleStats {
		handleRuleStats()
		return
	}

	if *ruleAdd != "" {
		handleRuleAdd()
		return
	}

	if *ruleRemove != "" {
		handleRuleRemove()
		return
	}

	if *ruleEnable != "" {
		handleRuleEnable()
		return
	}

	if *ruleDisable != "" {
		handleRuleDisable()
		return
	}

	if *cacheStats {
		handleCacheStats()
		return
	}

	if *cacheClear {
		handleCacheClear()
		return
	}

	if *cacheTest {
		handleCacheTest()
		return
	}

	if *workerStats {
		handleWorkerStats()
		return
	}

	if *workerTest {
		handleWorkerTest()
		return
	}

	if *performanceStats {
		handlePerformanceStats()
		return
	}

	if *memoryStats {
		handleMemoryStats()
		return
	}

	if *memoryTest {
		handleMemoryTest()
		return
	}

	if *memoryGC {
		handleMemoryGC()
		return
	}

	if *concurrencyStats {
		handleConcurrencyStats()
		return
	}

	if *concurrencyTest {
		handleConcurrencyTest()
		return
	}

	if *backpressureTest {
		handleBackpressureTest()
		return
	}

	if *ioStats {
		handleIOStats()
		return
	}

	if *ioTest {
		handleIOTest()
		return
	}

	if *ioFlush {
		handleIOFlush()
		return
	}

	if *configInit {
		handleConfigInit()
		return
	}

	if *configTemplate {
		handleConfigTemplate()
		return
	}

	// åŠ è½½é…ç½®æ–‡ä»¶
	if err := loadConfig(); err != nil {
		if handledErr := errorHandler.Handle(err, map[string]interface{}{
			"operation":   "load_config",
			"config_path": "~/.config/aipipe.json",
		}); handledErr != nil {
			log.Printf("âš ï¸  åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: %v", err)
			globalConfig = defaultConfig
		}
	}

	fmt.Printf("ğŸš€ AIPipe å¯åŠ¨ - ç›‘æ§ %s æ ¼å¼æ—¥å¿—\n", *logFormat)

	// æ˜¾ç¤ºæ¨¡å¼æç¤º
	if !*showNotImportant {
		fmt.Println("ğŸ’¡ åªæ˜¾ç¤ºé‡è¦æ—¥å¿—ï¼ˆè¿‡æ»¤çš„æ—¥å¿—ä¸æ˜¾ç¤ºï¼‰")
		if !*verbose {
			fmt.Println("   ä½¿ç”¨ --show-not-important æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—")
		}
	}

	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	if *filePath != "" {
		// æ–‡ä»¶ç›‘æ§æ¨¡å¼
		fmt.Printf("ğŸ“ ç›‘æ§æ–‡ä»¶: %s\n", *filePath)
		fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
		if err := watchFile(*filePath); err != nil {
			log.Fatalf("âŒ ç›‘æ§æ–‡ä»¶å¤±è´¥: %v", err)
		}
	} else {
		// æ ‡å‡†è¾“å…¥æ¨¡å¼
		fmt.Println("ğŸ“¥ ä»æ ‡å‡†è¾“å…¥è¯»å–æ—¥å¿—...")
		fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
		processStdin()
	}
}

// é…ç½®ç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// æµ‹è¯•é…ç½®æ–‡ä»¶
func handleConfigTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•é…ç½®æ–‡ä»¶...")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æµ‹è¯• AI æœåŠ¡è¿æ¥
	fmt.Println("ğŸ”— æµ‹è¯• AI æœåŠ¡è¿æ¥...")
	if err := testAIConnection(); err != nil {
		fmt.Printf("âŒ AI æœåŠ¡è¿æ¥å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	fmt.Println("âœ… é…ç½®æ–‡ä»¶æµ‹è¯•é€šè¿‡ï¼")
}

// éªŒè¯é…ç½®æ–‡ä»¶
func handleConfigValidate() {
	fmt.Println("ğŸ” éªŒè¯é…ç½®æ–‡ä»¶...")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®éªŒè¯å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	fmt.Println("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡ï¼")
}

// æ˜¾ç¤ºå½“å‰é…ç½®
func handleConfigShow() {
	fmt.Println("ğŸ“‹ å½“å‰é…ç½®:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æ˜¾ç¤ºé…ç½®ä¿¡æ¯ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰
	fmt.Printf("AI ç«¯ç‚¹: %s\n", globalConfig.AIEndpoint)
	fmt.Printf("æ¨¡å‹: %s\n", globalConfig.Model)
	fmt.Printf("Token: %s...%s\n", globalConfig.Token[:min(8, len(globalConfig.Token))], globalConfig.Token[max(0, len(globalConfig.Token)-8):])
	fmt.Printf("æœ€å¤§é‡è¯•æ¬¡æ•°: %d\n", globalConfig.MaxRetries)
	fmt.Printf("è¶…æ—¶æ—¶é—´: %d ç§’\n", globalConfig.Timeout)
	fmt.Printf("é¢‘ç‡é™åˆ¶: %d æ¬¡/åˆ†é’Ÿ\n", globalConfig.RateLimit)
	fmt.Printf("æœ¬åœ°è¿‡æ»¤: %t\n", globalConfig.LocalFilter)

	if globalConfig.CustomPrompt != "" {
		fmt.Printf("è‡ªå®šä¹‰æç¤ºè¯: %s\n", globalConfig.CustomPrompt)
	}
}

// AIæœåŠ¡ç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// åˆ—å‡ºæ‰€æœ‰AIæœåŠ¡
func handleAIList() {
	fmt.Println("ğŸ¤– AI æœåŠ¡åˆ—è¡¨:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	services := aiServiceManager.GetServices()
	if len(services) == 0 {
		fmt.Println("æ²¡æœ‰é…ç½®AIæœåŠ¡")
		return
	}

	for i, service := range services {
		status := "âŒ ç¦ç”¨"
		if service.Enabled {
			status = "âœ… å¯ç”¨"
		}

		fmt.Printf("%d. %s %s\n", i+1, status, service.Name)
		fmt.Printf("   ç«¯ç‚¹: %s\n", service.Endpoint)
		fmt.Printf("   æ¨¡å‹: %s\n", service.Model)
		fmt.Printf("   Token: %s...%s\n", service.Token[:min(8, len(service.Token))], service.Token[max(0, len(service.Token)-8):])
		fmt.Printf("   ä¼˜å…ˆçº§: %d\n", service.Priority)
		fmt.Println()
	}
}

// æµ‹è¯•æ‰€æœ‰AIæœåŠ¡
func handleAITest() {
	fmt.Println("ğŸ§ª æµ‹è¯•æ‰€æœ‰AIæœåŠ¡...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	services := aiServiceManager.GetServices()
	if len(services) == 0 {
		fmt.Println("æ²¡æœ‰é…ç½®AIæœåŠ¡")
		return
	}

	successCount := 0
	for _, service := range services {
		if !service.Enabled {
			fmt.Printf("â­ï¸  è·³è¿‡ç¦ç”¨çš„æœåŠ¡: %s\n", service.Name)
			continue
		}

		fmt.Printf("ğŸ”— æµ‹è¯•æœåŠ¡: %s...", service.Name)

		// åˆ›å»ºæµ‹è¯•è¯·æ±‚
		testPrompt := "è¯·å›å¤ 'OK' è¡¨ç¤ºè¿æ¥æ­£å¸¸"
		reqBody := ChatRequest{
			Model: service.Model,
			Messages: []ChatMessage{
				{
					Role:    "user",
					Content: testPrompt,
				},
			},
		}

		jsonData, err := json.Marshal(reqBody)
		if err != nil {
			fmt.Printf(" âŒ æ„å»ºè¯·æ±‚å¤±è´¥\n")
			continue
		}

		// åˆ›å»ºHTTPè¯·æ±‚
		req, err := http.NewRequest("POST", service.Endpoint, bytes.NewBuffer(jsonData))
		if err != nil {
			fmt.Printf(" âŒ åˆ›å»ºè¯·æ±‚å¤±è´¥\n")
			continue
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("api-key", service.Token)

		// å‘é€è¯·æ±‚
		client := &http.Client{
			Timeout: time.Duration(globalConfig.Timeout) * time.Second,
		}

		resp, err := client.Do(req)
		if err != nil {
			fmt.Printf(" âŒ è¯·æ±‚å¤±è´¥: %v\n", err)
			continue
		}
		defer resp.Body.Close()

		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			fmt.Printf(" âŒ APIé”™è¯¯ %d: %s\n", resp.StatusCode, string(body))
			continue
		}

		fmt.Printf(" âœ… æˆåŠŸ\n")
		successCount++
	}

	fmt.Printf("\nğŸ“Š æµ‹è¯•ç»“æœ: %d/%d æœåŠ¡å¯ç”¨\n", successCount, len(services))
	if successCount == 0 {
		os.Exit(1)
	}
}

// æ˜¾ç¤ºAIæœåŠ¡ç»Ÿè®¡ä¿¡æ¯
func handleAIStats() {
	fmt.Println("ğŸ“Š AI æœåŠ¡ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := aiServiceManager.GetStats()
	fmt.Printf("æ€»æœåŠ¡æ•°: %d\n", stats["total_services"])
	fmt.Printf("å¯ç”¨æœåŠ¡æ•°: %d\n", stats["enabled_services"])
	fmt.Printf("å½“å‰ç´¢å¼•: %d\n", stats["current_index"])
	fmt.Printf("æ•…éšœè½¬ç§»æ¨¡å¼: %t\n", stats["fallback_mode"])

	// æ˜¾ç¤ºæœåŠ¡è¯¦æƒ…
	services := aiServiceManager.GetServices()
	if len(services) > 0 {
		fmt.Println("\næœåŠ¡è¯¦æƒ…:")
		for _, service := range services {
			status := "âŒ ç¦ç”¨"
			if service.Enabled {
				status = "âœ… å¯ç”¨"
			}
			fmt.Printf("  %s %s (ä¼˜å…ˆçº§: %d)\n", status, service.Name, service.Priority)
		}
	}
}

// æµ‹è¯• AI æœåŠ¡è¿æ¥
func testAIConnection() error {
	// åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
	testPrompt := "è¯·å›å¤ 'OK' è¡¨ç¤ºè¿æ¥æ­£å¸¸"

	// æ„å»ºè¯·æ±‚
	reqBody := ChatRequest{
		Model: globalConfig.Model,
		Messages: []ChatMessage{
			{
				Role:    "user",
				Content: testPrompt,
			},
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return fmt.Errorf("æ„å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	// åˆ›å»º HTTP è¯·æ±‚
	req, err := http.NewRequest("POST", globalConfig.AIEndpoint, bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("api-key", globalConfig.Token)

	// å‘é€è¯·æ±‚
	client := &http.Client{
		Timeout: time.Duration(globalConfig.Timeout) * time.Second,
	}

	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("API è¿”å›é”™è¯¯çŠ¶æ€ç  %d: %s", resp.StatusCode, string(body))
	}

	return nil
}

// è¾…åŠ©å‡½æ•°
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

// åŠ è½½é…ç½®æ–‡ä»¶
// è‡ªåŠ¨æ£€æµ‹é»˜è®¤é…ç½®æ–‡ä»¶
func findDefaultConfig() (string, error) {
	configDir := filepath.Join(os.Getenv("HOME"), ".config")

	// æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥é…ç½®æ–‡ä»¶
	configFiles := []string{
		"aipipe.json",
		"aipipe.yaml",
		"aipipe.yml",
		"aipipe.toml",
	}

	for _, filename := range configFiles {
		configPath := filepath.Join(configDir, filename)
		if _, err := os.Stat(configPath); err == nil {
			if *verbose {
				log.Printf("ğŸ” æ‰¾åˆ°é»˜è®¤é…ç½®æ–‡ä»¶: %s", configPath)
			}
			return configPath, nil
		}
	}

	// æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é…ç½®æ–‡ä»¶ï¼Œè¿”å›é»˜è®¤è·¯å¾„
	defaultPath := filepath.Join(configDir, "aipipe.json")
	return defaultPath, nil
}

func loadConfig() error {
	var configPath string
	var err error

	// å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æŒ‡å®šçš„è·¯å¾„
	if *configFile != "" {
		configPath = *configFile
	} else {
		// å¦åˆ™æŸ¥æ‰¾é»˜è®¤é…ç½®æ–‡ä»¶
		configPath, err = findDefaultConfig()
		if err != nil {
			return fmt.Errorf("æŸ¥æ‰¾é»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
		}
	}

	// æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(configPath); os.IsNotExist(err) {
		// é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
		return createDefaultConfig(configPath)
	}

	// ä½¿ç”¨å¤šæ ¼å¼åŠ è½½
	if err := loadConfigWithFormat(configPath); err != nil {
		return err
	}

	// éªŒè¯å¿…è¦çš„é…ç½®é¡¹
	if globalConfig.AIEndpoint == "" {
		globalConfig.AIEndpoint = defaultConfig.AIEndpoint
	}
	if globalConfig.Token == "" {
		globalConfig.Token = defaultConfig.Token
	}
	if globalConfig.Model == "" {
		globalConfig.Model = defaultConfig.Model
	}

	// è®¾ç½®é»˜è®¤å€¼
	if globalConfig.MaxRetries == 0 {
		globalConfig.MaxRetries = defaultConfig.MaxRetries
	}
	if globalConfig.Timeout == 0 {
		globalConfig.Timeout = defaultConfig.Timeout
	}
	if globalConfig.RateLimit == 0 {
		globalConfig.RateLimit = defaultConfig.RateLimit
	}

	// åˆå§‹åŒ–AIæœåŠ¡ç®¡ç†å™¨
	if len(globalConfig.AIServices) > 0 {
		// ä½¿ç”¨æ–°çš„å¤šAIæœåŠ¡é…ç½®
		aiServiceManager = NewAIServiceManager(globalConfig.AIServices)
	} else {
		// å‘åå…¼å®¹ï¼šä½¿ç”¨æ—§çš„å•æœåŠ¡é…ç½®
		legacyService := AIService{
			Name:     "default",
			Endpoint: globalConfig.AIEndpoint,
			Token:    globalConfig.Token,
			Model:    globalConfig.Model,
			Priority: 1,
			Enabled:  true,
		}
		aiServiceManager = NewAIServiceManager([]AIService{legacyService})
	}

	// åˆå§‹åŒ–è§„åˆ™å¼•æ“
	ruleEngine = NewRuleEngine(globalConfig.Rules)

	// åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
	cacheManager = NewCacheManager(globalConfig.Cache)

	// åˆå§‹åŒ–å·¥ä½œæ± 
	workerPool = NewWorkerPool(globalConfig.WorkerPool)

	// åˆå§‹åŒ–å†…å­˜ç®¡ç†å™¨
	memoryManager = NewMemoryManager(globalConfig.Memory)

	// åˆå§‹åŒ–å¹¶å‘æ§åˆ¶å™¨
	concurrencyController = NewConcurrencyController(globalConfig.Concurrency)

	// åˆå§‹åŒ–I/Oä¼˜åŒ–å™¨
	ioOptimizer = NewIOOptimizer(globalConfig.IO)

	// éªŒè¯é…ç½®
	validator := NewConfigValidator()
	if err := validator.Validate(&globalConfig); err != nil {
		// æ˜¾ç¤ºè¯¦ç»†çš„éªŒè¯é”™è¯¯
		fmt.Printf("âŒ é…ç½®éªŒè¯å¤±è´¥:\n")
		for _, validationErr := range validator.GetErrors() {
			fmt.Printf("  â€¢ %s: %s (å½“å‰å€¼: %s)\n", validationErr.Field, validationErr.Message, validationErr.Value)
		}
		return fmt.Errorf("é…ç½®éªŒè¯å¤±è´¥: %w", err)
	}

	if *verbose {
		fmt.Printf("âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: %s\n", configPath)
		fmt.Printf("   AI ç«¯ç‚¹: %s\n", globalConfig.AIEndpoint)
		fmt.Printf("   æ¨¡å‹: %s\n", globalConfig.Model)
		if globalConfig.CustomPrompt != "" {
			fmt.Printf("   è‡ªå®šä¹‰æç¤ºè¯: %s\n", globalConfig.CustomPrompt)
		}
	}

	return nil
}

// åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
func createDefaultConfig(configPath string) error {
	// ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
	configDir := filepath.Dir(configPath)
	if err := os.MkdirAll(configDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºé…ç½®ç›®å½•å¤±è´¥: %w", err)
	}

	// åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
	data, err := json.MarshalIndent(defaultConfig, "", "  ")
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–é»˜è®¤é…ç½®å¤±è´¥: %w", err)
	}

	if err := os.WriteFile(configPath, data, 0644); err != nil {
		return fmt.Errorf("å†™å…¥é»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	fmt.Printf("ğŸ“ å·²åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶: %s\n", configPath)
	fmt.Println("   è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶è®¾ç½®æ‚¨çš„ AI æœåŠ¡å™¨ç«¯ç‚¹å’Œ Token")

	globalConfig = defaultConfig
	return nil
}

// ä»æ ‡å‡†è¾“å…¥å¤„ç†æ—¥å¿—
func processStdin() {
	if *noBatch {
		// ç¦ç”¨æ‰¹å¤„ç†ï¼Œé€è¡Œå¤„ç†
		processStdinLineByLine()
		return
	}

	// ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼
	processStdinWithBatch()
}

// é€è¡Œå¤„ç†ï¼ˆåŸå§‹æ–¹å¼ï¼‰
func processStdinLineByLine() {
	scanner := bufio.NewScanner(os.Stdin)
	scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

	lineCount := 0
	filteredCount := 0
	alertCount := 0

	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(*logFormat)

	for scanner.Scan() {
		line := scanner.Text()
		lineCount++

		if strings.TrimSpace(line) == "" {
			continue
		}

		// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
		completeLine, hasComplete := merger.Add(line)
		if hasComplete {
			filtered, alerted := processLogLine(completeLine)
			if filtered {
				filteredCount++
			}
			if alerted {
				alertCount++
			}
		}
	}

	// åˆ·æ–°æœ€åçš„ç¼“å†²
	if lastLine, hasLast := merger.Flush(); hasLast {
		filtered, alerted := processLogLine(lastLine)
		if filtered {
			filteredCount++
		}
		if alerted {
			alertCount++
		}
	}

	if err := scanner.Err(); err != nil {
		log.Fatalf("è¯»å–è¾“å…¥å¤±è´¥: %v", err)
	}

	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Printf("ğŸ“Š ç»Ÿè®¡: æ€»è®¡ %d è¡Œ, è¿‡æ»¤ %d è¡Œ, å‘Šè­¦ %d æ¬¡\n", lineCount, filteredCount, alertCount)
}

// å¤„ç†journalctlå‘½ä»¤
func processJournalctl() {
	// æ„å»ºjournalctlå‘½ä»¤
	args := buildJournalctlCommand()

	// æ˜¾ç¤ºä½¿ç”¨çš„å‘½ä»¤
	fmt.Printf("ğŸ”§ æ‰§è¡Œå‘½ä»¤: %s\n", strings.Join(args, " "))
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åˆ›å»ºå‘½ä»¤
	cmd := exec.Command(args[0], args[1:]...)
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr

	// åˆ›å»ºç®¡é“
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		log.Fatalf("âŒ åˆ›å»ºç®¡é“å¤±è´¥: %v", err)
	}

	// å¯åŠ¨å‘½ä»¤
	if err := cmd.Start(); err != nil {
		log.Fatalf("âŒ å¯åŠ¨journalctlå¤±è´¥: %v", err)
	}

	// å¤„ç†è¾“å‡º
	scanner := bufio.NewScanner(stdout)
	scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

	lineCount := 0
	filteredCount := 0
	alertCount := 0
	batchCount := 0

	// åˆ›å»ºæ‰¹å¤„ç†å™¨
	batcher := NewLogBatcher(func(lines []string) {
		batchCount++
		if *verbose || *debug {
			log.Printf("ğŸ“¦ æ‰¹æ¬¡ #%d: å¤„ç† %d è¡Œæ—¥å¿—", batchCount, len(lines))
		}

		filtered, alerted := processBatch(lines)
		filteredCount += filtered
		alertCount += alerted
	})

	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(*logFormat)

	// è¯»å–æ—¥å¿—è¡Œ
	for scanner.Scan() {
		line := scanner.Text()
		lineCount++

		if strings.TrimSpace(line) == "" {
			continue
		}

		// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
		completeLine, hasComplete := merger.Add(line)
		if hasComplete {
			// æ·»åŠ åˆ°æ‰¹å¤„ç†å™¨
			batcher.Add(completeLine)
		}
	}

	// åˆ·æ–°æœ€åçš„ç¼“å†²
	if lastLine, hasLast := merger.Flush(); hasLast {
		batcher.Add(lastLine)
	}

	if err := scanner.Err(); err != nil {
		log.Printf("âŒ è¯»å–journalctlè¾“å‡ºå¤±è´¥: %v", err)
	}

	// åˆ·æ–°å‰©ä½™çš„æ—¥å¿—
	batcher.Flush()

	// ç­‰å¾…å‘½ä»¤ç»“æŸ
	cmd.Wait()

	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Printf("ğŸ“Š ç»Ÿè®¡: æ€»è®¡ %d è¡Œ, è¿‡æ»¤ %d è¡Œ, å‘Šè­¦ %d æ¬¡, æ‰¹æ¬¡ %d ä¸ª\n", lineCount, filteredCount, alertCount, batchCount)
}

// è‡ªåŠ¨æ£€æµ‹å¤šæºé…ç½®æ–‡ä»¶
func findMultiSourceConfig() (string, error) {
	configDir := filepath.Join(os.Getenv("HOME"), ".config")

	// æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥å¤šæºé…ç½®æ–‡ä»¶
	configFiles := []string{
		"aipipe-sources.json",
		"aipipe-sources.yaml",
		"aipipe-sources.yml",
		"aipipe-sources.toml",
		"aipipe-multi.json",
		"aipipe-multi.yaml",
		"aipipe-multi.yml",
		"aipipe-multi.toml",
	}

	for _, filename := range configFiles {
		configPath := filepath.Join(configDir, filename)
		if _, err := os.Stat(configPath); err == nil {
			if *verbose {
				log.Printf("ğŸ” æ‰¾åˆ°å¤šæºé…ç½®æ–‡ä»¶: %s", configPath)
			}
			return configPath, nil
		}
	}

	// æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é…ç½®æ–‡ä»¶ï¼Œè¿”å›é»˜è®¤è·¯å¾„
	defaultPath := filepath.Join(configDir, "aipipe-sources.json")
	return defaultPath, nil
}

// å¤„ç†å¤šæºç›‘æ§
func processMultiSource() {
	var configPath string
	var err error

	if *multiSource != "" {
		// ä½¿ç”¨æŒ‡å®šçš„é…ç½®æ–‡ä»¶
		configPath = *multiSource
	} else {
		// è‡ªåŠ¨æ£€æµ‹å¤šæºé…ç½®æ–‡ä»¶
		configPath, err = findMultiSourceConfig()
		if err != nil {
			log.Fatalf("âŒ æŸ¥æ‰¾å¤šæºé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
		}
	}

	// åŠ è½½å¤šæºé…ç½®æ–‡ä»¶
	config, err := loadMultiSourceConfig(configPath)
	if err != nil {
		log.Fatalf("âŒ åŠ è½½å¤šæºé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// åŠ è½½ä¸»é…ç½®æ–‡ä»¶
	if err := loadConfig(); err != nil {
		log.Printf("âš ï¸  åŠ è½½ä¸»é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: %v", err)
		globalConfig = defaultConfig
	}

	fmt.Printf("ğŸš€ AIPipe å¤šæºç›‘æ§å¯åŠ¨ - ç›‘æ§ %d ä¸ªæº\n", len(config.Sources))
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// æ˜¾ç¤ºå¯ç”¨çš„æº
	enabledSources := 0
	for _, source := range config.Sources {
		if source.Enabled {
			enabledSources++
			fmt.Printf("ğŸ“¡ æº: %s (%s) - %s\n", source.Name, source.Type, source.Description)
		}
	}

	if enabledSources == 0 {
		log.Fatalf("âŒ æ²¡æœ‰å¯ç”¨çš„ç›‘æ§æº")
	}

	fmt.Printf("âœ… å¯ç”¨ %d ä¸ªç›‘æ§æº\n", enabledSources)
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åˆ›å»ºç­‰å¾…ç»„
	var wg sync.WaitGroup
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// å¯åŠ¨æ¯ä¸ªç›‘æ§æº
	for _, source := range config.Sources {
		if !source.Enabled {
			continue
		}

		wg.Add(1)
		go func(src SourceConfig) {
			defer wg.Done()
			monitorSource(ctx, src)
		}(source)
	}

	// ç­‰å¾…æ‰€æœ‰ç›‘æ§æºå®Œæˆ
	wg.Wait()
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Println("ğŸ“Š å¤šæºç›‘æ§å®Œæˆ")
}

// ç›‘æ§å•ä¸ªæº
func monitorSource(ctx context.Context, source SourceConfig) {
	defer func() {
		if r := recover(); r != nil {
			log.Printf("âŒ æº %s ç›‘æ§panicæ¢å¤: %v", source.Name, r)
		}
	}()

	fmt.Printf("ğŸ” å¯åŠ¨ç›‘æ§æº: %s (%s)\n", source.Name, source.Type)

	switch source.Type {
	case "file":
		monitorFileSource(ctx, source)
	case "journalctl":
		monitorJournalSource(ctx, source)
	case "stdin":
		monitorStdinSource(ctx, source)
	default:
		log.Printf("âŒ ä¸æ”¯æŒçš„æºç±»å‹: %s", source.Type)
	}
}

// ç›‘æ§æ–‡ä»¶æº
func monitorFileSource(ctx context.Context, source SourceConfig) {
	if source.Path == "" {
		log.Printf("âŒ æº %s ç¼ºå°‘æ–‡ä»¶è·¯å¾„", source.Name)
		return
	}

	// è®¾ç½®å½“å‰æ—¥å¿—æ–‡ä»¶è·¯å¾„
	currentLogFile = source.Path

	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(source.Format)

	// åˆ›å»ºæ‰¹å¤„ç†å™¨
	batcher := NewLogBatcher(func(lines []string) {
		processBatch(lines)
	})

	// å¯åŠ¨æ–‡ä»¶ç›‘æ§ï¼ˆéé˜»å¡ï¼‰
	watchFileWithContext(ctx, source.Path, merger, batcher)

	// ç­‰å¾…contextå–æ¶ˆï¼Œä¿æŒgoroutineè¿è¡Œ
	<-ctx.Done()
	log.Printf("ğŸ” ç›‘æ§æºå·²åœæ­¢: %s", source.Name)
}

// ç›‘æ§journalctlæº
func monitorJournalSource(ctx context.Context, source SourceConfig) {
	if source.Journal == nil {
		log.Printf("âŒ æº %s ç¼ºå°‘journalctlé…ç½®", source.Name)
		return
	}

	// æ„å»ºjournalctlå‘½ä»¤
	args := buildJournalctlCommandFromConfig(source.Journal)

	// åˆ›å»ºå‘½ä»¤
	cmd := exec.CommandContext(ctx, args[0], args[1:]...)

	// åˆ›å»ºç®¡é“
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		log.Printf("âŒ æº %s åˆ›å»ºç®¡é“å¤±è´¥: %v", source.Name, err)
		return
	}

	// å¯åŠ¨å‘½ä»¤
	if err := cmd.Start(); err != nil {
		log.Printf("âŒ æº %s å¯åŠ¨journalctlå¤±è´¥: %v", source.Name, err)
		return
	}

	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(source.Format)

	// åˆ›å»ºæ‰¹å¤„ç†å™¨
	batcher := NewLogBatcher(func(lines []string) {
		processBatch(lines)
	})

	// å¤„ç†è¾“å‡º
	scanner := bufio.NewScanner(stdout)
	scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

	for scanner.Scan() {
		select {
		case <-ctx.Done():
			return
		default:
		}

		line := scanner.Text()
		if strings.TrimSpace(line) == "" {
			continue
		}

		// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
		completeLine, hasComplete := merger.Add(line)
		if hasComplete {
			batcher.Add(completeLine)
		}
	}

	// åˆ·æ–°æœ€åçš„ç¼“å†²
	if lastLine, hasLast := merger.Flush(); hasLast {
		batcher.Add(lastLine)
	}

	// åˆ·æ–°å‰©ä½™çš„æ—¥å¿—
	batcher.Flush()

	// ç­‰å¾…å‘½ä»¤ç»“æŸ
	cmd.Wait()
}

// ç›‘æ§stdinæº
func monitorStdinSource(ctx context.Context, source SourceConfig) {
	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(source.Format)

	// åˆ›å»ºæ‰¹å¤„ç†å™¨
	batcher := NewLogBatcher(func(lines []string) {
		processBatch(lines)
	})

	// å¤„ç†æ ‡å‡†è¾“å…¥
	scanner := bufio.NewScanner(os.Stdin)
	scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

	for scanner.Scan() {
		select {
		case <-ctx.Done():
			return
		default:
		}

		line := scanner.Text()
		if strings.TrimSpace(line) == "" {
			continue
		}

		// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
		completeLine, hasComplete := merger.Add(line)
		if hasComplete {
			batcher.Add(completeLine)
		}
	}

	// åˆ·æ–°æœ€åçš„ç¼“å†²
	if lastLine, hasLast := merger.Flush(); hasLast {
		batcher.Add(lastLine)
	}

	// åˆ·æ–°å‰©ä½™çš„æ—¥å¿—
	batcher.Flush()
}

// ä»é…ç½®æ„å»ºjournalctlå‘½ä»¤
func buildJournalctlCommandFromConfig(journal *JournalConfig) []string {
	args := []string{"journalctl", "-f", "--no-pager"}

	// æ·»åŠ æœåŠ¡è¿‡æ»¤
	if len(journal.Services) > 0 {
		for _, service := range journal.Services {
			service = strings.TrimSpace(service)
			if service != "" {
				args = append(args, "-u", service)
			}
		}
	}

	// æ·»åŠ ä¼˜å…ˆçº§è¿‡æ»¤
	if journal.Priority != "" {
		args = append(args, "-p", journal.Priority)
	}

	// æ·»åŠ æ—¶é—´èŒƒå›´
	if journal.Since != "" {
		args = append(args, "--since", journal.Since)
	}
	if journal.Until != "" {
		args = append(args, "--until", journal.Until)
	}

	// æ·»åŠ ç”¨æˆ·è¿‡æ»¤
	if journal.User != "" {
		args = append(args, "_UID="+journal.User)
	}

	// æ·»åŠ å¯åŠ¨è¿‡æ»¤
	if journal.Boot {
		args = append(args, "-b")
	}

	// æ·»åŠ å†…æ ¸è¿‡æ»¤
	if journal.Kernel {
		args = append(args, "-k")
	}

	return args
}

// é…ç½®æ–‡ä»¶æ ¼å¼æ£€æµ‹
func detectConfigFormat(filePath string) string {
	ext := strings.ToLower(filepath.Ext(filePath))
	switch ext {
	case ".json":
		return "json"
	case ".yaml", ".yml":
		return "yaml"
	case ".toml":
		return "toml"
	default:
		// å°è¯•è¯»å–æ–‡ä»¶å†…å®¹æ¥æ£€æµ‹æ ¼å¼
		data, err := os.ReadFile(filePath)
		if err != nil {
			return "json" // é»˜è®¤æ ¼å¼
		}

		// æ£€æµ‹JSONæ ¼å¼
		var jsonTest interface{}
		if json.Unmarshal(data, &jsonTest) == nil {
			return "json"
		}

		// æ£€æµ‹YAMLæ ¼å¼
		var yamlTest interface{}
		if yaml.Unmarshal(data, &yamlTest) == nil {
			return "yaml"
		}

		// æ£€æµ‹TOMLæ ¼å¼
		var tomlTest interface{}
		if _, err := toml.Decode(string(data), &tomlTest); err == nil {
			return "toml"
		}

		return "json" // é»˜è®¤æ ¼å¼
	}
}

// è§£æé…ç½®æ–‡ä»¶
func parseConfigFile(data []byte, format string, target interface{}) error {
	switch format {
	case "json":
		return json.Unmarshal(data, target)
	case "yaml":
		return yaml.Unmarshal(data, target)
	case "toml":
		_, err := toml.Decode(string(data), target)
		return err
	default:
		return fmt.Errorf("ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: %s", format)
	}
}

// åŠ è½½å¤šæºé…ç½®æ–‡ä»¶
func loadMultiSourceConfig(configPath string) (*MultiSourceConfig, error) {
	data, err := os.ReadFile(configPath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// è‡ªåŠ¨æ£€æµ‹é…ç½®æ–‡ä»¶æ ¼å¼
	format := detectConfigFormat(configPath)
	if *verbose {
		log.Printf("ğŸ” æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶æ ¼å¼: %s", format)
	}

	var config MultiSourceConfig
	if err := parseConfigFile(data, format, &config); err != nil {
		return nil, fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥ (%sæ ¼å¼): %v", format, err)
	}

	return &config, nil
}

// åŠ è½½ä¸»é…ç½®æ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
func loadConfigWithFormat(configPath string) error {
	data, err := os.ReadFile(configPath)
	if err != nil {
		return fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// è‡ªåŠ¨æ£€æµ‹é…ç½®æ–‡ä»¶æ ¼å¼
	format := detectConfigFormat(configPath)
	if *verbose {
		log.Printf("ğŸ” æ£€æµ‹åˆ°ä¸»é…ç½®æ–‡ä»¶æ ¼å¼: %s", format)
	}

	if err := parseConfigFile(data, format, &globalConfig); err != nil {
		return fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥ (%sæ ¼å¼): %v", format, err)
	}

	return nil
}

// å¸¦ä¸Šä¸‹æ–‡çš„æ–‡ä»¶ç›‘æ§
func watchFileWithContext(ctx context.Context, filePath string, merger *LogLineMerger, batcher *LogBatcher) {
	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		log.Printf("âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç­‰å¾…åˆ›å»º: %s", filePath)
		// ç­‰å¾…æ–‡ä»¶åˆ›å»ºï¼Œæ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				if _, err := os.Stat(filePath); err == nil {
					log.Printf("âœ… æ–‡ä»¶å·²åˆ›å»º: %s", filePath)
					break
				}
			}
		}
	}

	// å¯åŠ¨æ–‡ä»¶ç›‘æ§goroutine
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("âŒ æ–‡ä»¶ç›‘æ§panicæ¢å¤: %v", r)
			}
		}()

		// ä½¿ç”¨fsnotifyç›‘æ§æ–‡ä»¶
		watcher, err := fsnotify.NewWatcher()
		if err != nil {
			log.Printf("âŒ åˆ›å»ºæ–‡ä»¶ç›‘æ§å™¨å¤±è´¥: %v", err)
			return
		}
		defer watcher.Close()

		// ç›‘æ§æ–‡ä»¶ç›®å½•
		dir := filepath.Dir(filePath)
		if err := watcher.Add(dir); err != nil {
			log.Printf("âŒ æ·»åŠ ç›®å½•ç›‘æ§å¤±è´¥: %v", err)
			return
		}

		// è¯»å–åˆå§‹æ–‡ä»¶å†…å®¹
		file, err := os.Open(filePath)
		if err != nil {
			log.Printf("âŒ æ‰“å¼€æ–‡ä»¶å¤±è´¥: %v", err)
			return
		}
		defer file.Close()

		// å®šä½åˆ°æ–‡ä»¶æœ«å°¾
		file.Seek(0, io.SeekEnd)

		// è¯»å–æ–‡ä»¶å†…å®¹
		scanner := bufio.NewScanner(file)
		scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

		for scanner.Scan() {
			select {
			case <-ctx.Done():
				return
			default:
			}

			line := scanner.Text()
			if strings.TrimSpace(line) == "" {
				continue
			}

			// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
			completeLine, hasComplete := merger.Add(line)
			if hasComplete {
				batcher.Add(completeLine)
			}
		}

		// åˆ·æ–°æœ€åçš„ç¼“å†²
		if lastLine, hasLast := merger.Flush(); hasLast {
			batcher.Add(lastLine)
		}

		// ç›‘æ§æ–‡ä»¶å˜åŒ–
		for {
			select {
			case <-ctx.Done():
				return
			case event, ok := <-watcher.Events:
				if !ok {
					return
				}

				// æ–‡ä»¶å†™å…¥äº‹ä»¶
				if event.Op&fsnotify.Write == fsnotify.Write {
					if event.Name == filePath {
						// è¯»å–æ–°å†…å®¹
						file, err := os.Open(filePath)
						if err != nil {
							continue
						}

						// å®šä½åˆ°æ–‡ä»¶æœ«å°¾
						file.Seek(0, io.SeekEnd)

						scanner := bufio.NewScanner(file)
						scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

						for scanner.Scan() {
							line := scanner.Text()
							if strings.TrimSpace(line) == "" {
								continue
							}

							completeLine, hasComplete := merger.Add(line)
							if hasComplete {
								batcher.Add(completeLine)
							}
						}

						file.Close()
					}
				}
			case err, ok := <-watcher.Errors:
				if !ok {
					return
				}
				log.Printf("âš ï¸  æ–‡ä»¶ç›‘æ§é”™è¯¯: %v", err)
			}
		}
	}()

	// å‡½æ•°ç«‹å³è¿”å›ï¼Œgoroutineç»§ç»­åœ¨åå°è¿è¡Œ
}

// æ‰¹å¤„ç†æ¨¡å¼å¤„ç†æ ‡å‡†è¾“å…¥
func processStdinWithBatch() {
	scanner := bufio.NewScanner(os.Stdin)
	scanner.Buffer(make([]byte, 1024*1024), 1024*1024)

	lineCount := 0
	filteredCount := 0
	alertCount := 0
	batchCount := 0

	// åˆ›å»ºæ‰¹å¤„ç†å™¨
	batcher := NewLogBatcher(func(lines []string) {
		batchCount++
		if *verbose || *debug {
			log.Printf("ğŸ“¦ æ‰¹æ¬¡ #%d: å¤„ç† %d è¡Œæ—¥å¿—", batchCount, len(lines))
		}

		filtered, alerted := processBatch(lines)
		filteredCount += filtered
		alertCount += alerted
	})

	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(*logFormat)

	// è¯»å–æ—¥å¿—è¡Œ
	for scanner.Scan() {
		line := scanner.Text()
		lineCount++

		if strings.TrimSpace(line) == "" {
			continue
		}

		// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
		completeLine, hasComplete := merger.Add(line)
		if hasComplete {
			// æ·»åŠ åˆ°æ‰¹å¤„ç†å™¨
			batcher.Add(completeLine)
		}
	}

	// åˆ·æ–°æœ€åçš„ç¼“å†²
	if lastLine, hasLast := merger.Flush(); hasLast {
		batcher.Add(lastLine)
	}

	if err := scanner.Err(); err != nil {
		log.Fatalf("è¯»å–è¾“å…¥å¤±è´¥: %v", err)
	}

	// åˆ·æ–°å‰©ä½™çš„æ—¥å¿—
	batcher.Flush()

	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	fmt.Printf("ğŸ“Š ç»Ÿè®¡: æ€»è®¡ %d è¡Œ, è¿‡æ»¤ %d è¡Œ, å‘Šè­¦ %d æ¬¡, æ‰¹æ¬¡ %d ä¸ª\n", lineCount, filteredCount, alertCount, batchCount)
}

// åˆ›å»ºæ—¥å¿—æ‰¹å¤„ç†å™¨
func NewLogBatcher(processor func([]string)) *LogBatcher {
	batcher := &LogBatcher{
		lines:     make([]string, 0, *batchSize),
		processor: processor,
	}
	return batcher
}

// æ·»åŠ æ—¥å¿—åˆ°æ‰¹å¤„ç†å™¨
func (b *LogBatcher) Add(line string) {
	b.mu.Lock()
	defer b.mu.Unlock()

	b.lines = append(b.lines, line)

	// å¦‚æœè¾¾åˆ°æ‰¹å¤„ç†å¤§å°ï¼Œç«‹å³å¤„ç†
	if len(b.lines) >= *batchSize {
		b.flush()
		return
	}

	// é‡ç½®å®šæ—¶å™¨
	if b.timer != nil {
		b.timer.Stop()
	}
	b.timer = time.AfterFunc(*batchWait, func() {
		b.mu.Lock()
		defer b.mu.Unlock()
		b.flush()
	})
}

// åˆ·æ–°æ‰¹å¤„ç†å™¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œä¸åŠ é”ï¼‰
func (b *LogBatcher) flush() {
	if len(b.lines) == 0 {
		return
	}

	// å¤„ç†å½“å‰æ‰¹æ¬¡
	b.processor(b.lines)

	// æ¸…ç©ºæ‰¹æ¬¡
	b.lines = make([]string, 0, *batchSize)
	if b.timer != nil {
		b.timer.Stop()
		b.timer = nil
	}
}

// åˆ·æ–°æ‰¹å¤„ç†å™¨ï¼ˆå…¬å…±æ–¹æ³•ï¼ŒåŠ é”ï¼‰
func (b *LogBatcher) Flush() {
	b.mu.Lock()
	defer b.mu.Unlock()
	b.flush()
}

// å¤„ç†ä¸€æ‰¹æ—¥å¿—
func processBatch(lines []string) (filtered int, alerted int) {
	if len(lines) == 0 {
		return 0, 0
	}

	// å…ˆè¿›è¡Œæœ¬åœ°é¢„è¿‡æ»¤
	needAIAnalysis := make([]string, 0)
	localFiltered := make(map[int]*LogAnalysis) // ç´¢å¼• -> æœ¬åœ°åˆ†æç»“æœ

	for i, line := range lines {
		if localAnalysis := tryLocalFilter(line); localAnalysis != nil {
			localFiltered[i] = localAnalysis
			filtered++
		} else {
			needAIAnalysis = append(needAIAnalysis, line)
		}
	}

	// å¦‚æœæœ‰éœ€è¦ AI åˆ†æçš„æ—¥å¿—ï¼Œæ‰¹é‡è°ƒç”¨
	var aiResults map[int]*LogAnalysis
	if len(needAIAnalysis) > 0 {
		batchAnalysis, err := analyzeBatchLogs(needAIAnalysis, *logFormat)
		if err != nil {
			if *verbose {
				log.Printf("âŒ æ‰¹é‡åˆ†æå¤±è´¥: %v", err)
			}
			// å¤±è´¥æ—¶é€è¡Œå¤„ç†
			for _, line := range needAIAnalysis {
				f, a := processLogLine(line)
				if f {
					filtered++
				}
				if a {
					alerted++
				}
			}
			return filtered, alerted
		}

		// æ„å»º AI ç»“æœæ˜ å°„
		aiResults = make(map[int]*LogAnalysis)
		aiIndex := 0
		for i := range lines {
			if _, isLocal := localFiltered[i]; !isLocal {
				if aiIndex < len(batchAnalysis.Results) {
					aiResults[i] = &batchAnalysis.Results[aiIndex]
					aiIndex++
				}
			}
		}

		// æ˜¾ç¤ºæ•´ä½“æ‘˜è¦
		if batchAnalysis.ImportantCount > 0 {
			fmt.Printf("\nğŸ“‹ æ‰¹æ¬¡æ‘˜è¦: %s (é‡è¦æ—¥å¿—: %d æ¡)\n\n",
				batchAnalysis.OverallSummary, batchAnalysis.ImportantCount)
		}
	}

	// ç¬¬ä¸€æ­¥ï¼šæ ‡è®°é‡è¦æ—¥å¿—çš„ç´¢å¼•
	importantIndices := make(map[int]bool)
	importantLogs := make([]string, 0)

	for i, line := range lines {
		var analysis *LogAnalysis
		if localResult, ok := localFiltered[i]; ok {
			analysis = localResult
		} else if aiResult, ok := aiResults[i]; ok {
			analysis = aiResult
		} else {
			analysis = &LogAnalysis{
				ShouldFilter: true,
				Summary:      "æ— åˆ†æç»“æœ",
				Reason:       "æ‰¹é‡åˆ†æå¤±è´¥æˆ–ç»“æœç¼ºå¤±",
			}
		}

		if !analysis.ShouldFilter {
			importantIndices[i] = true
			importantLogs = append(importantLogs, line)
			alerted++
		} else {
			filtered++
		}
	}

	// ç¬¬äºŒæ­¥ï¼šè®¡ç®—éœ€è¦æ˜¾ç¤ºçš„è¡Œï¼ˆé‡è¦è¡Œ + ä¸Šä¸‹æ–‡ï¼‰
	shouldDisplay := make(map[int]bool)
	for i := range importantIndices {
		// æ˜¾ç¤ºé‡è¦è¡Œæœ¬èº«
		shouldDisplay[i] = true

		// æ˜¾ç¤ºå‰é¢çš„ä¸Šä¸‹æ–‡
		for j := i - *contextLines; j < i; j++ {
			if j >= 0 {
				shouldDisplay[j] = true
			}
		}

		// æ˜¾ç¤ºåé¢çš„ä¸Šä¸‹æ–‡
		for j := i + 1; j <= i+*contextLines; j++ {
			if j < len(lines) {
				shouldDisplay[j] = true
			}
		}
	}

	// ç¬¬ä¸‰æ­¥ï¼šè¾“å‡ºæ—¥å¿—ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
	lastDisplayed := -10 // ä¸Šæ¬¡æ˜¾ç¤ºçš„è¡Œå·
	for i, line := range lines {
		var analysis *LogAnalysis
		if localResult, ok := localFiltered[i]; ok {
			analysis = localResult
		} else if aiResult, ok := aiResults[i]; ok {
			analysis = aiResult
		} else {
			analysis = &LogAnalysis{
				ShouldFilter: true,
				Summary:      "æ— åˆ†æç»“æœ",
			}
		}

		// åˆ¤æ–­æ˜¯å¦åº”è¯¥æ˜¾ç¤ºè¿™è¡Œ
		if !shouldDisplay[i] && !*showNotImportant {
			continue // ä¸æ˜¾ç¤º
		}

		// å¦‚æœè·ç¦»ä¸Šæ¬¡æ˜¾ç¤ºçš„è¡Œè¾ƒè¿œï¼Œæ’å…¥åˆ†éš”ç¬¦
		if i > lastDisplayed+1 && lastDisplayed >= 0 {
			fmt.Println("   ...")
		}

		// æ˜¾ç¤ºæ—¥å¿—
		isImportant := importantIndices[i]
		isContext := shouldDisplay[i] && !isImportant

		if isImportant {
			fmt.Printf("âš ï¸  [é‡è¦] %s\n", line)
		} else if isContext {
			fmt.Printf("   â”‚ %s\n", line) // ä¸Šä¸‹æ–‡è¡Œç”¨ â”‚ æ ‡è®°
		} else if *showNotImportant {
			fmt.Printf("ğŸ”‡ [è¿‡æ»¤] %s\n", line)
			if *verbose && analysis.Reason != "" {
				fmt.Printf("   åŸå› : %s\n", analysis.Reason)
			}
		}

		lastDisplayed = i
	}

	// å¦‚æœæœ‰é‡è¦æ—¥å¿—ï¼Œå‘é€ä¸€æ¬¡æ‰¹é‡é€šçŸ¥
	if len(importantLogs) > 0 {
		// æ”¶é›†æ‰€æœ‰é‡è¦æ—¥å¿—çš„æ‘˜è¦
		summaries := make([]string, 0)
		for _, result := range aiResults {
			if result != nil && !result.ShouldFilter && result.Summary != "" {
				summaries = append(summaries, result.Summary)
			}
		}

		// æ„å»ºæ‰¹é‡é€šçŸ¥æ‘˜è¦
		var notifySummary string
		if len(summaries) > 0 {
			if len(summaries) == 1 {
				notifySummary = summaries[0]
			} else if len(summaries) <= 3 {
				notifySummary = strings.Join(summaries, "ã€")
			} else {
				notifySummary = fmt.Sprintf("%s ç­‰ %d ä¸ªé—®é¢˜", strings.Join(summaries[:2], "ã€"), len(summaries))
			}
		} else {
			notifySummary = fmt.Sprintf("å‘ç° %d æ¡é‡è¦æ—¥å¿—", len(importantLogs))
		}

		// æ„å»ºé€šçŸ¥å†…å®¹ï¼ˆæä¾›æ›´è¯¦ç»†çš„ä¸Šä¸‹æ–‡ï¼‰
		notifyContent := ""
		if len(importantLogs) == 1 {
			// å•æ¡æ—¥å¿—ï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹
			notifyContent = importantLogs[0]
		} else if len(importantLogs) <= 5 {
			// 5æ¡ä»¥å†…ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—ï¼ˆæˆªæ–­é•¿è¡Œï¼‰
			formattedLogs := make([]string, len(importantLogs))
			for i, line := range importantLogs {
				if len(line) > 200 {
					formattedLogs[i] = line[:200] + "..."
				} else {
					formattedLogs[i] = line
				}
			}
			notifyContent = strings.Join(formattedLogs, "\n\n")
		} else {
			// è¶…è¿‡5æ¡ï¼Œæ˜¾ç¤ºå‰3æ¡å’Œç»Ÿè®¡ä¿¡æ¯
			formattedLogs := make([]string, 0, 4)
			for i, line := range importantLogs {
				if i >= 3 {
					break
				}
				if len(line) > 150 {
					formattedLogs = append(formattedLogs, line[:150]+"...")
				} else {
					formattedLogs = append(formattedLogs, line)
				}
			}
			formattedLogs = append(formattedLogs, fmt.Sprintf("... è¿˜æœ‰ %d æ¡é‡è¦æ—¥å¿—", len(importantLogs)-3))
			notifyContent = strings.Join(formattedLogs, "\n\n")
		}

		// å‘é€ä¸€æ¬¡é€šçŸ¥
		go sendNotification(notifySummary, notifyContent)
	}

	return filtered, alerted
}

// å¤„ç†å•è¡Œæ—¥å¿—
func processLogLine(line string) (filtered bool, alerted bool) {
	// åˆ†ææ—¥å¿—
	analysis, err := analyzeLog(line, *logFormat)
	if err != nil {
		if *verbose {
			log.Printf("âŒ åˆ†ææ—¥å¿—å¤±è´¥: %v", err)
		}
		// å‡ºé”™æ—¶é»˜è®¤æ˜¾ç¤ºæ—¥å¿—
		fmt.Println(line)
		return false, false
	}

	if analysis.ShouldFilter {
		// è¿‡æ»¤æ‰çš„æ—¥å¿— - é»˜è®¤ä¸æ˜¾ç¤ºï¼Œé™¤éå¼€å¯ --show-not-important
		if *showNotImportant {
			fmt.Printf("ğŸ”‡ [è¿‡æ»¤] %s\n", line)
			if *verbose && analysis.Reason != "" {
				fmt.Printf("   åŸå› : %s\n", analysis.Reason)
			}
		}
		return true, false
	} else {
		// é‡è¦æ—¥å¿—ï¼Œéœ€è¦é€šçŸ¥ç”¨æˆ·
		fmt.Printf("âš ï¸  [é‡è¦] %s\n", line)
		fmt.Printf("   ğŸ“ æ‘˜è¦: %s\n", analysis.Summary)

		// å‘é€ macOS é€šçŸ¥
		go sendNotification(analysis.Summary, line)
		return false, true
	}
}

// ç›‘æ§æ–‡ä»¶
func watchFile(path string) error {
	// è·å–ç»å¯¹è·¯å¾„
	absPath, err := filepath.Abs(path)
	if err != nil {
		return fmt.Errorf("è·å–ç»å¯¹è·¯å¾„å¤±è´¥: %w", err)
	}

	// è®¾ç½®å…¨å±€å˜é‡ï¼Œç”¨äºé€šçŸ¥
	currentLogFile = absPath

	// åŠ è½½ä¸Šæ¬¡çš„çŠ¶æ€
	state := loadFileState(absPath)

	// æ‰“å¼€æ–‡ä»¶
	file, err := os.Open(absPath)
	if err != nil {
		return fmt.Errorf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close()

	// è·å–æ–‡ä»¶ä¿¡æ¯
	fileInfo, err := file.Stat()
	if err != nil {
		return fmt.Errorf("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %w", err)
	}

	currentInode := getInode(fileInfo)

	// å¦‚æœæ˜¯åŒä¸€ä¸ªæ–‡ä»¶ä¸”æœ‰ä¿å­˜çš„ä½ç½®ï¼Œä»ä¸Šæ¬¡ä½ç½®å¼€å§‹è¯»å–
	if state != nil && state.Inode == currentInode && state.Offset > 0 {
		fmt.Printf("ğŸ“Œ ä»ä¸Šæ¬¡ä½ç½®ç»§ç»­è¯»å– (åç§»: %d å­—èŠ‚)\n", state.Offset)
		if _, err := file.Seek(state.Offset, 0); err != nil {
			fmt.Printf("âš ï¸  æ— æ³•å®šä½åˆ°ä¸Šæ¬¡ä½ç½®ï¼Œä»æ–‡ä»¶æœ«å°¾å¼€å§‹: %v\n", err)
			file.Seek(0, 2) // å®šä½åˆ°æ–‡ä»¶æœ«å°¾
		}
	} else {
		// æ–°æ–‡ä»¶æˆ–è½®è½¬åçš„æ–‡ä»¶ï¼Œä»æœ«å°¾å¼€å§‹
		fmt.Println("ğŸ“Œ ä»æ–‡ä»¶æœ«å°¾å¼€å§‹ç›‘æ§æ–°å†…å®¹")
		file.Seek(0, 2)
	}

	// åˆ›å»ºæ–‡ä»¶ç›‘æ§å™¨
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		return fmt.Errorf("åˆ›å»ºæ–‡ä»¶ç›‘æ§å™¨å¤±è´¥: %w", err)
	}
	defer watcher.Close()

	// ç›‘æ§æ–‡ä»¶
	if err := watcher.Add(absPath); err != nil {
		return fmt.Errorf("æ·»åŠ æ–‡ä»¶ç›‘æ§å¤±è´¥: %w", err)
	}

	reader := bufio.NewReader(file)
	lineCount := 0
	filteredCount := 0
	alertCount := 0
	batchCount := 0

	// åˆ›å»ºæ‰¹å¤„ç†å™¨ï¼ˆå¦‚æœæœªç¦ç”¨æ‰¹å¤„ç†ï¼‰
	var batcher *LogBatcher
	if !*noBatch {
		batcher = NewLogBatcher(func(lines []string) {
			batchCount++
			if *verbose || *debug {
				log.Printf("ğŸ“¦ æ‰¹æ¬¡ #%d: å¤„ç† %d è¡Œæ—¥å¿—", batchCount, len(lines))
			}

			filtered, alerted := processBatch(lines)
			filteredCount += filtered
			alertCount += alerted

			// æ‰¹å¤„ç†å®Œæˆåä¿å­˜æ–‡ä»¶ä½ç½®
			offset, _ := file.Seek(0, 1)
			saveFileState(absPath, offset, currentInode)
		})
	}

	// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
	merger := NewLogLineMerger(*logFormat)

	// ç«‹å³è¯»å–å½“å‰ä½ç½®åˆ°æ–‡ä»¶æœ«å°¾çš„å†…å®¹
	for {
		line, err := reader.ReadString('\n')
		if err != nil {
			if err != io.EOF {
				log.Printf("è¯»å–æ–‡ä»¶å¤±è´¥: %v", err)
			}
			break
		}

		line = strings.TrimSuffix(line, "\n")
		if strings.TrimSpace(line) == "" {
			continue
		}

		lineCount++

		// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
		completeLine, hasComplete := merger.Add(line)
		if !hasComplete {
			continue
		}

		if *noBatch {
			// é€è¡Œå¤„ç†æ¨¡å¼
			filtered, alerted := processLogLine(completeLine)
			if filtered {
				filteredCount++
			}
			if alerted {
				alertCount++
			}
			// ä¿å­˜å½“å‰ä½ç½®
			offset, _ := file.Seek(0, 1)
			saveFileState(absPath, offset, currentInode)
		} else {
			// æ‰¹å¤„ç†æ¨¡å¼
			batcher.Add(completeLine)
		}
	}

	// åˆ·æ–°åˆå¹¶å™¨çš„æœ€åç¼“å†²
	if lastLine, hasLast := merger.Flush(); hasLast {
		if *noBatch {
			filtered, alerted := processLogLine(lastLine)
			if filtered {
				filteredCount++
			}
			if alerted {
				alertCount++
			}
			offset, _ := file.Seek(0, 1)
			saveFileState(absPath, offset, currentInode)
		} else {
			batcher.Add(lastLine)
		}
	}

	// åˆ·æ–°åˆå§‹æ‰¹æ¬¡
	if batcher != nil {
		batcher.Flush()
	}

	fmt.Println("â³ ç­‰å¾…æ–°æ—¥å¿—...")

	// ç›‘æ§æ–‡ä»¶å˜åŒ–
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case event, ok := <-watcher.Events:
			if !ok {
				return nil
			}

			if event.Op&fsnotify.Write == fsnotify.Write {
				// æ–‡ä»¶æœ‰æ–°å†…å®¹
				for {
					line, err := reader.ReadString('\n')
					if err != nil {
						if err != io.EOF {
							log.Printf("è¯»å–æ–‡ä»¶å¤±è´¥: %v", err)
						}
						break
					}

					line = strings.TrimSuffix(line, "\n")
					if strings.TrimSpace(line) == "" {
						continue
					}

					lineCount++

					// å°è¯•åˆå¹¶å¤šè¡Œæ—¥å¿—
					completeLine, hasComplete := merger.Add(line)
					if !hasComplete {
						continue
					}

					if *noBatch {
						// é€è¡Œå¤„ç†æ¨¡å¼
						filtered, alerted := processLogLine(completeLine)
						if filtered {
							filteredCount++
						}
						if alerted {
							alertCount++
						}
						// ä¿å­˜å½“å‰ä½ç½®
						offset, _ := file.Seek(0, 1)
						saveFileState(absPath, offset, currentInode)
					} else {
						// æ‰¹å¤„ç†æ¨¡å¼
						batcher.Add(completeLine)
					}
				}
			}

			// æ£€æµ‹æ–‡ä»¶è½®è½¬ï¼ˆåˆ é™¤æˆ–é‡å‘½åï¼‰
			if event.Op&(fsnotify.Remove|fsnotify.Rename) != 0 {
				fmt.Println("ğŸ”„ æ£€æµ‹åˆ°æ—¥å¿—è½®è½¬ï¼Œç­‰å¾…æ–°æ–‡ä»¶...")

				// åˆ·æ–°åˆå¹¶å™¨ç¼“å†²åŒºï¼ˆå¤„ç†æœªå®Œæˆçš„æ—¥å¿—ï¼‰
				if lastLine, hasLast := merger.Flush(); hasLast {
					if *noBatch {
						filtered, alerted := processLogLine(lastLine)
						if filtered {
							filteredCount++
						}
						if alerted {
							alertCount++
						}
					} else {
						batcher.Add(lastLine)
					}
				}

				// ç­‰å¾…æ–°æ–‡ä»¶å‡ºç°
				time.Sleep(1 * time.Second)

				// å°è¯•é‡æ–°æ‰“å¼€æ–‡ä»¶
				newFile, err := os.Open(absPath)
				if err != nil {
					fmt.Printf("âš ï¸  ç­‰å¾…æ–°æ–‡ä»¶åˆ›å»º: %v\n", err)
					continue
				}

				// å…³é—­æ—§æ–‡ä»¶
				file.Close()
				file = newFile
				reader = bufio.NewReader(file)

				// é‡æ–°åˆ›å»ºåˆå¹¶å™¨ï¼ˆæ–°æ–‡ä»¶ï¼‰
				merger = NewLogLineMerger(*logFormat)

				// è·å–æ–°æ–‡ä»¶ä¿¡æ¯
				fileInfo, err := file.Stat()
				if err == nil {
					currentInode = getInode(fileInfo)
					fmt.Println("âœ… å·²åˆ‡æ¢åˆ°æ–°æ–‡ä»¶")
					// é‡ç½®åç§»é‡
					saveFileState(absPath, 0, currentInode)
				}
			}

		case <-ticker.C:
			// å®šæœŸæ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«è½®è½¬ï¼ˆå¤§å°å˜å°ï¼‰
			currentInfo, err := os.Stat(absPath)
			if err != nil {
				continue
			}

			currentSize := currentInfo.Size()
			currentOffset, _ := file.Seek(0, 1)

			// å¦‚æœæ–‡ä»¶å¤§å°å°äºå½“å‰åç§»é‡ï¼Œè¯´æ˜æ–‡ä»¶è¢«æˆªæ–­æˆ–è½®è½¬
			if currentSize < currentOffset {
				fmt.Println("ğŸ”„ æ£€æµ‹åˆ°æ–‡ä»¶æˆªæ–­æˆ–è½®è½¬ï¼Œé‡æ–°æ‰“å¼€æ–‡ä»¶...")

				// åˆ·æ–°åˆå¹¶å™¨ç¼“å†²åŒºï¼ˆå¤„ç†æœªå®Œæˆçš„æ—¥å¿—ï¼‰
				if lastLine, hasLast := merger.Flush(); hasLast {
					if *noBatch {
						filtered, alerted := processLogLine(lastLine)
						if filtered {
							filteredCount++
						}
						if alerted {
							alertCount++
						}
					} else {
						batcher.Add(lastLine)
					}
				}

				// é‡æ–°æ‰“å¼€æ–‡ä»¶
				file.Close()
				newFile, err := os.Open(absPath)
				if err != nil {
					log.Printf("é‡æ–°æ‰“å¼€æ–‡ä»¶å¤±è´¥: %v", err)
					continue
				}

				file = newFile
				reader = bufio.NewReader(file)

				// é‡æ–°åˆ›å»ºåˆå¹¶å™¨ï¼ˆæ–°æ–‡ä»¶ï¼‰
				merger = NewLogLineMerger(*logFormat)

				// è·å–æ–°æ–‡ä»¶ä¿¡æ¯
				fileInfo, _ := file.Stat()
				currentInode = getInode(fileInfo)

				// ä»å¤´å¼€å§‹è¯»å–
				saveFileState(absPath, 0, currentInode)
				fmt.Println("âœ… å·²é‡æ–°æ‰“å¼€æ–‡ä»¶ï¼Œä»å¤´å¼€å§‹è¯»å–")
			}

		case err, ok := <-watcher.Errors:
			if !ok {
				return nil
			}
			log.Printf("ç›‘æ§é”™è¯¯: %v", err)
		}
	}
}

// è·å–æ–‡ä»¶çŠ¶æ€è·¯å¾„
func getStateFilePath(logPath string) string {
	dir := filepath.Dir(logPath)
	base := filepath.Base(logPath)
	return filepath.Join(dir, ".aipipe_"+base+".state")
}

// åŠ è½½æ–‡ä»¶çŠ¶æ€
func loadFileState(path string) *FileState {
	stateFile := getStateFilePath(path)
	data, err := os.ReadFile(stateFile)
	if err != nil {
		return nil
	}

	var state FileState
	if err := json.Unmarshal(data, &state); err != nil {
		return nil
	}

	return &state
}

// ä¿å­˜æ–‡ä»¶çŠ¶æ€
func saveFileState(path string, offset int64, inode uint64) {
	state := FileState{
		Path:   path,
		Offset: offset,
		Inode:  inode,
		Time:   time.Now(),
	}

	data, err := json.MarshalIndent(state, "", "  ")
	if err != nil {
		return
	}

	stateFile := getStateFilePath(path)
	os.WriteFile(stateFile, data, 0644)
}

// åˆ†ææ—¥å¿—å†…å®¹ï¼ˆå•æ¡ï¼‰
func analyzeLog(logLine string, format string) (*LogAnalysis, error) {
	// æœ¬åœ°é¢„è¿‡æ»¤ï¼šå¯¹äºæ˜ç¡®çš„ä½çº§åˆ«æ—¥å¿—ï¼Œç›´æ¥è¿‡æ»¤ï¼Œä¸è°ƒç”¨ AI
	if localAnalysis := tryLocalFilter(logLine); localAnalysis != nil {
		return localAnalysis, nil
	}

	// æ„å»ºç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
	systemPrompt := buildSystemPrompt(format)
	userPrompt := buildUserPrompt(logLine)

	// è°ƒç”¨ AI API
	response, err := callAIAPI(systemPrompt, userPrompt)
	if err != nil {
		return nil, fmt.Errorf("è°ƒç”¨ AI API å¤±è´¥: %w", err)
	}

	// è§£æå“åº”
	analysis, err := parseAnalysisResponse(response)
	if err != nil {
		return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
	}

	// åå¤„ç†ï¼šä¿å®ˆç­–ç•¥ï¼Œå½“ AI æ— æ³•ç¡®å®šæ—¶ï¼Œé»˜è®¤è¿‡æ»¤
	analysis = applyConservativeFilter(analysis)

	return analysis, nil
}

// æ‰¹é‡åˆ†ææ—¥å¿—
func analyzeBatchLogs(logLines []string, format string) (*BatchLogAnalysis, error) {
	if len(logLines) == 0 {
		return &BatchLogAnalysis{}, nil
	}

	// æ„å»ºç³»ç»Ÿæç¤ºè¯
	systemPrompt := buildSystemPrompt(format)

	// æ„å»ºæ‰¹é‡åˆ†æçš„ç”¨æˆ·æç¤ºè¯
	userPrompt := buildBatchUserPrompt(logLines)

	// è°ƒç”¨ AI API
	response, err := callAIAPI(systemPrompt, userPrompt)
	if err != nil {
		return nil, fmt.Errorf("è°ƒç”¨ AI API å¤±è´¥: %w", err)
	}

	// è§£ææ‰¹é‡å“åº”
	batchAnalysis, err := parseBatchAnalysisResponse(response, len(logLines))
	if err != nil {
		return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
	}

	// åº”ç”¨ä¿å®ˆç­–ç•¥åˆ°æ¯ä¸€æ¡ç»“æœ
	for i := range batchAnalysis.Results {
		batchAnalysis.Results[i] = *applyConservativeFilter(&batchAnalysis.Results[i])
		if !batchAnalysis.Results[i].ShouldFilter {
			batchAnalysis.ImportantCount++
		}
	}

	return batchAnalysis, nil
}

// æœ¬åœ°é¢„è¿‡æ»¤ï¼šå¯¹äºæ˜ç¡®çš„ä½çº§åˆ«æ—¥å¿—ï¼Œç›´æ¥è¿‡æ»¤ï¼Œä¸è°ƒç”¨ AI
// è¿”å› nil è¡¨ç¤ºæ— æ³•æœ¬åœ°åˆ¤æ–­ï¼Œéœ€è¦è°ƒç”¨ AI
func tryLocalFilter(logLine string) *LogAnalysis {
	// è½¬æ¢ä¸ºå¤§å†™ä»¥ä¾¿åŒ¹é…
	upperLine := strings.ToUpper(logLine)

	// å®šä¹‰ä½çº§åˆ«æ—¥å¿—çš„æ­£åˆ™æ¨¡å¼
	// åŒ¹é…å¸¸è§çš„æ—¥å¿—çº§åˆ«æ ¼å¼ï¼š[DEBUG]ã€DEBUGã€ DEBUG ã€[D] ç­‰
	lowLevelPatterns := []struct {
		level   string
		pattern string
		summary string
	}{
		{"TRACE", `\b(TRACE|TRC)\b`, "TRACE çº§åˆ«æ—¥å¿—"},
		{"DEBUG", `\b(DEBUG|DBG|D)\b`, "DEBUG çº§åˆ«æ—¥å¿—"},
		{"INFO", `\b(INFO|INF|I)\b`, "INFO çº§åˆ«æ—¥å¿—"},
		{"VERBOSE", `\bVERBOSE\b`, "VERBOSE çº§åˆ«æ—¥å¿—"},
	}

	for _, pattern := range lowLevelPatterns {
		// ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
		matched, err := regexp.MatchString(pattern.pattern, upperLine)
		if err == nil && matched {
			// é¢å¤–æ£€æŸ¥ï¼šç¡®ä¿ä¸åŒ…å«æ˜æ˜¾çš„é”™è¯¯å…³é”®è¯
			// æœ‰æ—¶å€™ INFO æ—¥å¿—ä¹Ÿå¯èƒ½åŒ…å« error ç­‰å…³é”®è¯ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ¤æ–­
			hasErrorKeywords := strings.Contains(upperLine, "ERROR") ||
				strings.Contains(upperLine, "EXCEPTION") ||
				strings.Contains(upperLine, "FATAL") ||
				strings.Contains(upperLine, "CRITICAL") ||
				strings.Contains(upperLine, "FAILED") ||
				strings.Contains(upperLine, "FAILURE")

			// å¦‚æœæ—¥å¿—çº§åˆ«æ˜¯ä½çº§åˆ«ï¼Œä½†åŒ…å«é”™è¯¯å…³é”®è¯ï¼Œè¿˜æ˜¯äº¤ç»™ AI åˆ¤æ–­
			if hasErrorKeywords {
				continue
			}

			if *verbose || *debug {
				log.Printf("âš¡ æœ¬åœ°è¿‡æ»¤: æ£€æµ‹åˆ° %s çº§åˆ«ï¼Œç›´æ¥è¿‡æ»¤ï¼ˆä¸è°ƒç”¨ AIï¼‰", pattern.level)
			}

			return &LogAnalysis{
				ShouldFilter: true,
				Summary:      pattern.summary,
				Reason:       fmt.Sprintf("æœ¬åœ°è¿‡æ»¤ï¼š%s çº§åˆ«çš„æ—¥å¿—é€šå¸¸æ— éœ€å…³æ³¨", pattern.level),
			}
		}
	}

	// æ— æ³•æœ¬åœ°åˆ¤æ–­ï¼Œè¿”å› nilï¼Œéœ€è¦è°ƒç”¨ AI
	return nil
}

// åº”ç”¨ä¿å®ˆè¿‡æ»¤ç­–ç•¥
// å½“ AI æ— æ³•åˆ¤æ–­æˆ–è¿”å›ä¸ç¡®å®šç»“æœæ—¶ï¼Œé»˜è®¤è¿‡æ»¤æ‰ï¼Œé¿å…è¯¯æŠ¥
func applyConservativeFilter(analysis *LogAnalysis) *LogAnalysis {
	// æ£€æŸ¥çš„å…³é”®è¯åˆ—è¡¨ï¼ˆè¡¨ç¤º AI æ— æ³•ç¡®å®šæˆ–æ—¥å¿—å¼‚å¸¸ï¼‰
	uncertainKeywords := []string{
		"æ—¥å¿—å†…å®¹å¼‚å¸¸",
		"æ—¥å¿—å†…å®¹ä¸å®Œæ•´",
		"æ— æ³•åˆ¤æ–­",
		"æ—¥å¿—æ ¼å¼å¼‚å¸¸",
		"æ—¥å¿—å†…å®¹ä¸ç¬¦åˆé¢„æœŸ",
		"æ— æ³•ç¡®å®š",
		"ä¸ç¡®å®š",
		"æ— æ³•è¯†åˆ«",
		"æ ¼å¼ä¸æ­£ç¡®",
		"å†…å®¹å¼‚å¸¸",
		"æ— æ³•è§£æ",
	}

	// æ£€æŸ¥ summary å’Œ reason å­—æ®µ
	checkText := strings.ToLower(analysis.Summary + " " + analysis.Reason)

	for _, keyword := range uncertainKeywords {
		if strings.Contains(checkText, strings.ToLower(keyword)) {
			// å‘ç°ä¸ç¡®å®šçš„å…³é”®è¯ï¼Œå¼ºåˆ¶è¿‡æ»¤
			if *verbose || *debug {
				log.Printf("ğŸ” æ£€æµ‹åˆ°ä¸ç¡®å®šå…³é”®è¯ã€Œ%sã€ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥ï¼šè¿‡æ»¤æ­¤æ—¥å¿—", keyword)
			}
			analysis.ShouldFilter = true
			if analysis.Reason == "" {
				analysis.Reason = "AI æ— æ³•ç¡®å®šæ—¥å¿—é‡è¦æ€§ï¼Œé‡‡ç”¨ä¿å®ˆç­–ç•¥è¿‡æ»¤"
			} else {
				analysis.Reason = analysis.Reason + "ï¼ˆä¿å®ˆç­–ç•¥ï¼šè¿‡æ»¤ï¼‰"
			}
			break
		}
	}

	return analysis
}

// è·å–æ ¼å¼ç‰¹å®šçš„ç¤ºä¾‹
func getFormatSpecificExamples(format string) string {
	switch format {
	case "java":
		return `Java ç‰¹å®šç¤ºä¾‹ï¼š
   - "INFO com.example.service.UserService - User created successfully"
   - "ERROR com.example.dao.DatabaseDAO - Connection pool exhausted"
   - "WARN com.example.controller.AuthController - Invalid JWT token"`

	case "php":
		return `PHP ç‰¹å®šç¤ºä¾‹ï¼š
   - "PHP Notice: Undefined variable $user in /app/index.php"
   - "PHP Fatal error: Call to undefined function mysql_connect()"
   - "PHP Warning: file_get_contents() failed to open stream"`

	case "nginx":
		return `Nginx ç‰¹å®šç¤ºä¾‹ï¼š
   - "127.0.0.1 - - [13/Oct/2025:10:00:01 +0000] \"GET /api/health HTTP/1.1\" 200"
   - "upstream server temporarily disabled while connecting to upstream"
   - "connect() failed (111: Connection refused) while connecting to upstream"`

	case "go":
		return `Go ç‰¹å®šç¤ºä¾‹ï¼š
   - "INFO: Starting server on :8080"
   - "ERROR: database connection failed: dial tcp: connection refused"
   - "WARN: goroutine leak detected"`

	case "rust":
		return `Rust ç‰¹å®šç¤ºä¾‹ï¼š
   - "INFO: Server listening on 127.0.0.1:8080"
   - "ERROR: thread 'main' panicked at 'index out of bounds'"
   - "WARN: memory usage high: 512MB"`

	case "csharp":
		return `C# ç‰¹å®šç¤ºä¾‹ï¼š
   - "INFO: Application started"
   - "ERROR: System.Exception: Database connection timeout"
   - "WARN: Memory pressure detected"`

	case "nodejs":
		return `Node.js ç‰¹å®šç¤ºä¾‹ï¼š
   - "info: Server running on port 3000"
   - "error: Error: ENOENT: no such file or directory"
   - "warn: DeprecationWarning: Buffer() is deprecated"`

	case "docker":
		return `Docker ç‰¹å®šç¤ºä¾‹ï¼š
   - "Container started successfully"
   - "ERROR: failed to start container: port already in use"
   - "WARN: container running out of memory"`

	case "kubernetes":
		return `Kubernetes ç‰¹å®šç¤ºä¾‹ï¼š
   - "Pod started successfully"
   - "ERROR: Failed to pull image: ImagePullBackOff"
   - "WARN: Pod evicted due to memory pressure"`

	case "postgresql":
		return `PostgreSQL ç‰¹å®šç¤ºä¾‹ï¼š
   - "LOG: database system is ready to accept connections"
   - "ERROR: relation \"users\" does not exist"
   - "WARN: checkpoint request timed out"`

	case "mysql":
		return `MySQL ç‰¹å®šç¤ºä¾‹ï¼š
   - "InnoDB: Database was not shut down normally"
   - "ERROR 1045: Access denied for user 'root'@'localhost'"
   - "Warning: Aborted connection to db"`

	case "redis":
		return `Redis ç‰¹å®šç¤ºä¾‹ï¼š
   - "Redis server version 6.2.6, bits=64"
   - "ERROR: OOM command not allowed when used memory > 'maxmemory'"
   - "WARN: overcommit_memory is set to 0"`

	case "journald":
		return `Linux journald ç‰¹å®šç¤ºä¾‹ï¼š
   - "Oct 17 10:00:01 systemd[1]: Started Network Manager Script Dispatcher Service"
   - "Oct 17 10:00:02 kernel: [ 1234.567890] Out of memory: Kill process 1234 (chrome) score 500 or sacrifice child"
   - "Oct 17 10:00:03 sshd[1234]: Failed password for root from 192.168.1.100 port 22 ssh2"`

	case "macos-console":
		return `macOS Console ç‰¹å®šç¤ºä¾‹ï¼š
   - "2025-10-17 10:00:01.123456+0800 0x7b Default 0x0 0 0 kernel: (AppleH11ANEInterface) ANE0: EnableMemoryUnwireTimer: ERROR: Cannot enable Memory Unwire Timer"
   - "2025-10-17 10:00:02.234567+0800 0x1f11722 Error 0x185174d 386 0 locationd: (TCC) [com.apple.TCC:access] send_message_with_reply_sync(): XPC_ERROR_CONNECTION_INVALID"
   - "2025-10-17 10:00:03.345678+0800 0x1f11e95 Error 0x1851731 558 0 searchpartyd: (TCC) [com.apple.TCC:access] send_message_with_reply_sync(): XPC_ERROR_CONNECTION_INVALID"`

	case "syslog":
		return `Syslog ç‰¹å®šç¤ºä¾‹ï¼š
   - "Oct 17 10:00:01 hostname systemd[1]: Started Network Manager Script Dispatcher Service"
   - "Oct 17 10:00:02 hostname kernel: [ 1234.567890] Out of memory: Kill process 1234 (chrome) score 500"
   - "Oct 17 10:00:03 hostname sshd[1234]: Failed password for root from 192.168.1.100 port 22 ssh2"`

	default:
		return ""
	}
}

// æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆå®šä¹‰è§’è‰²å’Œåˆ¤æ–­æ ‡å‡†ï¼‰
func buildSystemPrompt(format string) string {
	formatExamples := getFormatSpecificExamples(format)

	basePrompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥å¿—åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨åˆ†æ %s æ ¼å¼çš„æ—¥å¿—ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­æ—¥å¿—æ˜¯å¦éœ€è¦å…³æ³¨ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›åˆ†æç»“æœã€‚

è¿”å›æ ¼å¼ï¼š
{
  "should_filter": true/false,  // true è¡¨ç¤ºåº”è¯¥è¿‡æ»¤ï¼ˆä¸é‡è¦ï¼‰ï¼Œfalse è¡¨ç¤ºéœ€è¦å…³æ³¨
  "summary": "ç®€çŸ­æ‘˜è¦ï¼ˆ20å­—å†…ï¼‰",
  "reason": "åˆ¤æ–­åŸå› "
}

åˆ¤æ–­æ ‡å‡†å’Œç¤ºä¾‹ï¼š

ã€åº”è¯¥è¿‡æ»¤çš„æ—¥å¿—ã€‘(should_filter=true) - æ­£å¸¸è¿è¡ŒçŠ¶æ€ï¼Œæ— éœ€å‘Šè­¦ï¼š
1. å¥åº·æ£€æŸ¥å’Œå¿ƒè·³
   - "Health check endpoint called"
   - "Heartbeat received from client"
   - "/health returned 200"
   
2. åº”ç”¨å¯åŠ¨å’Œé…ç½®åŠ è½½
   - "Application started successfully"
   - "Configuration loaded from config.yml"
   - "Server listening on port 8080"
   
3. æ­£å¸¸çš„ä¸šåŠ¡æ“ä½œï¼ˆINFO/DEBUGï¼‰
   - "User logged in: john@example.com"
   - "Retrieved 20 records from database"
   - "Cache hit for key: user_123"
   - "Request processed in 50ms"
   
4. å®šæ—¶ä»»åŠ¡æ­£å¸¸æ‰§è¡Œ
   - "Scheduled task completed successfully"
   - "Cleanup job finished, removed 10 items"
   
5. é™æ€èµ„æºè¯·æ±‚
   - "GET /static/css/style.css 200"
   - "Serving static file: logo.png"

6. å¸¸è§„æ•°æ®åº“æ“ä½œ
   - "Query executed successfully in 10ms"
   - "Transaction committed"
   
7. æ­£å¸¸çš„APIè¯·æ±‚å“åº”
   - "GET /api/users 200 OK"
   - "POST /api/data returned 201"

ã€éœ€è¦å…³æ³¨çš„æ—¥å¿—ã€‘(should_filter=false) - å¼‚å¸¸æƒ…å†µï¼Œéœ€è¦å‘Šè­¦ï¼š
1. é”™è¯¯å’Œå¼‚å¸¸ï¼ˆERRORçº§åˆ«ï¼‰
   - "ERROR: Database connection failed"
   - "NullPointerException at line 123"
   - "Failed to connect to Redis"
   - ä»»ä½•åŒ…å« Exception, Error, Failed çš„é”™è¯¯ä¿¡æ¯
   
2. æ•°æ®åº“é—®é¢˜
   - "Database connection timeout"
   - "Deadlock detected"
   - "Slow query: 5000ms"
   - "Connection pool exhausted"
   
3. è®¤è¯å’Œæˆæƒé—®é¢˜
   - "Authentication failed for user admin"
   - "Invalid token: access denied"
   - "Permission denied: insufficient privileges"
   - "Multiple failed login attempts from 192.168.1.100"
   
4. æ€§èƒ½é—®é¢˜ï¼ˆWARNçº§åˆ«æˆ–æ…¢å“åº”ï¼‰
   - "Request timeout after 30s"
   - "Response time exceeded threshold: 5000ms"
   - "Memory usage high: 85%%"
   - "Thread pool near capacity: 95/100"
   
5. èµ„æºè€—å°½
   - "Out of memory error"
   - "Disk space low: 95%% used"
   - "Too many open files"
   
6. å¤–éƒ¨æœåŠ¡è°ƒç”¨å¤±è´¥
   - "Payment gateway timeout"
   - "Failed to call external API: 500"
   - "Third-party service unavailable"
   
7. ä¸šåŠ¡å¼‚å¸¸
   - "Order processing failed: insufficient balance"
   - "Payment declined: invalid card"
   - "Data validation failed"
   
8. å®‰å…¨é—®é¢˜
   - "SQL injection attempt detected"
   - "Suspicious activity from IP"
   - "Rate limit exceeded"
   - "Invalid CSRF token"
   
9. æ•°æ®ä¸€è‡´æ€§é—®é¢˜
   - "Data mismatch detected"
   - "Inconsistent state in transaction"
   
10. æœåŠ¡é™çº§å’Œç†”æ–­
    - "Circuit breaker opened"
    - "Service degraded mode activated"`, format)

	// æ·»åŠ æ ¼å¼ç‰¹å®šçš„ç¤ºä¾‹
	if formatExamples != "" {
		basePrompt += "\n\n" + formatExamples
	}

	basePrompt += `

æ³¨æ„ï¼š
- å¦‚æœæ—¥å¿—çº§åˆ«æ˜¯ ERROR æˆ–åŒ…å« Exception/Errorï¼Œé€šå¸¸éœ€è¦å…³æ³¨
- å¦‚æœåŒ…å« "failed", "timeout", "unable", "cannot" ç­‰è´Ÿé¢è¯æ±‡ï¼Œéœ€è¦ä»”ç»†åˆ¤æ–­
- å¦‚æœæ˜¯ WARN çº§åˆ«ï¼Œéœ€è¦æ ¹æ®å…·ä½“å†…å®¹åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
- å¥åº·æ£€æŸ¥ã€å¿ƒè·³ã€æ­£å¸¸çš„ INFO æ—¥å¿—é€šå¸¸å¯ä»¥è¿‡æ»¤

é‡è¦åŸåˆ™ï¼ˆä¿å®ˆç­–ç•¥ï¼‰ï¼š
- å¦‚æœæ—¥å¿—å†…å®¹ä¸å®Œæ•´ã€æ ¼å¼å¼‚å¸¸æˆ–æ— æ³•ç¡®å®šé‡è¦æ€§ï¼Œè¯·è®¾ç½® should_filter=true
- åœ¨ summary æˆ– reason ä¸­æ˜ç¡®è¯´æ˜"æ—¥å¿—å†…å®¹å¼‚å¸¸"ã€"æ— æ³•åˆ¤æ–­"ç­‰åŸå› 
- æˆ‘ä»¬é‡‡å–ä¿å®ˆç­–ç•¥ï¼šåªæç¤ºç¡®è®¤é‡è¦çš„ä¿¡æ¯ï¼Œä¸ç¡®å®šçš„ä¸€å¾‹è¿‡æ»¤

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚`

	// å¦‚æœæœ‰è‡ªå®šä¹‰æç¤ºè¯ï¼Œæ·»åŠ åˆ°ç³»ç»Ÿæç¤ºè¯ä¸­
	if globalConfig.CustomPrompt != "" {
		basePrompt += "\n\n" + globalConfig.CustomPrompt
	}

	return basePrompt
}

// æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆå®é™…è¦åˆ†æçš„æ—¥å¿—ï¼‰
func buildUserPrompt(logLine string) string {
	return fmt.Sprintf("è¯·åˆ†æä»¥ä¸‹æ—¥å¿—ï¼š\n\n%s", logLine)
}

// æ„å»ºæ‰¹é‡ç”¨æˆ·æç¤ºè¯
func buildBatchUserPrompt(logLines []string) string {
	var sb strings.Builder
	sb.WriteString("è¯·æ‰¹é‡åˆ†æä»¥ä¸‹æ—¥å¿—ï¼Œå¯¹æ¯ä¸€è¡Œç»™å‡ºåˆ¤æ–­ï¼š\n\n")

	for i, line := range logLines {
		sb.WriteString(fmt.Sprintf("[%d] %s\n", i+1, line))
	}

	sb.WriteString("\nè¯·è¿”å› JSON æ ¼å¼ï¼š\n")
	sb.WriteString("{\n")
	sb.WriteString("  \"results\": [\n")
	sb.WriteString("    {\"should_filter\": true/false, \"summary\": \"æ‘˜è¦\", \"reason\": \"åŸå› \"},\n")
	sb.WriteString("    ...\n")
	sb.WriteString("  ],\n")
	sb.WriteString("  \"overall_summary\": \"è¿™æ‰¹æ—¥å¿—çš„æ•´ä½“æ‘˜è¦ï¼ˆ20å­—å†…ï¼‰\",\n")
	sb.WriteString(fmt.Sprintf("  \"important_count\": 0  // é‡è¦æ—¥å¿—æ•°é‡ï¼ˆ%d æ¡ä¸­æœ‰å‡ æ¡ï¼‰\n", len(logLines)))
	sb.WriteString("}\n")
	sb.WriteString("\næ³¨æ„ï¼šresults æ•°ç»„å¿…é¡»åŒ…å« " + fmt.Sprintf("%d", len(logLines)) + " ä¸ªå…ƒç´ ï¼ŒæŒ‰é¡ºåºå¯¹åº”æ¯ä¸€è¡Œæ—¥å¿—ã€‚")

	return sb.String()
}

// è°ƒç”¨ AI API
func callAIAPI(systemPrompt, userPrompt string) (string, error) {
	// è·å–AIæœåŠ¡
	service, err := aiServiceManager.GetNextService()
	if err != nil {
		return "", fmt.Errorf("è·å–AIæœåŠ¡å¤±è´¥: %w", err)
	}

	// è®°å½•æœåŠ¡è°ƒç”¨
	aiServiceManager.RecordCall(service.Name)

	// æ„å»ºè¯·æ±‚ï¼Œä½¿ç”¨ system å’Œ user ä¸¤æ¡æ¶ˆæ¯
	reqBody := ChatRequest{
		Model: service.Model,
		Messages: []ChatMessage{
			{
				Role:    "system",
				Content: systemPrompt,
			},
			{
				Role:    "user",
				Content: userPrompt,
			},
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return "", err
	}

	// Debug: æ‰“å°è¯·æ±‚ä¿¡æ¯
	if *debug {
		fmt.Println("\n" + strings.Repeat("=", 80))
		fmt.Println("ğŸ” DEBUG: HTTP è¯·æ±‚è¯¦æƒ…")
		fmt.Println(strings.Repeat("=", 80))
		fmt.Printf("æœåŠ¡: %s\n", service.Name)
		fmt.Printf("URL: %s\n", service.Endpoint)
		fmt.Printf("Method: POST\n")
		fmt.Printf("Headers:\n")
		fmt.Printf("  Content-Type: application/json\n")
		fmt.Printf("  api-key: %s...%s\n", service.Token[:min(10, len(service.Token))], service.Token[max(0, len(service.Token)-10):])
		fmt.Printf("\nRequest Body:\n")
		var prettyJSON bytes.Buffer
		if err := json.Indent(&prettyJSON, jsonData, "", "  "); err == nil {
			fmt.Println(prettyJSON.String())
		} else {
			fmt.Println(string(jsonData))
		}
		fmt.Println(strings.Repeat("=", 80))
	}

	// åˆ›å»º HTTP è¯·æ±‚
	req, err := http.NewRequest("POST", service.Endpoint, bytes.NewBuffer(jsonData))
	if err != nil {
		return "", err
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("api-key", service.Token)

	// å‘é€è¯·æ±‚
	client := &http.Client{
		Timeout: time.Duration(globalConfig.Timeout) * time.Second,
	}

	if *debug {
		fmt.Printf("â³ å‘é€è¯·æ±‚ä¸­...\n")
	}

	startTime := time.Now()
	var resp *http.Response
	var httpErr error

	// é‡è¯•æœºåˆ¶
	for i := 0; i < globalConfig.MaxRetries; i++ {
		resp, httpErr = client.Do(req)
		if httpErr == nil {
			break
		}

		// ä½¿ç”¨é”™è¯¯å¤„ç†å™¨å¤„ç†ç½‘ç»œé”™è¯¯
		if handledErr := errorHandler.Handle(httpErr, map[string]interface{}{
			"operation":   "ai_api_call",
			"service":     service.Name,
			"endpoint":    service.Endpoint,
			"retry":       i + 1,
			"max_retries": globalConfig.MaxRetries,
		}); handledErr != nil {
			if i == globalConfig.MaxRetries-1 {
				if *debug {
					fmt.Printf("âŒ è¯·æ±‚å¤±è´¥ (é‡è¯• %d/%d): %v\n", i+1, globalConfig.MaxRetries, handledErr)
					fmt.Println(strings.Repeat("=", 80) + "\n")
				}
				return "", handledErr
			}
			time.Sleep(time.Duration(i+1) * time.Second) // æŒ‡æ•°é€€é¿
		} else {
			// é”™è¯¯å·²æ¢å¤ï¼Œé‡è¯•
			continue
		}
	}

	if httpErr != nil {
		if *debug {
			fmt.Printf("âŒ è¯·æ±‚å¤±è´¥: %v\n", httpErr)
			fmt.Println(strings.Repeat("=", 80) + "\n")
		}
		return "", httpErr
	}
	defer resp.Body.Close()

	elapsed := time.Since(startTime)

	// è¯»å–å“åº”ä½“
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", err
	}

	// Debug: æ‰“å°å“åº”ä¿¡æ¯
	if *debug {
		fmt.Println(strings.Repeat("=", 80))
		fmt.Println("ğŸ” DEBUG: HTTP å“åº”è¯¦æƒ…")
		fmt.Println(strings.Repeat("=", 80))
		fmt.Printf("Status Code: %d %s\n", resp.StatusCode, resp.Status)
		fmt.Printf("Response Time: %v\n", elapsed)
		fmt.Printf("Content-Length: %d bytes\n", len(body))
		fmt.Printf("\nResponse Headers:\n")
		for key, values := range resp.Header {
			for _, value := range values {
				fmt.Printf("  %s: %s\n", key, value)
			}
		}
		fmt.Printf("\nResponse Body:\n")
		var prettyJSON bytes.Buffer
		if err := json.Indent(&prettyJSON, body, "", "  "); err == nil {
			fmt.Println(prettyJSON.String())
		} else {
			fmt.Println(string(body))
		}
		fmt.Println(strings.Repeat("=", 80) + "\n")
	}

	if resp.StatusCode != http.StatusOK {
		apiErr := fmt.Errorf("API è¿”å›é”™è¯¯çŠ¶æ€ç  %d: %s", resp.StatusCode, string(body))

		// ä½¿ç”¨é”™è¯¯å¤„ç†å™¨å¤„ç† API é”™è¯¯
		if handledErr := errorHandler.Handle(apiErr, map[string]interface{}{
			"operation":     "ai_api_response",
			"service":       service.Name,
			"status_code":   resp.StatusCode,
			"endpoint":      service.Endpoint,
			"response_body": string(body),
		}); handledErr != nil {
			return "", handledErr
		}
	}

	// è§£æå“åº”
	var chatResp ChatResponse
	if err := json.Unmarshal(body, &chatResp); err != nil {
		return "", err
	}

	if len(chatResp.Choices) == 0 {
		return "", fmt.Errorf("API å“åº”ä¸­æ²¡æœ‰å†…å®¹")
	}

	return chatResp.Choices[0].Message.Content, nil
}

// è§£ææ‰¹é‡ AI å“åº”
func parseBatchAnalysisResponse(response string, expectedCount int) (*BatchLogAnalysis, error) {
	// æå– JSONï¼ˆå¤„ç† markdown ä»£ç å—ï¼‰
	jsonStr := extractJSON(response)

	var batchAnalysis BatchLogAnalysis
	if err := json.Unmarshal([]byte(jsonStr), &batchAnalysis); err != nil {
		return nil, fmt.Errorf("è§£ææ‰¹é‡ JSON å¤±è´¥: %w\nåŸå§‹å“åº”: %s\næå–çš„JSON: %s", err, response, jsonStr)
	}

	// éªŒè¯ç»“æœæ•°é‡
	if len(batchAnalysis.Results) != expectedCount {
		if *verbose || *debug {
			log.Printf("âš ï¸  æ‰¹é‡åˆ†æç»“æœæ•°é‡ä¸åŒ¹é…ï¼šæœŸæœ› %d æ¡ï¼Œå®é™… %d æ¡", expectedCount, len(batchAnalysis.Results))
		}

		// å¦‚æœç»“æœå°‘äºé¢„æœŸï¼Œè¡¥å……é»˜è®¤ç»“æœï¼ˆè¿‡æ»¤ï¼‰
		for len(batchAnalysis.Results) < expectedCount {
			batchAnalysis.Results = append(batchAnalysis.Results, LogAnalysis{
				ShouldFilter: true,
				Summary:      "ç»“æœç¼ºå¤±",
				Reason:       "æ‰¹é‡åˆ†æè¿”å›ç»“æœæ•°é‡ä¸è¶³",
			})
		}
	}

	return &batchAnalysis, nil
}

// æå– JSONï¼ˆä»å¯èƒ½åŒ…å« markdown ä»£ç å—çš„å“åº”ä¸­ï¼‰
func extractJSON(response string) string {
	jsonStr := response

	// å¤„ç† ```json ... ``` æ ¼å¼
	if strings.Contains(response, "```json") {
		start := strings.Index(response, "```json")
		if start != -1 {
			start += 7
			remaining := response[start:]
			end := strings.Index(remaining, "```")
			if end != -1 {
				jsonStr = remaining[:end]
			}
		}
	} else if strings.Contains(response, "```") {
		start := strings.Index(response, "```")
		if start != -1 {
			start += 3
			remaining := response[start:]
			end := strings.Index(remaining, "```")
			if end != -1 {
				jsonStr = remaining[:end]
			}
		}
	}

	// æ¸…ç†å­—ç¬¦ä¸²
	jsonStr = strings.TrimSpace(jsonStr)

	// æ™ºèƒ½å®šä½ JSON èµ·å§‹å’Œç»“æŸ
	if len(jsonStr) > 0 && jsonStr[0] != '{' && jsonStr[0] != '[' {
		startBrace := strings.Index(jsonStr, "{")
		startBracket := strings.Index(jsonStr, "[")

		start := -1
		if startBrace != -1 && (startBracket == -1 || startBrace < startBracket) {
			start = startBrace
		} else if startBracket != -1 {
			start = startBracket
		}

		if start != -1 {
			jsonStr = jsonStr[start:]
		}
	}

	if len(jsonStr) > 0 && jsonStr[len(jsonStr)-1] != '}' && jsonStr[len(jsonStr)-1] != ']' {
		endBrace := strings.LastIndex(jsonStr, "}")
		endBracket := strings.LastIndex(jsonStr, "]")

		end := -1
		if endBrace != -1 && endBrace > endBracket {
			end = endBrace
		} else if endBracket != -1 {
			end = endBracket
		}

		if end != -1 {
			jsonStr = jsonStr[:end+1]
		}
	}

	return jsonStr
}

// è§£æ AI å“åº”ï¼ˆå•æ¡ï¼‰
func parseAnalysisResponse(response string) (*LogAnalysis, error) {
	jsonStr := extractJSON(response)

	var analysis LogAnalysis
	if err := json.Unmarshal([]byte(jsonStr), &analysis); err != nil {
		return nil, fmt.Errorf("è§£æ JSON å¤±è´¥: %w\nåŸå§‹å“åº”: %s\næå–çš„JSON: %s", err, response, jsonStr)
	}

	return &analysis, nil
}

// å‘é€é€šçŸ¥ï¼ˆæ”¯æŒå¤šç§æ–¹å¼ï¼‰
func sendNotification(summary, logLine string) {
	// æˆªæ–­æ—¥å¿—å†…å®¹ï¼Œé¿å…é€šçŸ¥å¤ªé•¿
	displayLog := logLine
	if len(displayLog) > 100 {
		displayLog = displayLog[:100] + "..."
	}

	// å‘é€ç³»ç»Ÿé€šçŸ¥
	sendSystemNotification(summary, displayLog)

	// å‘é€é‚®ä»¶é€šçŸ¥
	if globalConfig.Notifiers.Email.Enabled {
		go safeSendEmailNotification(summary, logLine)
	}

	// å‘é€webhooké€šçŸ¥
	if globalConfig.Notifiers.DingTalk.Enabled {
		go safeSendWebhookNotification(globalConfig.Notifiers.DingTalk, summary, logLine, "dingtalk")
	}
	if globalConfig.Notifiers.WeChat.Enabled {
		go safeSendWebhookNotification(globalConfig.Notifiers.WeChat, summary, logLine, "wechat")
	}
	if globalConfig.Notifiers.Feishu.Enabled {
		go safeSendWebhookNotification(globalConfig.Notifiers.Feishu, summary, logLine, "feishu")
	}
	if globalConfig.Notifiers.Slack.Enabled {
		go safeSendWebhookNotification(globalConfig.Notifiers.Slack, summary, logLine, "slack")
	}

	// å‘é€è‡ªå®šä¹‰webhooké€šçŸ¥
	for _, webhook := range globalConfig.Notifiers.CustomWebhooks {
		if webhook.Enabled {
			go safeSendWebhookNotification(webhook, summary, logLine, "custom")
		}
	}
}

// å‘é€ç³»ç»Ÿé€šçŸ¥
func sendSystemNotification(summary, displayLog string) {
	// æ£€æµ‹æ“ä½œç³»ç»Ÿå¹¶å‘é€ç›¸åº”çš„é€šçŸ¥
	if isMacOS() {
		sendMacOSNotification(summary, displayLog)
	} else if isLinux() {
		sendLinuxNotification(summary, displayLog)
	} else {
		if *verbose || *debug {
			log.Printf("âš ï¸  ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿï¼Œè·³è¿‡ç³»ç»Ÿé€šçŸ¥")
		}
		return
	}

	// æ’­æ”¾ç³»ç»Ÿå£°éŸ³
	go playSystemSound()
}

// æ£€æµ‹æ˜¯å¦ä¸º macOS
func isMacOS() bool {
	return strings.Contains(strings.ToLower(runtime.GOOS), "darwin")
}

// æ£€æµ‹æ˜¯å¦ä¸º Linux
func isLinux() bool {
	return strings.Contains(strings.ToLower(runtime.GOOS), "linux")
}

// å‘é€ macOS é€šçŸ¥
func sendMacOSNotification(summary, displayLog string) {
	// ä½¿ç”¨ osascript é€šè¿‡æ ‡å‡†è¾“å…¥å‘é€é€šçŸ¥ï¼ˆæ›´å¥½åœ°æ”¯æŒ UTF-8 ä¸­æ–‡ï¼‰
	script := fmt.Sprintf(`display notification "%s" with title "âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦" subtitle "%s"`,
		escapeForAppleScript(displayLog),
		escapeForAppleScript(summary))

	cmd := exec.Command("osascript", "-")
	cmd.Stdin = strings.NewReader(script)

	// è®¾ç½®ç¯å¢ƒå˜é‡ç¡®ä¿ä½¿ç”¨ UTF-8
	cmd.Env = append(os.Environ(), "LANG=zh_CN.UTF-8")

	err := cmd.Run()

	if err != nil {
		if *verbose || *debug {
			log.Printf("âš ï¸  å‘é€ macOS é€šçŸ¥å¤±è´¥: %v", err)
			log.Printf("ğŸ’¡ è¯·æ£€æŸ¥é€šçŸ¥æƒé™ï¼šç³»ç»Ÿè®¾ç½® > é€šçŸ¥ > ç»ˆç«¯")
		}
	} else {
		if *verbose || *debug {
			log.Printf("âœ… macOS é€šçŸ¥å·²å‘é€: %s", summary)
		}
	}
}

// å‘é€ Linux é€šçŸ¥
func sendLinuxNotification(summary, displayLog string) {
	// å°è¯•ä½¿ç”¨ notify-send (éœ€è¦å®‰è£… libnotify-bin)
	cmd := exec.Command("notify-send",
		"âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦",
		fmt.Sprintf("%s\n%s", summary, displayLog),
		"--urgency=critical",
		"--expire-time=10000")

	err := cmd.Run()

	if err != nil {
		// å¦‚æœ notify-send å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ–¹å¼
		if *verbose || *debug {
			log.Printf("âš ï¸  notify-send å¤±è´¥ï¼Œå°è¯•å…¶ä»–é€šçŸ¥æ–¹å¼: %v", err)
		}

		// å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»– Linux é€šçŸ¥æ–¹å¼ï¼Œæ¯”å¦‚ï¼š
		// - å†™å…¥åˆ°ç³»ç»Ÿæ—¥å¿—
		// - å‘é€åˆ°æ¡Œé¢é€šçŸ¥æœåŠ¡
		// - ç­‰ç­‰

		if *verbose || *debug {
			log.Printf("âš ï¸  Linux ç³»ç»Ÿé€šçŸ¥å‘é€å¤±è´¥")
		}
		return
	}

	if *verbose || *debug {
		log.Printf("âœ… Linux é€šçŸ¥å·²å‘é€: %s", summary)
	}
}

// æ’­æ”¾ç³»ç»Ÿæç¤ºéŸ³
func playSystemSound() {
	if isMacOS() {
		playMacOSSound()
	} else if isLinux() {
		playLinuxSound()
	}
	// å…¶ä»–å¹³å°ä¸æ’­æ”¾å£°éŸ³ï¼Œé™é»˜å¤±è´¥
}

// æ’­æ”¾ macOS ç³»ç»Ÿå£°éŸ³
func playMacOSSound() {
	// ä½¿ç”¨ afplay æ’­æ”¾ç³»ç»Ÿå£°éŸ³æ–‡ä»¶ï¼ˆç»éªŒè¯æ­¤æ–¹å¼å¯é ï¼‰
	soundPaths := []string{
		"/System/Library/Sounds/Glass.aiff",
		"/System/Library/Sounds/Ping.aiff",
		"/System/Library/Sounds/Pop.aiff",
		"/System/Library/Sounds/Purr.aiff",
		"/System/Library/Sounds/Bottle.aiff",
		"/System/Library/Sounds/Funk.aiff",
	}

	for _, soundPath := range soundPaths {
		cmd := exec.Command("afplay", soundPath)
		if err := cmd.Run(); err == nil {
			if *verbose || *debug {
				log.Printf("ğŸ”Š æ’­æ”¾ macOS å£°éŸ³: %s", soundPath)
			}
			return // æ’­æ”¾æˆåŠŸ
		}
	}

	// å¦‚æœæ‰€æœ‰å£°éŸ³æ–‡ä»¶éƒ½å¤±è´¥ï¼Œä½¿ç”¨ beep ä½œä¸ºæœ€åä¿éšœ
	if *verbose || *debug {
		log.Printf("âš ï¸  macOS å£°éŸ³æ–‡ä»¶ä¸å¯ç”¨ï¼Œä½¿ç”¨ beep")
	}
	cmd := exec.Command("osascript", "-e", "beep 1")
	cmd.Run()
}

// æ’­æ”¾ Linux ç³»ç»Ÿå£°éŸ³
func playLinuxSound() {
	// å°è¯•ä½¿ç”¨ paplay (PulseAudio)
	cmd := exec.Command("paplay", "/usr/share/sounds/alsa/Front_Left.wav")
	if err := cmd.Run(); err == nil {
		if *verbose || *debug {
			log.Printf("ğŸ”Š æ’­æ”¾ Linux å£°éŸ³: PulseAudio")
		}
		return
	}

	// å°è¯•ä½¿ç”¨ aplay (ALSA)
	cmd = exec.Command("aplay", "/usr/share/sounds/alsa/Front_Left.wav")
	if err := cmd.Run(); err == nil {
		if *verbose || *debug {
			log.Printf("ğŸ”Š æ’­æ”¾ Linux å£°éŸ³: ALSA")
		}
		return
	}

	// å°è¯•ä½¿ç”¨ speaker-test (ç”Ÿæˆæµ‹è¯•éŸ³)
	cmd = exec.Command("speaker-test", "-t", "sine", "-f", "1000", "-l", "1")
	if err := cmd.Run(); err == nil {
		if *verbose || *debug {
			log.Printf("ğŸ”Š æ’­æ”¾ Linux å£°éŸ³: speaker-test")
		}
		return
	}

	// å¦‚æœæ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥ï¼Œé™é»˜å¤±è´¥
	if *verbose || *debug {
		log.Printf("âš ï¸  Linux å£°éŸ³æ’­æ”¾å¤±è´¥")
	}
}

// è½¬ä¹‰ AppleScript å­—ç¬¦ä¸²
func escapeForAppleScript(s string) string {
	s = strings.ReplaceAll(s, "\\", "\\\\")
	s = strings.ReplaceAll(s, "\"", "\\\"")
	s = strings.ReplaceAll(s, "\n", " ")
	s = strings.ReplaceAll(s, "\r", " ")
	return s
}

// è·å–æ–‡ä»¶ inodeï¼ˆç”¨äºæ£€æµ‹æ–‡ä»¶è½®è½¬ï¼‰
func getInode(info os.FileInfo) uint64 {
	if stat, ok := info.Sys().(*syscall.Stat_t); ok {
		return stat.Ino
	}
	return 0
}

// åˆ›å»ºæ—¥å¿—è¡Œåˆå¹¶å™¨
func NewLogLineMerger(format string) *LogLineMerger {
	return &LogLineMerger{
		format:      format,
		buffer:      "",
		hasBuffered: false,
	}
}

// åˆ¤æ–­ä¸€è¡Œæ˜¯å¦æ˜¯æ–°æ—¥å¿—æ¡ç›®çš„å¼€å§‹
func isNewLogLine(line string, format string) bool {
	// ç©ºè¡Œä¸æ˜¯æ–°æ—¥å¿—
	if strings.TrimSpace(line) == "" {
		return false
	}

	switch format {
	case "java":
		// Java æ—¥å¿—é€šå¸¸ä»¥æ—¶é—´æˆ³æˆ–æ—¥å¿—çº§åˆ«å¼€å¤´
		// å¸¸è§æ ¼å¼ï¼š
		// - 2024-01-01 12:00:00
		// - [2024-01-01 12:00:00]
		// - 2024-01-01T12:00:00.000Z
		// - INFO: ...
		// - [INFO] ...
		// å †æ ˆè·Ÿè¸ªè¡Œé€šå¸¸æ˜¯ï¼š
		// - ä»¥ç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦å¼€å¤´
		// - "at " å¼€å¤´
		// - "Caused by:" å¼€å¤´
		// - "..." å¼€å¤´ï¼ˆçœç•¥çš„å †æ ˆï¼‰
		// - å¼‚å¸¸ç±»åå¼€å¤´ï¼ˆå¦‚ java.lang.NullPointerExceptionï¼‰

		// å¦‚æœä»¥ç©ºç™½å­—ç¬¦å¼€å¤´ï¼Œé€šå¸¸æ˜¯ç»­è¡Œ
		if len(line) > 0 && (line[0] == ' ' || line[0] == '\t') {
			return false
		}

		// å †æ ˆè·Ÿè¸ªç‰¹å¾
		trimmed := strings.TrimSpace(line)
		if strings.HasPrefix(trimmed, "at ") ||
			strings.HasPrefix(trimmed, "Caused by:") ||
			strings.HasPrefix(trimmed, "Suppressed:") ||
			strings.HasPrefix(trimmed, "...") {
			return false
		}

		// æ£€æŸ¥æ˜¯å¦æ˜¯å¼‚å¸¸ç±»åï¼ˆé€šå¸¸åŒ…å«åŒ…åå’Œå¼‚å¸¸ç±»å‹ï¼‰
		// ä¾‹å¦‚ï¼šjava.lang.NullPointerException, com.example.CustomException
		// ä½†è¦æ’é™¤ä»¥æ—¶é—´æˆ³æˆ–æ—¥å¿—çº§åˆ«å¼€å¤´çš„æƒ…å†µ
		if strings.Contains(trimmed, "Exception") ||
			strings.Contains(trimmed, "Error") ||
			strings.Contains(trimmed, "Throwable") {
			// å¦‚æœåŒ…å«å¼‚å¸¸å…³é”®è¯ï¼Œä½†ä¸ä»¥æ—¶é—´æˆ³å¼€å¤´ï¼Œè®¤ä¸ºæ˜¯ç»­è¡Œ
			if !regexp.MustCompile(`^\d{4}-\d{2}-\d{2}|^\[|^\d{2}:\d{2}:\d{2}`).MatchString(line) {
				return false
			}
		}

		// æ—¶é—´æˆ³æ­£åˆ™ï¼šåŒ¹é…å¸¸è§çš„æ—¶é—´æ ¼å¼
		timestampPatterns := []string{
			`^\d{4}-\d{2}-\d{2}`,                     // 2024-01-01
			`^\[\d{4}-\d{2}-\d{2}`,                   // [2024-01-01
			`^\d{2}:\d{2}:\d{2}`,                     // 12:00:00
			`^(INFO|DEBUG|WARN|ERROR|TRACE|FATAL)`,   // æ—¥å¿—çº§åˆ«å¼€å¤´
			`^\[(INFO|DEBUG|WARN|ERROR|TRACE|FATAL)`, // [INFO]
		}

		for _, pattern := range timestampPatterns {
			if matched, _ := regexp.MatchString(pattern, line); matched {
				return true
			}
		}

		// é»˜è®¤ï¼šå¦‚æœä¸åŒ¹é…æ–°è¡Œç‰¹å¾ï¼Œè®¤ä¸ºæ˜¯ç»­è¡Œï¼ˆä¿å®ˆç­–ç•¥ï¼‰
		return false

	case "python", "fastapi":
		// Python æ—¥å¿—æ ¼å¼ç±»ä¼¼ Java
		// å¦‚æœä»¥ç©ºç™½å­—ç¬¦å¼€å¤´ï¼Œé€šå¸¸æ˜¯ç»­è¡Œ
		if len(line) > 0 && (line[0] == ' ' || line[0] == '\t') {
			return false
		}

		trimmed := strings.TrimSpace(line)

		// Python å †æ ˆè·Ÿè¸ªç‰¹å¾
		if strings.HasPrefix(trimmed, "Traceback") ||
			strings.HasPrefix(trimmed, "File ") ||
			strings.HasPrefix(trimmed, "During handling") {
			return false
		}

		// Python å¼‚å¸¸ç±»åï¼ˆç±»ä¼¼ Javaï¼‰
		// ä¾‹å¦‚ï¼šValueError, KeyError, sqlalchemy.exc.OperationalError
		if (strings.Contains(trimmed, "Error:") ||
			strings.Contains(trimmed, "Exception:") ||
			strings.Contains(trimmed, "Warning:")) &&
			!regexp.MustCompile(`^\d{4}-\d{2}-\d{2}|^\[`).MatchString(line) {
			return false
		}

		// æ—¶é—´æˆ³æ£€æŸ¥
		timestampPatterns := []string{
			`^\d{4}-\d{2}-\d{2}`,                     // 2024-01-01
			`^\[\d{4}-\d{2}-\d{2}`,                   // [2024-01-01
			`^\d{2}:\d{2}:\d{2}`,                     // 12:00:00
			`^(INFO|DEBUG|WARNING|ERROR|CRITICAL)`,   // æ—¥å¿—çº§åˆ«å¼€å¤´
			`^\[(INFO|DEBUG|WARNING|ERROR|CRITICAL)`, // [INFO]
		}

		for _, pattern := range timestampPatterns {
			if matched, _ := regexp.MatchString(pattern, line); matched {
				return true
			}
		}

		// é»˜è®¤ï¼šå¦‚æœä¸åŒ¹é…æ–°è¡Œç‰¹å¾ï¼Œè®¤ä¸ºæ˜¯ç»­è¡Œ
		return false

	case "php":
		// PHP æ—¥å¿—é€šå¸¸ä»¥ [æ—¥æœŸ] å¼€å¤´
		// [01-Jan-2024 12:00:00] PHP Error: ...
		if matched, _ := regexp.MatchString(`^\[[\d-]+.*?\]`, line); matched {
			return true
		}

		// ç»­è¡Œé€šå¸¸ä¸ä»¥ [ å¼€å¤´
		if len(line) > 0 && line[0] != '[' {
			return false
		}

		return true

	case "nginx":
		// Nginx è®¿é—®æ—¥å¿—é€šå¸¸ä»¥ IP åœ°å€å¼€å¤´
		// 192.168.1.1 - - [01/Jan/2024:12:00:00 +0000] ...
		if matched, _ := regexp.MatchString(`^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}`, line); matched {
			return true
		}

		// Nginx é”™è¯¯æ—¥å¿—ä»¥æ—¶é—´æˆ³å¼€å¤´
		// 2024/01/01 12:00:00 [error] ...
		if matched, _ := regexp.MatchString(`^\d{4}/\d{2}/\d{2}`, line); matched {
			return true
		}

		return true

	case "ruby":
		// Ruby æ—¥å¿—æ ¼å¼ç±»ä¼¼å…¶ä»–è¯­è¨€
		if len(line) > 0 && (line[0] == ' ' || line[0] == '\t') {
			return false
		}

		// Ruby å †æ ˆè·Ÿè¸ª
		if strings.Contains(line, ".rb:") && !strings.Contains(line, "[") {
			return false
		}

		if matched, _ := regexp.MatchString(`^\[|\d{4}-\d{2}-\d{2}`, line); matched {
			return true
		}

		return true

	default:
		// é»˜è®¤ï¼šä»¥æ—¶é—´æˆ³æˆ–æ—¥å¿—çº§åˆ«å¼€å¤´çš„è®¤ä¸ºæ˜¯æ–°è¡Œ
		if matched, _ := regexp.MatchString(`^\d{4}-\d{2}-\d{2}|^\[|^(INFO|DEBUG|WARN|ERROR)`, line); matched {
			return true
		}
		return true
	}
}

// æ·»åŠ ä¸€è¡Œåˆ°åˆå¹¶å™¨
// è¿”å›å€¼ï¼šå®Œæ•´çš„æ—¥å¿—è¡Œï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œæ˜¯å¦æœ‰å®Œæ•´è¡Œ
func (m *LogLineMerger) Add(line string) (string, bool) {
	// åˆ¤æ–­è¿™ä¸€è¡Œæ˜¯å¦æ˜¯æ–°æ—¥å¿—çš„å¼€å§‹
	if isNewLogLine(line, m.format) {
		// å¦‚æœç¼“å†²åŒºæœ‰å†…å®¹ï¼Œå…ˆè¿”å›ç¼“å†²åŒºçš„å†…å®¹
		if m.hasBuffered {
			oldBuffer := m.buffer
			m.buffer = line
			m.hasBuffered = true
			return oldBuffer, true
		} else {
			// ç¼“å†²åŒºä¸ºç©ºï¼Œç›´æ¥ç¼“å­˜è¿™ä¸€è¡Œ
			m.buffer = line
			m.hasBuffered = true
			return "", false
		}
	} else {
		// è¿™ä¸€è¡Œæ˜¯ç»­è¡Œï¼Œæ‹¼æ¥åˆ°ç¼“å†²åŒº
		if m.hasBuffered {
			m.buffer = m.buffer + "\n" + line
		} else {
			// æ²¡æœ‰ç¼“å†²ï¼Œè¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼ˆç¬¬ä¸€è¡Œå°±æ˜¯ç»­è¡Œï¼‰
			// ä½†ä¸ºäº†å¥å£®æ€§ï¼Œè¿˜æ˜¯ç¼“å­˜å®ƒ
			m.buffer = line
			m.hasBuffered = true
		}
		return "", false
	}
}

// åˆ·æ–°åˆå¹¶å™¨ï¼Œè¿”å›ç¼“å†²åŒºä¸­çš„å†…å®¹
func (m *LogLineMerger) Flush() (string, bool) {
	if m.hasBuffered {
		result := m.buffer
		m.buffer = ""
		m.hasBuffered = false
		return result, true
	}
	return "", false
}

// å®‰å…¨å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆå¸¦panicæ¢å¤å’Œè¶…æ—¶æ§åˆ¶ï¼‰
func safeSendEmailNotification(summary, logLine string) {
	defer func() {
		if r := recover(); r != nil {
			if *verbose || *debug {
				log.Printf("âŒ é‚®ä»¶é€šçŸ¥panicæ¢å¤: %v", r)
			}
		}
	}()

	// ä½¿ç”¨contextæ§åˆ¶è¶…æ—¶
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	// ä½¿ç”¨channelæ§åˆ¶å¹¶å‘
	done := make(chan error, 1)
	go func() {
		done <- sendEmailNotificationWithContext(ctx, summary, logLine)
	}()

	select {
	case err := <-done:
		if err != nil && (*verbose || *debug) {
			log.Printf("âŒ é‚®ä»¶å‘é€å¤±è´¥: %v", err)
		}
	case <-ctx.Done():
		if *verbose || *debug {
			log.Printf("âŒ é‚®ä»¶å‘é€è¶…æ—¶: %v", ctx.Err())
		}
	}
}

// å¸¦contextçš„é‚®ä»¶å‘é€å‡½æ•°
func sendEmailNotificationWithContext(ctx context.Context, summary, logLine string) error {
	emailConfig := globalConfig.Notifiers.Email

	if !emailConfig.Enabled || len(emailConfig.ToEmails) == 0 {
		return nil
	}

	subject := fmt.Sprintf("âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦: %s", summary)
	body := fmt.Sprintf(`
é‡è¦æ—¥å¿—å‘Šè­¦

æ‘˜è¦: %s

æ—¥å¿—å†…å®¹:
%s

æ–‡ä»¶: %s

æ—¶é—´: %s
æ¥æº: AIPipe æ—¥å¿—ç›‘æ§ç³»ç»Ÿ
`, summary, logLine, currentLogFile, time.Now().Format("2006-01-02 15:04:05"))

	var err error
	if emailConfig.Provider == "resend" {
		err = sendResendEmailWithContext(ctx, emailConfig, subject, body)
	} else {
		err = sendSMTPEmailWithContext(ctx, emailConfig, subject, body)
	}

	if err != nil {
		return fmt.Errorf("é‚®ä»¶å‘é€å¤±è´¥: %w", err)
	}

	if *verbose || *debug {
		log.Printf("âœ… é‚®ä»¶å·²å‘é€: %s", subject)
	}
	return nil
}

// å‘é€é‚®ä»¶é€šçŸ¥ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
func sendEmailNotification(summary, logLine string) {
	ctx := context.Background()
	if err := sendEmailNotificationWithContext(ctx, summary, logLine); err != nil {
		if *verbose || *debug {
			log.Printf("âŒ é‚®ä»¶å‘é€å¤±è´¥: %v", err)
		}
	}
}

// å¸¦contextçš„SMTPé‚®ä»¶å‘é€
func sendSMTPEmailWithContext(ctx context.Context, config EmailConfig, subject, body string) error {
	// æ£€æŸ¥contextæ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
	}

	// æ„å»ºé‚®ä»¶å†…å®¹
	msg := fmt.Sprintf("From: %s\r\nTo: %s\r\nSubject: %s\r\n\r\n%s",
		config.FromEmail, strings.Join(config.ToEmails, ","), subject, body)

	// æ„å»ºSMTPåœ°å€
	addr := fmt.Sprintf("%s:%d", config.Host, config.Port)

	// åˆ›å»ºTLSé…ç½®
	tlsConfig := &tls.Config{
		ServerName: config.Host,
	}

	// å»ºç«‹è¿æ¥
	conn, err := tls.Dial("tcp", addr, tlsConfig)
	if err != nil {
		return fmt.Errorf("TLSè¿æ¥å¤±è´¥: %w", err)
	}
	defer conn.Close()

	// åˆ›å»ºSMTPå®¢æˆ·ç«¯
	client, err := smtp.NewClient(conn, config.Host)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºSMTPå®¢æˆ·ç«¯å¤±è´¥: %w", err)
	}
	defer client.Quit()

	// è®¤è¯
	auth := smtp.PlainAuth("", config.Username, config.Password, config.Host)
	if err := client.Auth(auth); err != nil {
		return fmt.Errorf("SMTPè®¤è¯å¤±è´¥: %w", err)
	}

	// å‘é€é‚®ä»¶
	if err := client.Mail(config.FromEmail); err != nil {
		return fmt.Errorf("è®¾ç½®å‘ä»¶äººå¤±è´¥: %w", err)
	}

	for _, to := range config.ToEmails {
		if err := client.Rcpt(to); err != nil {
			return fmt.Errorf("è®¾ç½®æ”¶ä»¶äººå¤±è´¥: %w", err)
		}
	}

	writer, err := client.Data()
	if err != nil {
		return fmt.Errorf("è·å–æ•°æ®å†™å…¥å™¨å¤±è´¥: %w", err)
	}
	defer writer.Close()

	if _, err := writer.Write([]byte(msg)); err != nil {
		return fmt.Errorf("å†™å…¥é‚®ä»¶å†…å®¹å¤±è´¥: %w", err)
	}

	return nil
}

// å¸¦contextçš„Resendé‚®ä»¶å‘é€
func sendResendEmailWithContext(ctx context.Context, config EmailConfig, subject, body string) error {
	// æ£€æŸ¥contextæ˜¯å¦å·²å–æ¶ˆ
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
	}

	// æ„å»ºè¯·æ±‚
	payload := map[string]interface{}{
		"from":    config.FromEmail,
		"to":      config.ToEmails,
		"subject": subject,
		"html":    body,
	}

	jsonData, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–è¯·æ±‚å¤±è´¥: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, "POST", "https://api.resend.com/emails", bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+config.Password) // ä½¿ç”¨passwordå­—æ®µå­˜å‚¨API key

	client := &http.Client{Timeout: 10 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("å‘é€è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode < 200 || resp.StatusCode >= 300 {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("resend APIé”™è¯¯ %d: %s", resp.StatusCode, string(body))
	}

	return nil
}

// é€šè¿‡SMTPå‘é€é‚®ä»¶
func sendSMTPEmail(config EmailConfig, subject, body string) error {
	// æ„å»ºé‚®ä»¶å†…å®¹
	message := fmt.Sprintf("From: %s\r\nTo: %s\r\nSubject: %s\r\nContent-Type: text/plain; charset=UTF-8\r\n\r\n%s",
		config.FromEmail, strings.Join(config.ToEmails, ","), subject, body)

	// è¿æ¥SMTPæœåŠ¡å™¨
	addr := fmt.Sprintf("%s:%d", config.Host, config.Port)
	auth := smtp.PlainAuth("", config.Username, config.Password, config.Host)

	// ä½¿ç”¨ç»Ÿä¸€çš„SMTPå‘é€æ–¹å¼
	err := smtp.SendMail(addr, auth, config.FromEmail, config.ToEmails, []byte(message))

	return err
}

// SSLé‚®ä»¶å‘é€

// é€šè¿‡Resend APIå‘é€é‚®ä»¶
func sendResendEmail(config EmailConfig, subject, body string) error {
	type ResendRequest struct {
		From    string   `json:"from"`
		To      []string `json:"to"`
		Subject string   `json:"subject"`
		Text    string   `json:"text"`
	}

	reqBody := ResendRequest{
		From:    config.FromEmail,
		To:      config.ToEmails,
		Subject: subject,
		Text:    body,
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return err
	}

	req, err := http.NewRequest("POST", "https://api.resend.com/emails", bytes.NewBuffer(jsonData))
	if err != nil {
		return err
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+config.Password)

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("resend API error: %s", string(body))
	}

	return nil
}

// å®‰å…¨å‘é€webhooké€šçŸ¥ï¼ˆå¸¦panicæ¢å¤å’Œè¶…æ—¶æ§åˆ¶ï¼‰
func safeSendWebhookNotification(config WebhookConfig, summary, logLine, webhookType string) {
	defer func() {
		if r := recover(); r != nil {
			if *verbose || *debug {
				log.Printf("âŒ %s webhooké€šçŸ¥panicæ¢å¤: %v", webhookType, r)
			}
		}
	}()

	// ä½¿ç”¨contextæ§åˆ¶è¶…æ—¶
	ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
	defer cancel()

	// ä½¿ç”¨channelæ§åˆ¶å¹¶å‘
	done := make(chan error, 1)
	go func() {
		done <- sendWebhookNotificationWithContext(ctx, config, summary, logLine, webhookType)
	}()

	select {
	case err := <-done:
		if err != nil && (*verbose || *debug) {
			log.Printf("âŒ %s webhookå‘é€å¤±è´¥: %v", webhookType, err)
		}
	case <-ctx.Done():
		if *verbose || *debug {
			log.Printf("âŒ %s webhookå‘é€è¶…æ—¶: %v", webhookType, ctx.Err())
		}
	}
}

// å¸¦contextçš„webhookå‘é€å‡½æ•°
func sendWebhookNotificationWithContext(ctx context.Context, config WebhookConfig, summary, logLine, webhookType string) error {
	if !config.Enabled || config.URL == "" {
		return nil
	}

	var payload interface{}

	// æ ¹æ®webhookç±»å‹æ„å»ºä¸åŒçš„payload
	switch webhookType {
	case "dingtalk":
		payload = buildDingTalkPayload(summary, logLine)
	case "wechat":
		payload = buildWeChatPayload(summary, logLine)
	case "feishu":
		payload = buildFeishuPayload(summary, logLine)
	case "slack":
		payload = buildSlackPayload(summary, logLine)
	default:
		payload = buildGenericPayload(summary, logLine)
	}

	jsonData, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("æ„å»ºwebhook payloadå¤±è´¥: %w", err)
	}

	req, err := http.NewRequest("POST", config.URL, bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("åˆ›å»ºwebhookè¯·æ±‚å¤±è´¥: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")

	// å¦‚æœé…ç½®äº†ç­¾åå¯†é’¥ï¼Œæ·»åŠ ç­¾å
	if config.Secret != "" {
		addWebhookSignature(req, jsonData, config.Secret, webhookType)
	}

	client := &http.Client{Timeout: 10 * time.Second}
	resp, err := client.Do(req.WithContext(ctx))
	if err != nil {
		return fmt.Errorf("å‘é€webhookå¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode < 200 || resp.StatusCode >= 300 {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("webhookå“åº”é”™è¯¯ %d: %s", resp.StatusCode, string(body))
	}

	if *verbose || *debug {
		log.Printf("âœ… %s webhookå·²å‘é€: %s", webhookType, summary)
	}
	return nil
}

// å‘é€webhooké€šçŸ¥ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
func sendWebhookNotification(config WebhookConfig, summary, logLine, webhookType string) {
	ctx := context.Background()
	if err := sendWebhookNotificationWithContext(ctx, config, summary, logLine, webhookType); err != nil {
		if *verbose || *debug {
			log.Printf("âŒ %s webhookå‘é€å¤±è´¥: %v", webhookType, err)
		}
	}
}

// æ„å»ºé’‰é’‰webhook payload
func buildDingTalkPayload(summary, logLine string) map[string]interface{} {
	content := fmt.Sprintf("âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦\n\nğŸ“‹ æ‘˜è¦: %s\n\nğŸ“ æ—¥å¿—å†…å®¹:\n%s\n\nğŸ“ æ–‡ä»¶: %s\n\nâ° æ—¶é—´: %s",
		summary, logLine, currentLogFile, time.Now().Format("2006-01-02 15:04:05"))

	return map[string]interface{}{
		"msgtype": "text",
		"text": map[string]string{
			"content": content,
		},
	}
}

// æ„å»ºä¼ä¸šå¾®ä¿¡webhook payload
func buildWeChatPayload(summary, logLine string) map[string]interface{} {
	content := fmt.Sprintf("âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦\n\nğŸ“‹ æ‘˜è¦: %s\n\nğŸ“ æ—¥å¿—å†…å®¹:\n%s\n\nğŸ“ æ–‡ä»¶: %s\n\nâ° æ—¶é—´: %s",
		summary, logLine, currentLogFile, time.Now().Format("2006-01-02 15:04:05"))

	return map[string]interface{}{
		"msgtype": "text",
		"text": map[string]string{
			"content": content,
		},
	}
}

// æ„å»ºé£ä¹¦webhook payload
func buildFeishuPayload(summary, logLine string) map[string]interface{} {
	// æ„å»ºæ›´è¯¦ç»†çš„é£ä¹¦é€šçŸ¥å†…å®¹
	content := fmt.Sprintf("âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦\n\nğŸ“‹ æ‘˜è¦: %s\n\nğŸ“ æ—¥å¿—å†…å®¹:\n%s\n\nğŸ“ æ–‡ä»¶: %s\n\nâ° æ—¶é—´: %s\n\nğŸ” æ¥æº: AIPipe æ—¥å¿—ç›‘æ§ç³»ç»Ÿ",
		summary, logLine, currentLogFile, time.Now().Format("2006-01-02 15:04:05"))

	return map[string]interface{}{
		"msg_type": "text",
		"content": map[string]string{
			"text": content,
		},
	}
}

// æ„å»ºSlack webhook payload
func buildSlackPayload(summary, logLine string) map[string]interface{} {
	text := fmt.Sprintf("âš ï¸ é‡è¦æ—¥å¿—å‘Šè­¦\n\n*æ‘˜è¦:* %s\n\n*æ—¥å¿—å†…å®¹:*\n```\n%s\n```\n\n*æ–‡ä»¶:* `%s`\n\n*æ—¶é—´:* %s",
		summary, logLine, currentLogFile, time.Now().Format("2006-01-02 15:04:05"))

	return map[string]interface{}{
		"text":       text,
		"username":   "AIPipe",
		"icon_emoji": ":warning:",
	}
}

// æ„å»ºé€šç”¨webhook payload
func buildGenericPayload(summary, logLine string) map[string]interface{} {
	return map[string]interface{}{
		"summary":   summary,
		"log_line":  logLine,
		"log_file":  currentLogFile,
		"timestamp": time.Now().Format("2006-01-02 15:04:05"),
		"source":    "AIPipe",
		"level":     "warning",
	}
}

// æ·»åŠ webhookç­¾å
func addWebhookSignature(req *http.Request, body []byte, secret, webhookType string) {
	// è¿™é‡Œå¯ä»¥å®ç°ä¸åŒwebhookå¹³å°çš„ç­¾åç®—æ³•
	// ç›®å‰åªæ˜¯å ä½ç¬¦å®ç°
	switch webhookType {
	case "dingtalk":
		// é’‰é’‰ç­¾åå®ç°
		// req.Header.Set("X-DingTalk-Signature", signature)
	case "wechat":
		// ä¼ä¸šå¾®ä¿¡ç­¾åå®ç°
		// req.Header.Set("X-WeChat-Signature", signature)
	case "feishu":
		// é£ä¹¦ç­¾åå®ç°
		// req.Header.Set("X-Feishu-Signature", signature)
	case "slack":
		// Slackç­¾åå®ç°
		// req.Header.Set("X-Slack-Signature", signature)
	default:
		// é€šç”¨ç­¾å
		// req.Header.Set("X-Webhook-Signature", signature)
	}
}

// æ™ºèƒ½è¯†åˆ«webhookç±»å‹
func detectWebhookType(webhookURL string) string {
	u, err := url.Parse(webhookURL)
	if err != nil {
		return "custom"
	}

	host := strings.ToLower(u.Host)
	path := strings.ToLower(u.Path)

	// é’‰é’‰
	if strings.Contains(host, "dingtalk") || strings.Contains(path, "dingtalk") {
		return "dingtalk"
	}

	// ä¼ä¸šå¾®ä¿¡
	if strings.Contains(host, "qyapi.weixin.qq.com") || strings.Contains(path, "wechat") {
		return "wechat"
	}

	// é£ä¹¦
	if strings.Contains(host, "feishu") || strings.Contains(path, "feishu") {
		return "feishu"
	}

	// Slack
	if strings.Contains(host, "slack.com") || strings.Contains(path, "slack") {
		return "slack"
	}

	return "custom"
}

// è§„åˆ™ç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// åˆ—å‡ºæ‰€æœ‰è¿‡æ»¤è§„åˆ™
func handleRuleList() {
	fmt.Println("ğŸ“‹ è¿‡æ»¤è§„åˆ™åˆ—è¡¨:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	rules := ruleEngine.GetRules()
	if len(rules) == 0 {
		fmt.Println("æ²¡æœ‰é…ç½®è¿‡æ»¤è§„åˆ™")
		return
	}

	for i, rule := range rules {
		status := "âŒ ç¦ç”¨"
		if rule.Enabled {
			status = "âœ… å¯ç”¨"
		}

		fmt.Printf("%d. %s %s\n", i+1, status, rule.Name)
		fmt.Printf("   ID: %s\n", rule.ID)
		fmt.Printf("   æ¨¡å¼: %s\n", rule.Pattern)
		fmt.Printf("   åŠ¨ä½œ: %s\n", rule.Action)
		fmt.Printf("   ä¼˜å…ˆçº§: %d\n", rule.Priority)
		fmt.Printf("   åˆ†ç±»: %s\n", rule.Category)
		if rule.Description != "" {
			fmt.Printf("   æè¿°: %s\n", rule.Description)
		}
		if rule.Color != "" {
			fmt.Printf("   é¢œè‰²: %s\n", rule.Color)
		}
		fmt.Println()
	}
}

// æµ‹è¯•è§„åˆ™
func handleRuleTest() {
	// è§£æå‚æ•°
	parts := strings.SplitN(*ruleTest, ",", 2)
	if len(parts) != 2 {
		fmt.Printf("âŒ å‚æ•°æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º: rule_id,test_line\n")
		os.Exit(1)
	}

	ruleID := parts[0]
	testLine := parts[1]

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("ğŸ§ª æµ‹è¯•è§„åˆ™: %s\n", ruleID)
	fmt.Printf("æµ‹è¯•è¡Œ: %s\n", testLine)
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	matched, err := ruleEngine.TestRule(ruleID, testLine)
	if err != nil {
		fmt.Printf("âŒ æµ‹è¯•å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	if matched {
		fmt.Printf("âœ… åŒ¹é…æˆåŠŸ\n")
	} else {
		fmt.Printf("âŒ ä¸åŒ¹é…\n")
	}
}

// æ˜¾ç¤ºè§„åˆ™å¼•æ“ç»Ÿè®¡ä¿¡æ¯
func handleRuleStats() {
	fmt.Println("ğŸ“Š è§„åˆ™å¼•æ“ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := ruleEngine.GetStats()
	fmt.Printf("æ€»è§„åˆ™æ•°: %d\n", stats.TotalRules)
	fmt.Printf("å¯ç”¨è§„åˆ™æ•°: %d\n", stats.EnabledRules)
	fmt.Printf("ç¼“å­˜å‘½ä¸­: %d\n", stats.CacheHits)
	fmt.Printf("ç¼“å­˜æœªå‘½ä¸­: %d\n", stats.CacheMisses)
	fmt.Printf("è¿‡æ»¤è¡Œæ•°: %d\n", stats.FilteredLines)
	fmt.Printf("å‘Šè­¦è¡Œæ•°: %d\n", stats.AlertedLines)
	fmt.Printf("å¿½ç•¥è¡Œæ•°: %d\n", stats.IgnoredLines)
	fmt.Printf("é«˜äº®è¡Œæ•°: %d\n", stats.HighlightedLines)

	// è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
	totalCache := stats.CacheHits + stats.CacheMisses
	if totalCache > 0 {
		hitRate := float64(stats.CacheHits) / float64(totalCache) * 100
		fmt.Printf("ç¼“å­˜å‘½ä¸­ç‡: %.2f%%\n", hitRate)
	}
}

// æ·»åŠ è§„åˆ™
func handleRuleAdd() {
	fmt.Println("â• æ·»åŠ è¿‡æ»¤è§„åˆ™...")

	// è§£æJSON
	var rule FilterRule
	if err := json.Unmarshal([]byte(*ruleAdd), &rule); err != nil {
		fmt.Printf("âŒ JSONè§£æå¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// éªŒè¯å¿…å¡«å­—æ®µ
	if rule.ID == "" {
		fmt.Printf("âŒ è§„åˆ™IDä¸èƒ½ä¸ºç©º\n")
		os.Exit(1)
	}
	if rule.Pattern == "" {
		fmt.Printf("âŒ è§„åˆ™æ¨¡å¼ä¸èƒ½ä¸ºç©º\n")
		os.Exit(1)
	}
	if rule.Action == "" {
		fmt.Printf("âŒ è§„åˆ™åŠ¨ä½œä¸èƒ½ä¸ºç©º\n")
		os.Exit(1)
	}

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æ·»åŠ è§„åˆ™
	if err := ruleEngine.AddRule(rule); err != nil {
		fmt.Printf("âŒ æ·»åŠ è§„åˆ™å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// ä¿å­˜è§„åˆ™åˆ°é…ç½®æ–‡ä»¶
	if err := saveRulesToConfig(); err != nil {
		fmt.Printf("âš ï¸  è§„åˆ™æ·»åŠ æˆåŠŸï¼Œä½†ä¿å­˜åˆ°é…ç½®æ–‡ä»¶å¤±è´¥: %v\n", err)
	} else {
		fmt.Printf("âœ… è§„åˆ™ %s æ·»åŠ å¹¶ä¿å­˜æˆåŠŸ\n", rule.ID)
	}
}

// åˆ é™¤è§„åˆ™
func handleRuleRemove() {
	ruleID := *ruleRemove

	fmt.Printf("ğŸ—‘ï¸  åˆ é™¤è§„åˆ™: %s\n", ruleID)

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// åˆ é™¤è§„åˆ™
	if err := ruleEngine.RemoveRule(ruleID); err != nil {
		fmt.Printf("âŒ åˆ é™¤è§„åˆ™å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// ä¿å­˜è§„åˆ™åˆ°é…ç½®æ–‡ä»¶
	if err := saveRulesToConfig(); err != nil {
		fmt.Printf("âš ï¸  è§„åˆ™åˆ é™¤æˆåŠŸï¼Œä½†ä¿å­˜åˆ°é…ç½®æ–‡ä»¶å¤±è´¥: %v\n", err)
	} else {
		fmt.Printf("âœ… è§„åˆ™ %s åˆ é™¤å¹¶ä¿å­˜æˆåŠŸ\n", ruleID)
	}
}

// å¯ç”¨è§„åˆ™
func handleRuleEnable() {
	ruleID := *ruleEnable

	fmt.Printf("âœ… å¯ç”¨è§„åˆ™: %s\n", ruleID)

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// å¯ç”¨è§„åˆ™
	if err := ruleEngine.SetRuleEnabled(ruleID, true); err != nil {
		fmt.Printf("âŒ å¯ç”¨è§„åˆ™å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("âœ… è§„åˆ™ %s å¯ç”¨æˆåŠŸ\n", ruleID)
}

// ç¦ç”¨è§„åˆ™
func handleRuleDisable() {
	ruleID := *ruleDisable

	fmt.Printf("âŒ ç¦ç”¨è§„åˆ™: %s\n", ruleID)

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// ç¦ç”¨è§„åˆ™
	if err := ruleEngine.SetRuleEnabled(ruleID, false); err != nil {
		fmt.Printf("âŒ ç¦ç”¨è§„åˆ™å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	fmt.Printf("âœ… è§„åˆ™ %s ç¦ç”¨æˆåŠŸ\n", ruleID)
}

// ä¿å­˜è§„åˆ™åˆ°é…ç½®æ–‡ä»¶
func saveRulesToConfig() error {
	// è·å–å½“å‰è§„åˆ™
	rules := ruleEngine.GetRules()

	// æ›´æ–°å…¨å±€é…ç½®
	globalConfig.Rules = rules

	// è·å–é…ç½®æ–‡ä»¶è·¯å¾„
	configPath, err := findDefaultConfig()
	if err != nil {
		return fmt.Errorf("æŸ¥æ‰¾é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// è¯»å–ç°æœ‰é…ç½®
	configData, err := os.ReadFile(configPath)
	if err != nil {
		return fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// è§£æç°æœ‰é…ç½®
	var config map[string]interface{}
	if err := json.Unmarshal(configData, &config); err != nil {
		return fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// æ›´æ–°è§„åˆ™
	config["rules"] = rules

	// ä¿å­˜é…ç½®
	updatedData, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–é…ç½®å¤±è´¥: %w", err)
	}

	if err := os.WriteFile(configPath, updatedData, 0644); err != nil {
		return fmt.Errorf("å†™å…¥é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
	}

	return nil
}

// ç¼“å­˜ç®¡ç†å™¨æ–¹æ³•

// åˆ›å»ºæ–°çš„ç¼“å­˜ç®¡ç†å™¨
func NewCacheManager(config CacheConfig) *CacheManager {
	cm := &CacheManager{
		aiCache:         make(map[string]*AIAnalysisCache),
		ruleCache:       make(map[string]*RuleMatchCache),
		configCache:     make(map[string]*CacheItem),
		maxSize:         config.MaxSize,
		maxItems:        config.MaxItems,
		cleanupInterval: config.CleanupInterval,
		stopCleanup:     make(chan bool),
	}

	// å¯åŠ¨æ¸…ç†åç¨‹
	if config.Enabled {
		go cm.startCleanup()
	}

	return cm
}

// å¯åŠ¨å®šæœŸæ¸…ç†
func (cm *CacheManager) startCleanup() {
	ticker := time.NewTicker(cm.cleanupInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			cm.cleanup()
		case <-cm.stopCleanup:
			return
		}
	}
}

// æ¸…ç†è¿‡æœŸç¼“å­˜
func (cm *CacheManager) cleanup() {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	now := time.Now()
	expiredCount := 0

	// æ¸…ç†AIåˆ†æç¼“å­˜
	for key, item := range cm.aiCache {
		if now.After(item.ExpiresAt) {
			delete(cm.aiCache, key)
			expiredCount++
		}
	}

	// æ¸…ç†è§„åˆ™åŒ¹é…ç¼“å­˜
	for key, item := range cm.ruleCache {
		if now.After(item.ExpiresAt) {
			delete(cm.ruleCache, key)
			expiredCount++
		}
	}

	// æ¸…ç†é…ç½®ç¼“å­˜
	for key, item := range cm.configCache {
		if now.After(item.ExpiresAt) {
			delete(cm.configCache, key)
			expiredCount++
		}
	}

	cm.stats.ExpiredItems = expiredCount
	cm.updateStats()
}

// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (cm *CacheManager) updateStats() {
	cm.stats.TotalItems = len(cm.aiCache) + len(cm.ruleCache) + len(cm.configCache)

	// è®¡ç®—å‘½ä¸­ç‡
	total := cm.stats.HitCount + cm.stats.MissCount
	if total > 0 {
		cm.stats.HitRate = float64(cm.stats.HitCount) / float64(total) * 100
	}

	// è®¡ç®—å†…å­˜ä½¿ç”¨é‡
	cm.stats.MemoryUsage = cm.calculateMemoryUsage()
}

// è®¡ç®—å†…å­˜ä½¿ç”¨é‡
func (cm *CacheManager) calculateMemoryUsage() int64 {
	var total int64

	for _, item := range cm.aiCache {
		total += int64(len(item.LogHash) + len(item.Result) + len(item.Model))
	}

	for _, item := range cm.ruleCache {
		total += int64(len(item.LogHash) + len(item.RuleID))
		if item.Result != nil {
			total += int64(len(item.Result.Action) + len(item.Result.RuleID))
		}
	}

	for _, item := range cm.configCache {
		total += int64(len(item.Key)) + item.Size
	}

	return total
}

// è·å–AIåˆ†æç»“æœ
func (cm *CacheManager) GetAIAnalysis(logHash string) (*AIAnalysisCache, bool) {
	cm.mutex.RLock()
	defer cm.mutex.RUnlock()

	item, exists := cm.aiCache[logHash]
	if !exists {
		cm.stats.MissCount++
		return nil, false
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(item.ExpiresAt) {
		cm.stats.MissCount++
		return nil, false
	}

	cm.stats.HitCount++
	return item, true
}

// è®¾ç½®AIåˆ†æç»“æœ
func (cm *CacheManager) SetAIAnalysis(logHash string, result *AIAnalysisCache) {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	// æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç©ºé—´
	if cm.needsEviction() {
		cm.evictOldest()
	}

	cm.aiCache[logHash] = result
	cm.updateStats()
}

// è·å–è§„åˆ™åŒ¹é…ç»“æœ
func (cm *CacheManager) GetRuleMatch(logHash, ruleID string) (*RuleMatchCache, bool) {
	cm.mutex.RLock()
	defer cm.mutex.RUnlock()

	key := logHash + ":" + ruleID
	item, exists := cm.ruleCache[key]
	if !exists {
		cm.stats.MissCount++
		return nil, false
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(item.ExpiresAt) {
		cm.stats.MissCount++
		return nil, false
	}

	cm.stats.HitCount++
	return item, true
}

// è®¾ç½®è§„åˆ™åŒ¹é…ç»“æœ
func (cm *CacheManager) SetRuleMatch(logHash, ruleID string, result *RuleMatchCache) {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	// æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç©ºé—´
	if cm.needsEviction() {
		cm.evictOldest()
	}

	key := logHash + ":" + ruleID
	cm.ruleCache[key] = result
	cm.updateStats()
}

// è·å–é…ç½®ç¼“å­˜
func (cm *CacheManager) GetConfig(key string) (interface{}, bool) {
	cm.mutex.RLock()
	defer cm.mutex.RUnlock()

	item, exists := cm.configCache[key]
	if !exists {
		cm.stats.MissCount++
		return nil, false
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(item.ExpiresAt) {
		cm.stats.MissCount++
		return nil, false
	}

	item.AccessCount++
	cm.stats.HitCount++
	return item.Value, true
}

// è®¾ç½®é…ç½®ç¼“å­˜
func (cm *CacheManager) SetConfig(key string, value interface{}, ttl time.Duration) {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	// æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç©ºé—´
	if cm.needsEviction() {
		cm.evictOldest()
	}

	now := time.Now()
	item := &CacheItem{
		Key:         key,
		Value:       value,
		CreatedAt:   now,
		ExpiresAt:   now.Add(ttl),
		AccessCount: 0,
		Size:        cm.calculateItemSize(value),
	}

	cm.configCache[key] = item
	cm.updateStats()
}

// è®¡ç®—é¡¹ç›®å¤§å°
func (cm *CacheManager) calculateItemSize(value interface{}) int64 {
	data, err := json.Marshal(value)
	if err != nil {
		return 0
	}
	return int64(len(data))
}

// æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
func (cm *CacheManager) needsEviction() bool {
	return cm.stats.MemoryUsage > cm.maxSize || cm.stats.TotalItems > cm.maxItems
}

// æ¸…ç†æœ€æ—§çš„é¡¹
func (cm *CacheManager) evictOldest() {
	// ç®€å•çš„LRUç­–ç•¥ï¼šæ¸…ç†è®¿é—®æ¬¡æ•°æœ€å°‘çš„é¡¹
	var oldestKey string
	var oldestAccess int = int(^uint(0) >> 1) // æœ€å¤§intå€¼

	for key, item := range cm.configCache {
		if item.AccessCount < oldestAccess {
			oldestAccess = item.AccessCount
			oldestKey = key
		}
	}

	if oldestKey != "" {
		delete(cm.configCache, oldestKey)
		cm.stats.EvictionCount++
	}
}

// æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
func (cm *CacheManager) Clear() {
	cm.mutex.Lock()
	defer cm.mutex.Unlock()

	cm.aiCache = make(map[string]*AIAnalysisCache)
	cm.ruleCache = make(map[string]*RuleMatchCache)
	cm.configCache = make(map[string]*CacheItem)
	cm.stats = CacheStats{}
}

// è·å–ç»Ÿè®¡ä¿¡æ¯
func (cm *CacheManager) GetStats() CacheStats {
	cm.mutex.RLock()
	defer cm.mutex.RUnlock()

	cm.updateStats()
	return cm.stats
}

// åœæ­¢ç¼“å­˜ç®¡ç†å™¨
func (cm *CacheManager) Stop() {
	close(cm.stopCleanup)
}

// ç”Ÿæˆæ—¥å¿—å“ˆå¸Œ
func generateLogHash(logLine string) string {
	hash := sha256.Sum256([]byte(logLine))
	return fmt.Sprintf("%x", hash)
}

// ç¼“å­˜ç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
func handleCacheStats() {
	fmt.Println("ğŸ“Š ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := cacheManager.GetStats()
	fmt.Printf("æ€»ç¼“å­˜é¡¹æ•°: %d\n", stats.TotalItems)
	fmt.Printf("ç¼“å­˜å‘½ä¸­æ¬¡æ•°: %d\n", stats.HitCount)
	fmt.Printf("ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°: %d\n", stats.MissCount)
	fmt.Printf("ç¼“å­˜å‘½ä¸­ç‡: %.2f%%\n", stats.HitRate)
	fmt.Printf("å†…å­˜ä½¿ç”¨é‡: %d å­—èŠ‚ (%.2f MB)\n", stats.MemoryUsage, float64(stats.MemoryUsage)/(1024*1024))
	fmt.Printf("æ¸…ç†æ¬¡æ•°: %d\n", stats.EvictionCount)
	fmt.Printf("è¿‡æœŸé¡¹æ•°: %d\n", stats.ExpiredItems)

	// æ˜¾ç¤ºå„ç±»å‹ç¼“å­˜è¯¦æƒ…
	fmt.Println("\nç¼“å­˜ç±»å‹è¯¦æƒ…:")
	fmt.Printf("  AIåˆ†æç¼“å­˜: %d é¡¹\n", len(cacheManager.aiCache))
	fmt.Printf("  è§„åˆ™åŒ¹é…ç¼“å­˜: %d é¡¹\n", len(cacheManager.ruleCache))
	fmt.Printf("  é…ç½®ç¼“å­˜: %d é¡¹\n", len(cacheManager.configCache))
}

// æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
func handleCacheClear() {
	fmt.Println("ğŸ—‘ï¸  æ¸…ç©ºæ‰€æœ‰ç¼“å­˜...")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	cacheManager.Clear()
	fmt.Println("âœ… æ‰€æœ‰ç¼“å­˜å·²æ¸…ç©º")
}

// æµ‹è¯•ç¼“å­˜åŠŸèƒ½
func handleCacheTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•ç¼“å­˜åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æµ‹è¯•é…ç½®ç¼“å­˜
	testKey := "test_config"
	testValue := map[string]interface{}{
		"test":    "value",
		"number":  123,
		"enabled": true,
	}

	fmt.Println("1. æµ‹è¯•é…ç½®ç¼“å­˜...")
	cacheManager.SetConfig(testKey, testValue, 1*time.Minute)

	if cached, found := cacheManager.GetConfig(testKey); found {
		fmt.Printf("   âœ… é…ç½®ç¼“å­˜æµ‹è¯•æˆåŠŸ: %v\n", cached)
	} else {
		fmt.Println("   âŒ é…ç½®ç¼“å­˜æµ‹è¯•å¤±è´¥")
	}

	// æµ‹è¯•AIåˆ†æç¼“å­˜
	testLogHash := generateLogHash("test log line")
	aiResult := &AIAnalysisCache{
		LogHash:    testLogHash,
		Result:     "This is a test log",
		Confidence: 0.95,
		Model:      "gpt-4",
		CreatedAt:  time.Now(),
		ExpiresAt:  time.Now().Add(1 * time.Hour),
	}

	fmt.Println("2. æµ‹è¯•AIåˆ†æç¼“å­˜...")
	cacheManager.SetAIAnalysis(testLogHash, aiResult)

	if cached, found := cacheManager.GetAIAnalysis(testLogHash); found {
		fmt.Printf("   âœ… AIåˆ†æç¼“å­˜æµ‹è¯•æˆåŠŸ: %s\n", cached.Result)
	} else {
		fmt.Println("   âŒ AIåˆ†æç¼“å­˜æµ‹è¯•å¤±è´¥")
	}

	// æµ‹è¯•è§„åˆ™åŒ¹é…ç¼“å­˜
	testRuleID := "test_rule"
	ruleResult := &RuleMatchCache{
		LogHash:   testLogHash,
		RuleID:    testRuleID,
		Matched:   true,
		Result:    &FilterResult{Action: "highlight", RuleID: testRuleID},
		CreatedAt: time.Now(),
		ExpiresAt: time.Now().Add(1 * time.Hour),
	}

	fmt.Println("3. æµ‹è¯•è§„åˆ™åŒ¹é…ç¼“å­˜...")
	cacheManager.SetRuleMatch(testLogHash, testRuleID, ruleResult)

	if cached, found := cacheManager.GetRuleMatch(testLogHash, testRuleID); found {
		fmt.Printf("   âœ… è§„åˆ™åŒ¹é…ç¼“å­˜æµ‹è¯•æˆåŠŸ: %s\n", cached.Result.Action)
	} else {
		fmt.Println("   âŒ è§„åˆ™åŒ¹é…ç¼“å­˜æµ‹è¯•å¤±è´¥")
	}

	// æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
	fmt.Println("\næœ€ç»ˆç¼“å­˜ç»Ÿè®¡:")
	stats := cacheManager.GetStats()
	fmt.Printf("  æ€»ç¼“å­˜é¡¹æ•°: %d\n", stats.TotalItems)
	fmt.Printf("  ç¼“å­˜å‘½ä¸­ç‡: %.2f%%\n", stats.HitRate)
	fmt.Printf("  å†…å­˜ä½¿ç”¨é‡: %.2f KB\n", float64(stats.MemoryUsage)/1024)

	fmt.Println("\nâœ… ç¼“å­˜åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}

// å·¥ä½œæ± æ–¹æ³•

// åˆ›å»ºæ–°çš„å·¥ä½œæ± 
func NewWorkerPool(config WorkerPoolConfig) *WorkerPool {
	wp := &WorkerPool{
		config:     config,
		jobQueue:   make(chan ProcessingJob, config.QueueSize),
		resultChan: make(chan ProcessingResult, config.QueueSize),
		workerPool: make(chan chan ProcessingJob, config.MaxWorkers),
		workers:    make([]*Worker, 0, config.MaxWorkers),
		quit:       make(chan bool),
		startTime:  time.Now(),
	}

	// åˆ›å»ºå·¥ä½œåç¨‹
	for i := 0; i < config.MaxWorkers; i++ {
		worker := NewWorker(i, wp)
		wp.workers = append(wp.workers, worker)
		worker.Start()
	}

	// å¯åŠ¨è°ƒåº¦å™¨
	go wp.dispatch()

	return wp
}

// åˆ›å»ºæ–°çš„å·¥ä½œåç¨‹
func NewWorker(id int, wp *WorkerPool) *Worker {
	return &Worker{
		ID:            id,
		WorkerPool:    wp.workerPool,
		JobChannel:    make(chan ProcessingJob),
		Quit:          make(chan bool),
		WorkerPoolRef: wp,
	}
}

// å¯åŠ¨å·¥ä½œåç¨‹
func (w *Worker) Start() {
	go func() {
		for {
			// å°†å·¥ä½œåç¨‹çš„é€šé“æ³¨å†Œåˆ°å·¥ä½œæ± 
			w.WorkerPool <- w.JobChannel

			select {
			case job := <-w.JobChannel:
				// å¤„ç†ä»»åŠ¡
				w.processJob(job)
			case <-w.Quit:
				return
			}
		}
	}()
}

// åœæ­¢å·¥ä½œåç¨‹
func (w *Worker) Stop() {
	go func() {
		w.Quit <- true
	}()
}

// å¤„ç†ä»»åŠ¡
func (w *Worker) processJob(job ProcessingJob) {
	startTime := time.Now()

	// æ›´æ–°ç»Ÿè®¡
	w.WorkerPoolRef.mutex.Lock()
	w.WorkerPoolRef.stats.ActiveWorkers++
	w.WorkerPoolRef.mutex.Unlock()

	defer func() {
		w.WorkerPoolRef.mutex.Lock()
		w.WorkerPoolRef.stats.ActiveWorkers--
		w.WorkerPoolRef.mutex.Unlock()
	}()

	result := ProcessingResult{
		JobID:          job.ID,
		ProcessedLines: len(job.Lines),
		CreatedAt:      time.Now(),
		Results:        make([]LogAnalysis, 0),
		Errors:         make([]string, 0),
		Metadata:       make(map[string]interface{}),
	}

	// å¤„ç†æ¯ä¸€è¡Œæ—¥å¿—
	for _, line := range job.Lines {
		// æ£€æŸ¥ç¼“å­˜
		logHash := generateLogHash(line)
		if cached, found := cacheManager.GetAIAnalysis(logHash); found {
			// ä½¿ç”¨ç¼“å­˜ç»“æœ
			result.Results = append(result.Results, LogAnalysis{
				Line:       line,
				Important:  true,
				Reason:     cached.Result,
				Confidence: cached.Confidence,
			})
			result.FilteredLines++
			continue
		}

		// åº”ç”¨è§„åˆ™è¿‡æ»¤
		if globalConfig.LocalFilter && ruleEngine != nil {
			filterResult := ruleEngine.Filter(line)
			if filterResult.ShouldIgnore {
				continue
			}
			if filterResult.ShouldProcess {
				// éœ€è¦AIåˆ†æ
				analysis, err := analyzeLogLine(line, job.Format)
				if err != nil {
					result.ErrorCount++
					result.Errors = append(result.Errors, fmt.Sprintf("åˆ†æå¤±è´¥: %v", err))
					continue
				}

				// ç¼“å­˜ç»“æœ
				cacheResult := &AIAnalysisCache{
					LogHash:    logHash,
					Result:     analysis.Reason,
					Confidence: analysis.Confidence,
					Model:      globalConfig.Model,
					CreatedAt:  time.Now(),
					ExpiresAt:  time.Now().Add(globalConfig.Cache.AITTL),
				}
				cacheManager.SetAIAnalysis(logHash, cacheResult)

				result.Results = append(result.Results, *analysis)
				if analysis.Important {
					result.AlertedLines++
				}
			}
		} else {
			// ç›´æ¥AIåˆ†æ
			analysis, err := analyzeLogLine(line, job.Format)
			if err != nil {
				result.ErrorCount++
				result.Errors = append(result.Errors, fmt.Sprintf("åˆ†æå¤±è´¥: %v", err))
				continue
			}

			// ç¼“å­˜ç»“æœ
			cacheResult := &AIAnalysisCache{
				LogHash:    logHash,
				Result:     analysis.Reason,
				Confidence: analysis.Confidence,
				Model:      globalConfig.Model,
				CreatedAt:  time.Now(),
				ExpiresAt:  time.Now().Add(globalConfig.Cache.AITTL),
			}
			cacheManager.SetAIAnalysis(logHash, cacheResult)

			result.Results = append(result.Results, *analysis)
			if analysis.Important {
				result.AlertedLines++
			}
		}
	}

	result.ProcessingTime = time.Since(startTime)

	// æ›´æ–°ç»Ÿè®¡
	w.WorkerPoolRef.mutex.Lock()
	w.WorkerPoolRef.stats.CompletedJobs++
	w.WorkerPoolRef.stats.TotalLines += int64(result.ProcessedLines)
	w.WorkerPoolRef.mutex.Unlock()

	// å‘é€ç»“æœ
	w.WorkerPoolRef.resultChan <- result
}

// è°ƒåº¦å™¨
func (wp *WorkerPool) dispatch() {
	for {
		select {
		case job := <-wp.jobQueue:
			// è·å–å¯ç”¨çš„å·¥ä½œåç¨‹
			worker := <-wp.workerPool
			// åˆ†é…ä»»åŠ¡
			worker <- job

			// æ›´æ–°ç»Ÿè®¡
			wp.mutex.Lock()
			wp.stats.TotalJobs++
			wp.stats.QueueLength = len(wp.jobQueue)
			wp.mutex.Unlock()

		case <-wp.quit:
			// åœæ­¢æ‰€æœ‰å·¥ä½œåç¨‹
			for _, worker := range wp.workers {
				worker.Stop()
			}
			return
		}
	}
}

// æäº¤ä»»åŠ¡
func (wp *WorkerPool) SubmitJob(job ProcessingJob) error {
	if !wp.config.Enabled {
		return fmt.Errorf("å·¥ä½œæ± æœªå¯ç”¨")
	}

	select {
	case wp.jobQueue <- job:
		return nil
	default:
		return fmt.Errorf("å·¥ä½œé˜Ÿåˆ—å·²æ»¡")
	}
}

// è·å–ç»“æœ
func (wp *WorkerPool) GetResult() <-chan ProcessingResult {
	return wp.resultChan
}

// è·å–ç»Ÿè®¡ä¿¡æ¯
func (wp *WorkerPool) GetStats() WorkerPoolStats {
	wp.mutex.RLock()
	defer wp.mutex.RUnlock()

	// è®¡ç®—ååé‡
	elapsed := time.Since(wp.startTime)
	if elapsed > 0 {
		wp.stats.Throughput = float64(wp.stats.TotalLines) / elapsed.Seconds()
	}

	// è®¡ç®—é”™è¯¯ç‡
	if wp.stats.TotalJobs > 0 {
		wp.stats.ErrorRate = float64(wp.stats.FailedJobs) / float64(wp.stats.TotalJobs) * 100
	}

	return wp.stats
}

// åœæ­¢å·¥ä½œæ± 
func (wp *WorkerPool) Stop() {
	close(wp.quit)
}

// æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
type MetricsCollector struct {
	metrics PerformanceMetrics
	mutex   sync.RWMutex
}

// åˆ›å»ºæ–°çš„æŒ‡æ ‡æ”¶é›†å™¨
func NewMetricsCollector() *MetricsCollector {
	return &MetricsCollector{
		metrics: PerformanceMetrics{
			LastUpdated: time.Now(),
		},
	}
}

// æ›´æ–°æŒ‡æ ‡
func (mc *MetricsCollector) UpdateMetrics(processed, filtered, alerted, apiCalls, errors int64, processingTime time.Duration) {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	mc.metrics.ProcessedLines += processed
	mc.metrics.FilteredLines += filtered
	mc.metrics.AlertedLines += alerted
	mc.metrics.APICalls += apiCalls
	mc.metrics.ErrorCount += errors
	mc.metrics.ProcessingTime += int64(processingTime.Milliseconds())
	mc.metrics.LastUpdated = time.Now()

	// è®¡ç®—ååé‡
	elapsed := time.Since(mc.metrics.LastUpdated)
	if elapsed > 0 {
		mc.metrics.Throughput = float64(mc.metrics.ProcessedLines) / elapsed.Seconds()
	}

	// è®¡ç®—å¹³å‡å»¶è¿Ÿ
	if mc.metrics.ProcessedLines > 0 {
		mc.metrics.AverageLatency = float64(mc.metrics.ProcessingTime) / float64(mc.metrics.ProcessedLines)
	}

	// è®¡ç®—é”™è¯¯ç‡
	if mc.metrics.ProcessedLines > 0 {
		mc.metrics.ErrorRate = float64(mc.metrics.ErrorCount) / float64(mc.metrics.ProcessedLines) * 100
	}
}

// æ›´æ–°ç¼“å­˜æŒ‡æ ‡
func (mc *MetricsCollector) UpdateCacheMetrics(hits, misses int64) {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	mc.metrics.CacheHits += hits
	mc.metrics.CacheMisses += misses

	// è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
	total := mc.metrics.CacheHits + mc.metrics.CacheMisses
	if total > 0 {
		mc.metrics.CacheHitRate = float64(mc.metrics.CacheHits) / float64(total) * 100
	}
}

// æ›´æ–°å†…å­˜ä½¿ç”¨
func (mc *MetricsCollector) UpdateMemoryUsage(usage int64) {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()

	mc.metrics.MemoryUsage = usage
}

// è·å–æŒ‡æ ‡
func (mc *MetricsCollector) GetMetrics() PerformanceMetrics {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()

	return mc.metrics
}

// åˆ†æå•è¡Œæ—¥å¿—ï¼ˆå·¥ä½œæ± ä½¿ç”¨ï¼‰
func analyzeLogLine(line, format string) (*LogAnalysis, error) {
	analysis, err := analyzeLog(line, format)
	if err != nil {
		return nil, err
	}

	// è®¾ç½®è¡Œå†…å®¹
	analysis.Line = line

	// æ ¹æ®ShouldFilterè®¾ç½®Important
	analysis.Important = !analysis.ShouldFilter

	// è®¾ç½®é»˜è®¤ç½®ä¿¡åº¦
	if analysis.Confidence == 0 {
		analysis.Confidence = 0.8
	}

	return analysis, nil
}

// å·¥ä½œæ± ç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// æ˜¾ç¤ºå·¥ä½œæ± ç»Ÿè®¡ä¿¡æ¯
func handleWorkerStats() {
	fmt.Println("ğŸ“Š å·¥ä½œæ± ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := workerPool.GetStats()
	fmt.Printf("æ€»ä»»åŠ¡æ•°: %d\n", stats.TotalJobs)
	fmt.Printf("å®Œæˆä»»åŠ¡æ•°: %d\n", stats.CompletedJobs)
	fmt.Printf("å¤±è´¥ä»»åŠ¡æ•°: %d\n", stats.FailedJobs)
	fmt.Printf("æ´»è·ƒå·¥ä½œåç¨‹æ•°: %d\n", stats.ActiveWorkers)
	fmt.Printf("é˜Ÿåˆ—é•¿åº¦: %d\n", stats.QueueLength)
	fmt.Printf("å¹³å‡å¤„ç†æ—¶é—´: %v\n", stats.AverageTime)
	fmt.Printf("æ€»å¤„ç†è¡Œæ•°: %d\n", stats.TotalLines)
	fmt.Printf("é”™è¯¯ç‡: %.2f%%\n", stats.ErrorRate)
	fmt.Printf("ååé‡: %.2f è¡Œ/ç§’\n", stats.Throughput)

	// æ˜¾ç¤ºé…ç½®ä¿¡æ¯
	fmt.Println("\nå·¥ä½œæ± é…ç½®:")
	fmt.Printf("  æœ€å¤§å·¥ä½œåç¨‹æ•°: %d\n", globalConfig.WorkerPool.MaxWorkers)
	fmt.Printf("  é˜Ÿåˆ—å¤§å°: %d\n", globalConfig.WorkerPool.QueueSize)
	fmt.Printf("  æ‰¹å¤„ç†å¤§å°: %d\n", globalConfig.WorkerPool.BatchSize)
	fmt.Printf("  è¶…æ—¶æ—¶é—´: %v\n", globalConfig.WorkerPool.Timeout)
	fmt.Printf("  é‡è¯•æ¬¡æ•°: %d\n", globalConfig.WorkerPool.RetryCount)
	fmt.Printf("  é€€é¿å»¶è¿Ÿ: %v\n", globalConfig.WorkerPool.BackoffDelay)
	fmt.Printf("  å¯ç”¨çŠ¶æ€: %t\n", globalConfig.WorkerPool.Enabled)
}

// æµ‹è¯•å·¥ä½œæ± åŠŸèƒ½
func handleWorkerTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•å·¥ä½œæ± åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// åˆ›å»ºæµ‹è¯•ä»»åŠ¡
	testLines := []string{
		"2024-01-01 10:00:00 [ERROR] Database connection failed",
		"2024-01-01 10:00:01 [INFO] User login successful",
		"2024-01-01 10:00:02 [WARN] High memory usage detected",
		"2024-01-01 10:00:03 [DEBUG] Processing request",
		"2024-01-01 10:00:04 [ERROR] File not found",
	}

	job := ProcessingJob{
		ID:        "test_job_1",
		Lines:     testLines,
		Format:    "java",
		Priority:  1,
		CreatedAt: time.Now(),
		Metadata: map[string]interface{}{
			"test": true,
		},
	}

	fmt.Println("1. æäº¤æµ‹è¯•ä»»åŠ¡...")
	if err := workerPool.SubmitJob(job); err != nil {
		fmt.Printf("   âŒ ä»»åŠ¡æäº¤å¤±è´¥: %v\n", err)
		return
	}
	fmt.Println("   âœ… ä»»åŠ¡æäº¤æˆåŠŸ")

	// ç­‰å¾…ç»“æœ
	fmt.Println("2. ç­‰å¾…å¤„ç†ç»“æœ...")
	timeout := time.After(30 * time.Second)

	select {
	case result := <-workerPool.GetResult():
		fmt.Printf("   âœ… ä»»åŠ¡å¤„ç†å®Œæˆ: %s\n", result.JobID)
		fmt.Printf("   å¤„ç†è¡Œæ•°: %d\n", result.ProcessedLines)
		fmt.Printf("   è¿‡æ»¤è¡Œæ•°: %d\n", result.FilteredLines)
		fmt.Printf("   å‘Šè­¦è¡Œæ•°: %d\n", result.AlertedLines)
		fmt.Printf("   é”™è¯¯æ•°: %d\n", result.ErrorCount)
		fmt.Printf("   å¤„ç†æ—¶é—´: %v\n", result.ProcessingTime)
		fmt.Printf("   ç»“æœæ•°: %d\n", len(result.Results))

		if len(result.Errors) > 0 {
			fmt.Println("   é”™è¯¯è¯¦æƒ…:")
			for i, err := range result.Errors {
				fmt.Printf("     %d. %s\n", i+1, err)
			}
		}

	case <-timeout:
		fmt.Println("   âŒ ä»»åŠ¡å¤„ç†è¶…æ—¶")
		return
	}

	// æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
	fmt.Println("\næœ€ç»ˆå·¥ä½œæ± ç»Ÿè®¡:")
	stats := workerPool.GetStats()
	fmt.Printf("  æ€»ä»»åŠ¡æ•°: %d\n", stats.TotalJobs)
	fmt.Printf("  å®Œæˆä»»åŠ¡æ•°: %d\n", stats.CompletedJobs)
	fmt.Printf("  ååé‡: %.2f è¡Œ/ç§’\n", stats.Throughput)

	fmt.Println("\nâœ… å·¥ä½œæ± åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}

// æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
func handlePerformanceStats() {
	fmt.Println("ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// è·å–ç¼“å­˜ç»Ÿè®¡
	cacheStats := cacheManager.GetStats()

	// è·å–å·¥ä½œæ± ç»Ÿè®¡
	workerStats := workerPool.GetStats()

	// è®¡ç®—å†…å­˜ä½¿ç”¨
	var m runtime.MemStats
	runtime.ReadMemStats(&m)

	fmt.Println("å¤„ç†ç»Ÿè®¡:")
	fmt.Printf("  æ€»å¤„ç†è¡Œæ•°: %d\n", workerStats.TotalLines)
	fmt.Printf("  å®Œæˆä»»åŠ¡æ•°: %d\n", workerStats.CompletedJobs)
	fmt.Printf("  å¤±è´¥ä»»åŠ¡æ•°: %d\n", workerStats.FailedJobs)
	fmt.Printf("  é”™è¯¯ç‡: %.2f%%\n", workerStats.ErrorRate)

	fmt.Println("\næ€§èƒ½æŒ‡æ ‡:")
	fmt.Printf("  ååé‡: %.2f è¡Œ/ç§’\n", workerStats.Throughput)
	fmt.Printf("  å¹³å‡å¤„ç†æ—¶é—´: %v\n", workerStats.AverageTime)
	fmt.Printf("  æ´»è·ƒå·¥ä½œåç¨‹: %d\n", workerStats.ActiveWorkers)

	fmt.Println("\nç¼“å­˜ç»Ÿè®¡:")
	fmt.Printf("  ç¼“å­˜å‘½ä¸­æ¬¡æ•°: %d\n", cacheStats.HitCount)
	fmt.Printf("  ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°: %d\n", cacheStats.MissCount)
	fmt.Printf("  ç¼“å­˜å‘½ä¸­ç‡: %.2f%%\n", cacheStats.HitRate)
	fmt.Printf("  æ€»ç¼“å­˜é¡¹æ•°: %d\n", cacheStats.TotalItems)

	fmt.Println("\nå†…å­˜ä½¿ç”¨:")
	fmt.Printf("  å½“å‰å†…å­˜ä½¿ç”¨: %.2f MB\n", float64(m.Alloc)/(1024*1024))
	fmt.Printf("  ç³»ç»Ÿå†…å­˜ä½¿ç”¨: %.2f MB\n", float64(m.Sys)/(1024*1024))
	fmt.Printf("  åƒåœ¾å›æ”¶æ¬¡æ•°: %d\n", m.NumGC)
	fmt.Printf("  åƒåœ¾å›æ”¶æ—¶é—´: %v\n", time.Duration(m.PauseTotalNs))

	fmt.Println("\nç³»ç»Ÿä¿¡æ¯:")
	fmt.Printf("  Goç‰ˆæœ¬: %s\n", runtime.Version())
	fmt.Printf("  CPUæ ¸å¿ƒæ•°: %d\n", runtime.NumCPU())
	fmt.Printf("  Goroutineæ•°: %d\n", runtime.NumGoroutine())
}

// å†…å­˜ç®¡ç†å™¨æ–¹æ³•

// åˆ›å»ºæ–°çš„å†…å­˜ç®¡ç†å™¨
func NewMemoryManager(config MemoryConfig) *MemoryManager {
	mm := &MemoryManager{
		config:      config,
		allocations: make(map[uintptr]int64),
		lastGC:      time.Now(),
	}

	// åˆ›å»ºæµå¼å¤„ç†å™¨
	mm.streamProcessor = &StreamProcessor{
		BufferSize: config.StreamBufferSize,
		ChunkSize:  config.ChunkSize,
		Buffer:     make([]string, 0, config.StreamBufferSize),
	}

	// å¯åŠ¨å†…å­˜ç›‘æ§
	if config.Enabled {
		go mm.startMemoryMonitoring()
	}

	return mm
}

// å¯åŠ¨å†…å­˜ç›‘æ§
func (mm *MemoryManager) startMemoryMonitoring() {
	ticker := time.NewTicker(mm.config.MemoryCheckInterval)
	defer ticker.Stop()

	for range ticker.C {
		mm.checkMemoryUsage()
	}
}

// æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
func (mm *MemoryManager) checkMemoryUsage() {
	mm.mutex.Lock()
	defer mm.mutex.Unlock()

	var m runtime.MemStats
	runtime.ReadMemStats(&m)

	// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
	mm.stats.CurrentUsage = int64(m.Alloc)
	mm.stats.HeapSize = int64(m.HeapSys)
	mm.stats.StackSize = int64(m.StackSys)
	mm.stats.GCCount = int64(m.NumGC)
	mm.stats.GCTime = int64(m.PauseTotalNs)
	mm.stats.AllocCount = int64(m.Mallocs)
	mm.stats.FreeCount = int64(m.Frees)
	mm.stats.LastGC = time.Unix(0, int64(m.LastGC))

	// æ›´æ–°å³°å€¼ä½¿ç”¨é‡
	if mm.stats.CurrentUsage > mm.stats.PeakUsage {
		mm.stats.PeakUsage = mm.stats.CurrentUsage
	}

	// è®¡ç®—å†…å­˜å‹åŠ›
	if mm.config.MemoryLimit > 0 {
		mm.stats.MemoryPressure = float64(mm.stats.CurrentUsage) / float64(mm.config.MemoryLimit)
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦åƒåœ¾å›æ”¶
	if mm.config.AutoGC && mm.stats.CurrentUsage > mm.config.GCThreshold {
		mm.forceGC()
	}
}

// å¼ºåˆ¶åƒåœ¾å›æ”¶
func (mm *MemoryManager) forceGC() {
	start := time.Now()
	runtime.GC()
	mm.lastGC = time.Now()

	// æ›´æ–°ç»Ÿè®¡
	mm.stats.GCCount++
	mm.stats.GCTime += int64(time.Since(start).Nanoseconds())
}

// è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯
func (mm *MemoryManager) GetStats() MemoryStats {
	// æ›´æ–°å½“å‰ç»Ÿè®¡
	mm.checkMemoryUsage()

	mm.mutex.RLock()
	defer mm.mutex.RUnlock()

	return mm.stats
}

// åˆ†é…å†…å­˜
func (mm *MemoryManager) Allocate(size int64) uintptr {
	mm.mutex.Lock()
	defer mm.mutex.Unlock()

	// æ£€æŸ¥å†…å­˜é™åˆ¶
	if mm.config.MemoryLimit > 0 && mm.stats.CurrentUsage+size > mm.config.MemoryLimit {
		// è§¦å‘åƒåœ¾å›æ”¶
		mm.forceGC()

		// å¦‚æœä»ç„¶è¶…é™ï¼Œè¿”å›0
		if mm.stats.CurrentUsage+size > mm.config.MemoryLimit {
			return 0
		}
	}

	// åˆ†é…å†…å­˜ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨å†…å­˜æ± ï¼‰
	ptr := uintptr(0) // ç®€åŒ–å®ç°
	mm.allocations[ptr] = size
	mm.stats.AllocCount++

	return ptr
}

// é‡Šæ”¾å†…å­˜
func (mm *MemoryManager) Free(ptr uintptr) {
	mm.mutex.Lock()
	defer mm.mutex.Unlock()

	if size, exists := mm.allocations[ptr]; exists {
		delete(mm.allocations, ptr)
		mm.stats.FreeCount++
		mm.stats.CurrentUsage -= size
	}
}

// æµå¼å¤„ç†æ—¥å¿—
func (mm *MemoryManager) ProcessStream(lines []string, processFunc func([]string) error) error {
	if !mm.config.Enabled {
		return processFunc(lines)
	}

	mm.streamProcessor.mutex.Lock()
	defer mm.streamProcessor.mutex.Unlock()

	// æ·»åŠ åˆ°ç¼“å†²åŒº
	mm.streamProcessor.Buffer = append(mm.streamProcessor.Buffer, lines...)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
	if len(mm.streamProcessor.Buffer) >= mm.streamProcessor.ChunkSize {
		// å¤„ç†å½“å‰å—
		chunk := make([]string, mm.streamProcessor.ChunkSize)
		copy(chunk, mm.streamProcessor.Buffer[:mm.streamProcessor.ChunkSize])

		// ç§»é™¤å·²å¤„ç†çš„éƒ¨åˆ†
		mm.streamProcessor.Buffer = mm.streamProcessor.Buffer[mm.streamProcessor.ChunkSize:]

		// å¤„ç†å—
		if err := processFunc(chunk); err != nil {
			return err
		}

		mm.streamProcessor.TotalProcessed += int64(len(chunk))
	}

	return nil
}

// åˆ·æ–°ç¼“å†²åŒº
func (mm *MemoryManager) FlushBuffer() error {
	mm.streamProcessor.mutex.Lock()
	defer mm.streamProcessor.mutex.Unlock()

	if len(mm.streamProcessor.Buffer) > 0 {
		// å¤„ç†å‰©ä½™æ•°æ®
		if err := mm.streamProcessor.ProcessFunc(mm.streamProcessor.Buffer); err != nil {
			return err
		}

		mm.streamProcessor.TotalProcessed += int64(len(mm.streamProcessor.Buffer))
		mm.streamProcessor.Buffer = mm.streamProcessor.Buffer[:0] // æ¸…ç©ºç¼“å†²åŒº
	}

	return nil
}

// åˆ›å»ºå†…å­˜æ± 
func NewMemoryPool(chunkSize, maxChunks int) *MemoryPool {
	mp := &MemoryPool{
		chunkSize:   chunkSize,
		maxChunks:   maxChunks,
		allocations: make(map[uintptr]int64),
	}

	// åˆå§‹åŒ–æ± 
	mp.pool = sync.Pool{
		New: func() interface{} {
			return make([]byte, chunkSize)
		},
	}

	return mp
}

// ä»æ± ä¸­è·å–å†…å­˜å—
func (mp *MemoryPool) Get() []byte {
	mp.mutex.Lock()
	defer mp.mutex.Unlock()

	if mp.currentChunks >= mp.maxChunks {
		return nil // æ± å·²æ»¡
	}

	chunk := mp.pool.Get().([]byte)
	mp.currentChunks++
	return chunk
}

// å°†å†…å­˜å—è¿”å›åˆ°æ± ä¸­
func (mp *MemoryPool) Put(chunk []byte) {
	mp.mutex.Lock()
	defer mp.mutex.Unlock()

	if mp.currentChunks > 0 {
		mp.pool.Put(chunk)
		mp.currentChunks--
	}
}

// åˆ›å»ºå†…å­˜åˆ†é…å™¨
func NewMemoryAllocator(pool *MemoryPool) *MemoryAllocator {
	return &MemoryAllocator{
		pool:        pool,
		allocations: make(map[uintptr]int64),
	}
}

// åˆ†é…å†…å­˜
func (ma *MemoryAllocator) Allocate(size int64) []byte {
	ma.mutex.Lock()
	defer ma.mutex.Unlock()

	// å°è¯•ä»æ± ä¸­è·å–
	if size <= int64(ma.pool.chunkSize) {
		chunk := ma.pool.Get()
		if chunk != nil {
			ptr := uintptr(unsafe.Pointer(&chunk[0]))
			ma.allocations[ptr] = size
			ma.totalAllocated += size
			return chunk[:size]
		}
	}

	// æ± ä¸­æ— æ³•è·å–ï¼Œç›´æ¥åˆ†é…
	chunk := make([]byte, size)
	ptr := uintptr(unsafe.Pointer(&chunk[0]))
	ma.allocations[ptr] = size
	ma.totalAllocated += size

	return chunk
}

// é‡Šæ”¾å†…å­˜
func (ma *MemoryAllocator) Free(chunk []byte) {
	ma.mutex.Lock()
	defer ma.mutex.Unlock()

	ptr := uintptr(unsafe.Pointer(&chunk[0]))
	if size, exists := ma.allocations[ptr]; exists {
		delete(ma.allocations, ptr)
		ma.totalAllocated -= size

		// å°è¯•è¿”å›åˆ°æ± ä¸­
		ma.pool.Put(chunk)
	}
}

// è·å–åˆ†é…ç»Ÿè®¡
func (ma *MemoryAllocator) GetStats() map[string]int64 {
	ma.mutex.RLock()
	defer ma.mutex.RUnlock()

	return map[string]int64{
		"total_allocated":    ma.totalAllocated,
		"active_allocations": int64(len(ma.allocations)),
	}
}

// å†…å­˜ç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// æ˜¾ç¤ºå†…å­˜ç»Ÿè®¡ä¿¡æ¯
func handleMemoryStats() {
	fmt.Println("ğŸ§  å†…å­˜ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := memoryManager.GetStats()
	fmt.Printf("å½“å‰å†…å­˜ä½¿ç”¨: %.2f MB\n", float64(stats.CurrentUsage)/(1024*1024))
	fmt.Printf("å³°å€¼å†…å­˜ä½¿ç”¨: %.2f MB\n", float64(stats.PeakUsage)/(1024*1024))
	fmt.Printf("å †å¤§å°: %.2f MB\n", float64(stats.HeapSize)/(1024*1024))
	fmt.Printf("æ ˆå¤§å°: %.2f MB\n", float64(stats.StackSize)/(1024*1024))
	fmt.Printf("åƒåœ¾å›æ”¶æ¬¡æ•°: %d\n", stats.GCCount)
	fmt.Printf("åƒåœ¾å›æ”¶æ—¶é—´: %v\n", time.Duration(stats.GCTime))
	fmt.Printf("åˆ†é…æ¬¡æ•°: %d\n", stats.AllocCount)
	fmt.Printf("é‡Šæ”¾æ¬¡æ•°: %d\n", stats.FreeCount)
	fmt.Printf("ä¸Šæ¬¡åƒåœ¾å›æ”¶: %v\n", stats.LastGC.Format("2006-01-02 15:04:05"))
	fmt.Printf("å†…å­˜å‹åŠ›: %.2f%%\n", stats.MemoryPressure*100)

	// æ˜¾ç¤ºé…ç½®ä¿¡æ¯
	fmt.Println("\nå†…å­˜é…ç½®:")
	fmt.Printf("  æœ€å¤§å†…å­˜ä½¿ç”¨: %.2f MB\n", float64(globalConfig.Memory.MaxMemoryUsage)/(1024*1024))
	fmt.Printf("  GCé˜ˆå€¼: %.2f MB\n", float64(globalConfig.Memory.GCThreshold)/(1024*1024))
	fmt.Printf("  æµå¼ç¼“å†²åŒºå¤§å°: %d\n", globalConfig.Memory.StreamBufferSize)
	fmt.Printf("  åˆ†å—å¤§å°: %d\n", globalConfig.Memory.ChunkSize)
	fmt.Printf("  å†…å­˜æ£€æŸ¥é—´éš”: %v\n", globalConfig.Memory.MemoryCheckInterval)
	fmt.Printf("  è‡ªåŠ¨GC: %t\n", globalConfig.Memory.AutoGC)
	fmt.Printf("  å†…å­˜é™åˆ¶: %.2f MB\n", float64(globalConfig.Memory.MemoryLimit)/(1024*1024))
	fmt.Printf("  å¯ç”¨çŠ¶æ€: %t\n", globalConfig.Memory.Enabled)
}

// æµ‹è¯•å†…å­˜ç®¡ç†åŠŸèƒ½
func handleMemoryTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•å†…å­˜ç®¡ç†åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æµ‹è¯•å†…å­˜åˆ†é…
	fmt.Println("1. æµ‹è¯•å†…å­˜åˆ†é…...")
	ptr1 := memoryManager.Allocate(1024 * 1024) // 1MB
	if ptr1 != 0 {
		fmt.Println("   âœ… 1MBå†…å­˜åˆ†é…æˆåŠŸ")
	} else {
		fmt.Println("   âŒ 1MBå†…å­˜åˆ†é…å¤±è´¥")
	}

	ptr2 := memoryManager.Allocate(2 * 1024 * 1024) // 2MB
	if ptr2 != 0 {
		fmt.Println("   âœ… 2MBå†…å­˜åˆ†é…æˆåŠŸ")
	} else {
		fmt.Println("   âŒ 2MBå†…å­˜åˆ†é…å¤±è´¥")
	}

	// æµ‹è¯•æµå¼å¤„ç†
	fmt.Println("2. æµ‹è¯•æµå¼å¤„ç†...")
	testLines := []string{
		"2024-01-01 10:00:00 [INFO] Test log line 1",
		"2024-01-01 10:00:01 [ERROR] Test log line 2",
		"2024-01-01 10:00:02 [WARN] Test log line 3",
	}

	processFunc := func(lines []string) error {
		fmt.Printf("   ğŸ“ å¤„ç†äº† %d è¡Œæ—¥å¿—\n", len(lines))
		return nil
	}

	if err := memoryManager.ProcessStream(testLines, processFunc); err != nil {
		fmt.Printf("   âŒ æµå¼å¤„ç†å¤±è´¥: %v\n", err)
	} else {
		fmt.Println("   âœ… æµå¼å¤„ç†æˆåŠŸ")
	}

	// æµ‹è¯•å†…å­˜æ± 
	fmt.Println("3. æµ‹è¯•å†…å­˜æ± ...")
	pool := NewMemoryPool(1024, 10)
	chunk1 := pool.Get()
	if chunk1 != nil {
		fmt.Println("   âœ… ä»å†…å­˜æ± è·å–å†…å­˜å—æˆåŠŸ")
		pool.Put(chunk1)
		fmt.Println("   âœ… å°†å†…å­˜å—è¿”å›åˆ°æ± ä¸­æˆåŠŸ")
	} else {
		fmt.Println("   âŒ ä»å†…å­˜æ± è·å–å†…å­˜å—å¤±è´¥")
	}

	// æµ‹è¯•å†…å­˜åˆ†é…å™¨
	fmt.Println("4. æµ‹è¯•å†…å­˜åˆ†é…å™¨...")
	allocator := NewMemoryAllocator(pool)
	chunk2 := allocator.Allocate(512)
	if chunk2 != nil {
		fmt.Println("   âœ… å†…å­˜åˆ†é…å™¨åˆ†é…æˆåŠŸ")
		allocator.Free(chunk2)
		fmt.Println("   âœ… å†…å­˜åˆ†é…å™¨é‡Šæ”¾æˆåŠŸ")
	} else {
		fmt.Println("   âŒ å†…å­˜åˆ†é…å™¨åˆ†é…å¤±è´¥")
	}

	// é‡Šæ”¾æµ‹è¯•å†…å­˜
	if ptr1 != 0 {
		memoryManager.Free(ptr1)
	}
	if ptr2 != 0 {
		memoryManager.Free(ptr2)
	}

	// æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
	fmt.Println("\næœ€ç»ˆå†…å­˜ç»Ÿè®¡:")
	stats := memoryManager.GetStats()
	fmt.Printf("  å½“å‰å†…å­˜ä½¿ç”¨: %.2f MB\n", float64(stats.CurrentUsage)/(1024*1024))
	fmt.Printf("  åˆ†é…æ¬¡æ•°: %d\n", stats.AllocCount)
	fmt.Printf("  é‡Šæ”¾æ¬¡æ•°: %d\n", stats.FreeCount)
	fmt.Printf("  å†…å­˜å‹åŠ›: %.2f%%\n", stats.MemoryPressure*100)

	fmt.Println("\nâœ… å†…å­˜ç®¡ç†åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}

// å¼ºåˆ¶åƒåœ¾å›æ”¶
func handleMemoryGC() {
	fmt.Println("ğŸ—‘ï¸  å¼ºåˆ¶åƒåœ¾å›æ”¶...")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// è·å–å›æ”¶å‰ç»Ÿè®¡
	statsBefore := memoryManager.GetStats()
	fmt.Printf("å›æ”¶å‰å†…å­˜ä½¿ç”¨: %.2f MB\n", float64(statsBefore.CurrentUsage)/(1024*1024))

	// å¼ºåˆ¶åƒåœ¾å›æ”¶
	start := time.Now()
	runtime.GC()
	runtime.GC() // æ‰§è¡Œä¸¤æ¬¡ç¡®ä¿å®Œå…¨å›æ”¶
	elapsed := time.Since(start)

	// è·å–å›æ”¶åç»Ÿè®¡
	statsAfter := memoryManager.GetStats()
	fmt.Printf("å›æ”¶åå†…å­˜ä½¿ç”¨: %.2f MB\n", float64(statsAfter.CurrentUsage)/(1024*1024))
	fmt.Printf("å›æ”¶æ—¶é—´: %v\n", elapsed)
	fmt.Printf("é‡Šæ”¾å†…å­˜: %.2f MB\n", float64(statsBefore.CurrentUsage-statsAfter.CurrentUsage)/(1024*1024))

	fmt.Println("âœ… åƒåœ¾å›æ”¶å®Œæˆ")
}

// å¹¶å‘æ§åˆ¶å™¨æ–¹æ³•

// åˆ›å»ºæ–°çš„å¹¶å‘æ§åˆ¶å™¨
func NewConcurrencyController(config ConcurrencyConfig) *ConcurrencyController {
	cc := &ConcurrencyController{
		config:   config,
		stopChan: make(chan bool),
	}

	// åˆ›å»ºèƒŒå‹æ§åˆ¶å™¨
	cc.backpressure = &BackpressureController{
		threshold: config.BackpressureThreshold,
		callbacks: make([]func(int64), 0),
	}

	// åˆ›å»ºè´Ÿè½½å‡è¡¡å™¨
	cc.loadBalancer = &LoadBalancer{
		strategy:    config.LoadBalanceStrategy,
		workers:     make([]*Worker, 0),
		workerStats: make(map[int]*WorkerStats),
	}

	// åˆ›å»ºè‡ªé€‚åº”æ‰©ç¼©å®¹å™¨
	cc.adaptiveScaler = &AdaptiveScaler{
		config:      config,
		workerStats: make(map[int]*WorkerStats),
	}

	// å¯åŠ¨è‡ªé€‚åº”æ‰©ç¼©å®¹
	if config.Enabled && config.AdaptiveScaling {
		go cc.startAdaptiveScaling()
	}

	return cc
}

// å¯åŠ¨è‡ªé€‚åº”æ‰©ç¼©å®¹
func (cc *ConcurrencyController) startAdaptiveScaling() {
	ticker := time.NewTicker(cc.config.ScalingInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			cc.checkAndScale()
		case <-cc.stopChan:
			return
		}
	}
}

// æ£€æŸ¥å¹¶æ‰§è¡Œæ‰©ç¼©å®¹
func (cc *ConcurrencyController) checkAndScale() {
	cc.mutex.Lock()
	defer cc.mutex.Unlock()

	// è®¡ç®—å½“å‰è´Ÿè½½
	currentLoad := cc.calculateCurrentLoad()

	// æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰©å®¹
	if currentLoad > cc.config.ScaleUpThreshold && cc.adaptiveScaler.currentWorkers < cc.config.MaxWorkers {
		cc.scaleUp()
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦ç¼©å®¹
	if currentLoad < cc.config.ScaleDownThreshold && cc.adaptiveScaler.currentWorkers > cc.config.MinWorkers {
		cc.scaleDown()
	}
}

// è®¡ç®—å½“å‰è´Ÿè½½
func (cc *ConcurrencyController) calculateCurrentLoad() float64 {
	if cc.adaptiveScaler.currentWorkers == 0 {
		return 0
	}

	totalLoad := int64(0)
	for _, stats := range cc.adaptiveScaler.workerStats {
		totalLoad += stats.CurrentLoad
	}

	return float64(totalLoad) / float64(cc.adaptiveScaler.currentWorkers)
}

// æ‰©å®¹
func (cc *ConcurrencyController) scaleUp() {
	if cc.adaptiveScaler.currentWorkers >= cc.config.MaxWorkers {
		return
	}

	// åˆ›å»ºæ–°çš„å·¥ä½œåç¨‹
	newWorker := NewWorker(cc.adaptiveScaler.currentWorkers, workerPool)
	cc.loadBalancer.workers = append(cc.loadBalancer.workers, newWorker)
	cc.adaptiveScaler.currentWorkers++

	// å¯åŠ¨å·¥ä½œåç¨‹
	newWorker.Start()

	// æ›´æ–°ç»Ÿè®¡
	cc.adaptiveScaler.workerStats[newWorker.ID] = &WorkerStats{
		ID:           newWorker.ID,
		LastActivity: time.Now(),
		IsHealthy:    true,
	}

	cc.adaptiveScaler.lastScaleTime = time.Now()
}

// ç¼©å®¹
func (cc *ConcurrencyController) scaleDown() {
	if cc.adaptiveScaler.currentWorkers <= cc.config.MinWorkers {
		return
	}

	// æ‰¾åˆ°è´Ÿè½½æœ€ä½çš„å·¥ä½œåç¨‹
	var targetWorker *Worker
	minLoad := int64(^uint64(0) >> 1)

	for _, worker := range cc.loadBalancer.workers {
		if stats, exists := cc.adaptiveScaler.workerStats[worker.ID]; exists {
			if stats.CurrentLoad < minLoad {
				minLoad = stats.CurrentLoad
				targetWorker = worker
			}
		}
	}

	if targetWorker != nil {
		// åœæ­¢å·¥ä½œåç¨‹
		targetWorker.Stop()

		// ä»è´Ÿè½½å‡è¡¡å™¨ä¸­ç§»é™¤
		for i, worker := range cc.loadBalancer.workers {
			if worker.ID == targetWorker.ID {
				cc.loadBalancer.workers = append(cc.loadBalancer.workers[:i], cc.loadBalancer.workers[i+1:]...)
				break
			}
		}

		// æ›´æ–°ç»Ÿè®¡
		delete(cc.adaptiveScaler.workerStats, targetWorker.ID)
		cc.adaptiveScaler.currentWorkers--
		cc.adaptiveScaler.lastScaleTime = time.Now()
	}
}

// åˆ›å»ºèƒŒå‹æ§åˆ¶å™¨
func NewBackpressureController(threshold int) *BackpressureController {
	return &BackpressureController{
		threshold: threshold,
		callbacks: make([]func(int64), 0),
	}
}

// æ£€æŸ¥èƒŒå‹
func (bc *BackpressureController) CheckBackpressure() bool {
	bc.mutex.RLock()
	defer bc.mutex.RUnlock()

	return int(bc.currentLoad) >= bc.threshold
}

// å¢åŠ è´Ÿè½½
func (bc *BackpressureController) AddLoad(load int64) {
	bc.mutex.Lock()
	defer bc.mutex.Unlock()

	bc.currentLoad += load

	// æ£€æŸ¥æ˜¯å¦è§¦å‘èƒŒå‹
	if int(bc.currentLoad) >= bc.threshold {
		bc.blockedCount++
		// è§¦å‘å›è°ƒ
		for _, callback := range bc.callbacks {
			callback(bc.currentLoad)
		}
	}
}

// å‡å°‘è´Ÿè½½
func (bc *BackpressureController) RemoveLoad(load int64) {
	bc.mutex.Lock()
	defer bc.mutex.Unlock()

	bc.currentLoad -= load
	if bc.currentLoad < 0 {
		bc.currentLoad = 0
	}
}

// æ‹’ç»ä»»åŠ¡
func (bc *BackpressureController) RejectTask() {
	bc.mutex.Lock()
	defer bc.mutex.Unlock()

	bc.rejectedCount++
}

// æ·»åŠ èƒŒå‹å›è°ƒ
func (bc *BackpressureController) AddCallback(callback func(int64)) {
	bc.mutex.Lock()
	defer bc.mutex.Unlock()

	bc.callbacks = append(bc.callbacks, callback)
}

// åˆ›å»ºè´Ÿè½½å‡è¡¡å™¨
func NewLoadBalancer(strategy string) *LoadBalancer {
	return &LoadBalancer{
		strategy:    strategy,
		workers:     make([]*Worker, 0),
		workerStats: make(map[int]*WorkerStats),
	}
}

// é€‰æ‹©å·¥ä½œåç¨‹
func (lb *LoadBalancer) SelectWorker() *Worker {
	lb.mutex.RLock()
	defer lb.mutex.RUnlock()

	if len(lb.workers) == 0 {
		return nil
	}

	switch lb.strategy {
	case "round_robin":
		return lb.selectRoundRobin()
	case "least_loaded":
		return lb.selectLeastLoaded()
	case "random":
		return lb.selectRandom()
	default:
		return lb.selectRoundRobin()
	}
}

// è½®è¯¢é€‰æ‹©
func (lb *LoadBalancer) selectRoundRobin() *Worker {
	if len(lb.workers) == 0 {
		return nil
	}

	worker := lb.workers[lb.currentIndex]
	lb.currentIndex = (lb.currentIndex + 1) % len(lb.workers)
	return worker
}

// é€‰æ‹©è´Ÿè½½æœ€ä½çš„å·¥ä½œåç¨‹
func (lb *LoadBalancer) selectLeastLoaded() *Worker {
	if len(lb.workers) == 0 {
		return nil
	}

	var selectedWorker *Worker
	minLoad := int64(^uint64(0) >> 1)

	for _, worker := range lb.workers {
		if stats, exists := lb.workerStats[worker.ID]; exists {
			if stats.CurrentLoad < minLoad {
				minLoad = stats.CurrentLoad
				selectedWorker = worker
			}
		}
	}

	if selectedWorker == nil {
		return lb.workers[0]
	}

	return selectedWorker
}

// éšæœºé€‰æ‹©
func (lb *LoadBalancer) selectRandom() *Worker {
	if len(lb.workers) == 0 {
		return nil
	}

	index := rand.Intn(len(lb.workers))
	return lb.workers[index]
}

// æ›´æ–°å·¥ä½œåç¨‹ç»Ÿè®¡
func (lb *LoadBalancer) UpdateWorkerStats(workerID int, stats *WorkerStats) {
	lb.mutex.Lock()
	defer lb.mutex.Unlock()

	lb.workerStats[workerID] = stats
}

// åˆ›å»ºä¼˜å…ˆçº§é˜Ÿåˆ—
func NewPriorityQueue() *PriorityQueue {
	return &PriorityQueue{
		jobs:       make([]ProcessingJob, 0),
		priorities: make(map[string]TaskPriority),
	}
}

// æ·»åŠ ä»»åŠ¡
func (pq *PriorityQueue) AddJob(job ProcessingJob, priority TaskPriority) {
	pq.mutex.Lock()
	defer pq.mutex.Unlock()

	pq.priorities[job.ID] = priority
	pq.jobs = append(pq.jobs, job)

	// æŒ‰ä¼˜å…ˆçº§æ’åº
	pq.sortByPriority()
}

// è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
func (pq *PriorityQueue) GetNextJob() *ProcessingJob {
	pq.mutex.Lock()
	defer pq.mutex.Unlock()

	if len(pq.jobs) == 0 {
		return nil
	}

	job := pq.jobs[0]
	pq.jobs = pq.jobs[1:]
	delete(pq.priorities, job.ID)

	return &job
}

// æŒ‰ä¼˜å…ˆçº§æ’åº
func (pq *PriorityQueue) sortByPriority() {
	sort.Slice(pq.jobs, func(i, j int) bool {
		priorityI := pq.priorities[pq.jobs[i].ID]
		priorityJ := pq.priorities[pq.jobs[j].ID]
		return priorityI > priorityJ // é«˜ä¼˜å…ˆçº§åœ¨å‰
	})
}

// è·å–é˜Ÿåˆ—é•¿åº¦
func (pq *PriorityQueue) Length() int {
	pq.mutex.RLock()
	defer pq.mutex.RUnlock()

	return len(pq.jobs)
}

// åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
func NewTaskScheduler(workers []*Worker, loadBalancer *LoadBalancer) *TaskScheduler {
	return &TaskScheduler{
		priorityQueue: NewPriorityQueue(),
		workers:       workers,
		loadBalancer:  loadBalancer,
	}
}

// æäº¤ä»»åŠ¡
func (ts *TaskScheduler) SubmitTask(job ProcessingJob, priority TaskPriority) error {
	ts.mutex.Lock()
	defer ts.mutex.Unlock()

	// æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„å·¥ä½œåç¨‹
	if len(ts.workers) == 0 {
		return fmt.Errorf("æ²¡æœ‰å¯ç”¨çš„å·¥ä½œåç¨‹")
	}

	// æ·»åŠ åˆ°ä¼˜å…ˆçº§é˜Ÿåˆ—
	ts.priorityQueue.AddJob(job, priority)

	// å°è¯•ç«‹å³åˆ†é…ä»»åŠ¡
	ts.tryAssignTask()

	return nil
}

// å°è¯•åˆ†é…ä»»åŠ¡
func (ts *TaskScheduler) tryAssignTask() {
	// è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
	job := ts.priorityQueue.GetNextJob()
	if job == nil {
		return
	}

	// é€‰æ‹©å·¥ä½œåç¨‹
	worker := ts.loadBalancer.SelectWorker()
	if worker == nil {
		// æ²¡æœ‰å¯ç”¨å·¥ä½œåç¨‹ï¼Œå°†ä»»åŠ¡æ”¾å›é˜Ÿåˆ—
		ts.priorityQueue.AddJob(*job, ts.priorityQueue.priorities[job.ID])
		return
	}

	// åˆ†é…ä»»åŠ¡
	select {
	case worker.JobChannel <- *job:
		// ä»»åŠ¡åˆ†é…æˆåŠŸ
		ts.stats.TotalJobs++
	default:
		// å·¥ä½œåç¨‹å¿™ï¼Œå°†ä»»åŠ¡æ”¾å›é˜Ÿåˆ—
		ts.priorityQueue.AddJob(*job, ts.priorityQueue.priorities[job.ID])
	}
}

// è·å–ç»Ÿè®¡ä¿¡æ¯
func (ts *TaskScheduler) GetStats() ConcurrencyStats {
	ts.mutex.RLock()
	defer ts.mutex.RUnlock()

	return ts.stats
}

// å¹¶å‘æ§åˆ¶å‘½ä»¤å¤„ç†å‡½æ•°

// æ˜¾ç¤ºå¹¶å‘æ§åˆ¶ç»Ÿè®¡ä¿¡æ¯
func handleConcurrencyStats() {
	fmt.Println("âš¡ å¹¶å‘æ§åˆ¶ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := concurrencyController.stats
	fmt.Printf("æ€»ä»»åŠ¡æ•°: %d\n", stats.TotalJobs)
	fmt.Printf("å·²å¤„ç†ä»»åŠ¡æ•°: %d\n", stats.ProcessedJobs)
	fmt.Printf("æ´»è·ƒå·¥ä½œåç¨‹æ•°: %d\n", stats.ActiveWorkers)
	fmt.Printf("é˜»å¡ä»»åŠ¡æ•°: %d\n", stats.BlockedJobs)
	fmt.Printf("æ‹’ç»ä»»åŠ¡æ•°: %d\n", stats.RejectedJobs)
	fmt.Printf("å¹³å‡å»¶è¿Ÿ: %v\n", stats.AverageLatency)
	fmt.Printf("ååé‡: %.2f ä»»åŠ¡/ç§’\n", stats.Throughput)
	fmt.Printf("é”™è¯¯ç‡: %.2f%%\n", stats.ErrorRate)
	fmt.Printf("èƒŒå‹ç‡: %.2f%%\n", stats.BackpressureRate)

	// æ˜¾ç¤ºé…ç½®ä¿¡æ¯
	fmt.Println("\nå¹¶å‘æ§åˆ¶é…ç½®:")
	fmt.Printf("  æœ€å¤§å¹¶å‘æ•°: %d\n", globalConfig.Concurrency.MaxConcurrency)
	fmt.Printf("  èƒŒå‹é˜ˆå€¼: %d\n", globalConfig.Concurrency.BackpressureThreshold)
	fmt.Printf("  è´Ÿè½½å‡è¡¡ç­–ç•¥: %s\n", globalConfig.Concurrency.LoadBalanceStrategy)
	fmt.Printf("  è‡ªé€‚åº”æ‰©ç¼©å®¹: %t\n", globalConfig.Concurrency.AdaptiveScaling)
	fmt.Printf("  æ‰©å®¹é˜ˆå€¼: %.2f\n", globalConfig.Concurrency.ScaleUpThreshold)
	fmt.Printf("  ç¼©å®¹é˜ˆå€¼: %.2f\n", globalConfig.Concurrency.ScaleDownThreshold)
	fmt.Printf("  æœ€å°å·¥ä½œåç¨‹æ•°: %d\n", globalConfig.Concurrency.MinWorkers)
	fmt.Printf("  æœ€å¤§å·¥ä½œåç¨‹æ•°: %d\n", globalConfig.Concurrency.MaxWorkers)
	fmt.Printf("  æ‰©ç¼©å®¹æ£€æŸ¥é—´éš”: %v\n", globalConfig.Concurrency.ScalingInterval)
	fmt.Printf("  å¯ç”¨çŠ¶æ€: %t\n", globalConfig.Concurrency.Enabled)
}

// æµ‹è¯•å¹¶å‘æ§åˆ¶åŠŸèƒ½
func handleConcurrencyTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•å¹¶å‘æ§åˆ¶åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æµ‹è¯•è´Ÿè½½å‡è¡¡å™¨
	fmt.Println("1. æµ‹è¯•è´Ÿè½½å‡è¡¡å™¨...")
	loadBalancer := NewLoadBalancer("round_robin")

	// åˆ›å»ºæµ‹è¯•å·¥ä½œåç¨‹
	testWorkers := make([]*Worker, 3)
	for i := 0; i < 3; i++ {
		worker := NewWorker(i, workerPool)
		testWorkers[i] = worker
		loadBalancer.workers = append(loadBalancer.workers, worker)
	}

	// æµ‹è¯•è½®è¯¢é€‰æ‹©
	for i := 0; i < 6; i++ {
		worker := loadBalancer.SelectWorker()
		if worker != nil {
			fmt.Printf("   âœ… è½®è¯¢é€‰æ‹©å·¥ä½œåç¨‹ %d\n", worker.ID)
		} else {
			fmt.Println("   âŒ è½®è¯¢é€‰æ‹©å¤±è´¥")
		}
	}

	// æµ‹è¯•ä¼˜å…ˆçº§é˜Ÿåˆ—
	fmt.Println("2. æµ‹è¯•ä¼˜å…ˆçº§é˜Ÿåˆ—...")
	priorityQueue := NewPriorityQueue()

	// æ·»åŠ ä¸åŒä¼˜å…ˆçº§çš„ä»»åŠ¡
	jobs := []ProcessingJob{
		{ID: "job1", Lines: []string{"test1"}, Priority: 1},
		{ID: "job2", Lines: []string{"test2"}, Priority: 3},
		{ID: "job3", Lines: []string{"test3"}, Priority: 2},
	}

	for i, job := range jobs {
		priority := TaskPriority(i + 1)
		priorityQueue.AddJob(job, priority)
		fmt.Printf("   âœ… æ·»åŠ ä»»åŠ¡ %s (ä¼˜å…ˆçº§ %d)\n", job.ID, priority)
	}

	// æŒ‰ä¼˜å…ˆçº§è·å–ä»»åŠ¡
	for i := 0; i < 3; i++ {
		job := priorityQueue.GetNextJob()
		if job != nil {
			fmt.Printf("   âœ… è·å–ä»»åŠ¡ %s\n", job.ID)
		} else {
			fmt.Println("   âŒ è·å–ä»»åŠ¡å¤±è´¥")
		}
	}

	// æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨
	fmt.Println("3. æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨...")
	scheduler := NewTaskScheduler(testWorkers, loadBalancer)

	// æäº¤ä»»åŠ¡
	testJob := ProcessingJob{
		ID:     "test_job",
		Lines:  []string{"test line"},
		Format: "java",
	}

	if err := scheduler.SubmitTask(testJob, PriorityHigh); err != nil {
		fmt.Printf("   âŒ ä»»åŠ¡æäº¤å¤±è´¥: %v\n", err)
	} else {
		fmt.Println("   âœ… ä»»åŠ¡æäº¤æˆåŠŸ")
	}

	// æ˜¾ç¤ºç»Ÿè®¡
	stats := scheduler.GetStats()
	fmt.Printf("  æ€»ä»»åŠ¡æ•°: %d\n", stats.TotalJobs)

	fmt.Println("\nâœ… å¹¶å‘æ§åˆ¶åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}

// æµ‹è¯•èƒŒå‹æ§åˆ¶åŠŸèƒ½
func handleBackpressureTest() {
	fmt.Println("ğŸ”„ æµ‹è¯•èƒŒå‹æ§åˆ¶åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// åˆ›å»ºèƒŒå‹æ§åˆ¶å™¨
	backpressure := NewBackpressureController(5)

	// æ·»åŠ å›è°ƒ
	backpressure.AddCallback(func(load int64) {
		fmt.Printf("   âš ï¸  èƒŒå‹è§¦å‘ï¼Œå½“å‰è´Ÿè½½: %d\n", load)
	})

	// æµ‹è¯•æ­£å¸¸è´Ÿè½½
	fmt.Println("1. æµ‹è¯•æ­£å¸¸è´Ÿè½½...")
	for i := 0; i < 3; i++ {
		backpressure.AddLoad(1)
		fmt.Printf("   âœ… æ·»åŠ è´Ÿè½½ %dï¼Œå½“å‰è´Ÿè½½: %d\n", i+1, backpressure.currentLoad)
	}

	// æµ‹è¯•èƒŒå‹è§¦å‘
	fmt.Println("2. æµ‹è¯•èƒŒå‹è§¦å‘...")
	for i := 0; i < 5; i++ {
		backpressure.AddLoad(1)
		fmt.Printf("   ğŸ“Š æ·»åŠ è´Ÿè½½ %dï¼Œå½“å‰è´Ÿè½½: %dï¼ŒèƒŒå‹çŠ¶æ€: %t\n",
			i+4, backpressure.currentLoad, backpressure.CheckBackpressure())
	}

	// æµ‹è¯•è´Ÿè½½å‡å°‘
	fmt.Println("3. æµ‹è¯•è´Ÿè½½å‡å°‘...")
	for i := 0; i < 3; i++ {
		backpressure.RemoveLoad(1)
		fmt.Printf("   âœ… å‡å°‘è´Ÿè½½ %dï¼Œå½“å‰è´Ÿè½½: %dï¼ŒèƒŒå‹çŠ¶æ€: %t\n",
			i+1, backpressure.currentLoad, backpressure.CheckBackpressure())
	}

	// æµ‹è¯•ä»»åŠ¡æ‹’ç»
	fmt.Println("4. æµ‹è¯•ä»»åŠ¡æ‹’ç»...")
	for i := 0; i < 3; i++ {
		backpressure.RejectTask()
		fmt.Printf("   âŒ æ‹’ç»ä»»åŠ¡ %d\n", i+1)
	}

	fmt.Println("\nâœ… èƒŒå‹æ§åˆ¶åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}

// I/Oä¼˜åŒ–å™¨æ–¹æ³•

// åˆ›å»ºæ–°çš„I/Oä¼˜åŒ–å™¨
func NewIOOptimizer(config IOConfig) *IOOptimizer {
	io := &IOOptimizer{
		config:   config,
		stopChan: make(chan bool),
	}

	// åˆ›å»ºæ‰¹é‡I/Oå¤„ç†å™¨
	io.processor = &BatchIOProcessor{
		config:     config,
		buffers:    make(map[string]*IOBuffer),
		operations: make(chan AsyncIOOperation, 1000),
		results:    make(chan AsyncIOOperation, 1000),
		stopChan:   make(chan bool),
	}

	// å¯åŠ¨I/Oå¤„ç†å™¨
	if config.Enabled {
		go io.startIOProcessor()
	}

	return io
}

// å¯åŠ¨I/Oå¤„ç†å™¨
func (io *IOOptimizer) startIOProcessor() {
	// å¯åŠ¨æ‰¹é‡å¤„ç†
	go io.processor.startBatchProcessing()

	// å¯åŠ¨å®šæœŸåˆ·æ–°
	if io.config.FlushInterval > 0 {
		go io.startPeriodicFlush()
	}
}

// å¯åŠ¨æ‰¹é‡å¤„ç†
func (bp *BatchIOProcessor) startBatchProcessing() {
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	for {
		select {
		case op := <-bp.operations:
			bp.processOperation(op)
		case <-ticker.C:
			bp.flushBuffers()
		case <-bp.stopChan:
			return
		}
	}
}

// å¤„ç†I/Oæ“ä½œ
func (bp *BatchIOProcessor) processOperation(op AsyncIOOperation) {
	bp.mutex.Lock()
	defer bp.mutex.Unlock()

	switch op.Type {
	case "read":
		bp.handleReadOperation(op)
	case "write":
		bp.handleWriteOperation(op)
	case "flush":
		bp.handleFlushOperation(op)
	}
}

// å¤„ç†è¯»æ“ä½œ
func (bp *BatchIOProcessor) handleReadOperation(op AsyncIOOperation) {
	start := time.Now()

	// æ¨¡æ‹Ÿå¼‚æ­¥è¯»æ“ä½œ
	go func() {
		// è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„å¼‚æ­¥è¯»æ“ä½œ
		data := make([]byte, len(op.Data))
		copy(data, op.Data)

		// æ›´æ–°ç»Ÿè®¡
		bp.mutex.Lock()
		bp.stats.ReadOperations++
		bp.stats.BytesRead += int64(len(data))
		bp.stats.ReadLatency = time.Since(start)
		bp.mutex.Unlock()

		// è°ƒç”¨å›è°ƒ
		if op.Callback != nil {
			op.Callback(data, nil)
		}
	}()
}

// å¤„ç†å†™æ“ä½œ
func (bp *BatchIOProcessor) handleWriteOperation(op AsyncIOOperation) {
	start := time.Now()

	// æ¨¡æ‹Ÿå¼‚æ­¥å†™æ“ä½œ
	go func() {
		// è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„å¼‚æ­¥å†™æ“ä½œ

		// æ›´æ–°ç»Ÿè®¡
		bp.mutex.Lock()
		bp.stats.WriteOperations++
		bp.stats.BytesWritten += int64(len(op.Data))
		bp.stats.WriteLatency = time.Since(start)
		bp.mutex.Unlock()

		// è°ƒç”¨å›è°ƒ
		if op.Callback != nil {
			op.Callback(nil, nil)
		}
	}()
}

// å¤„ç†åˆ·æ–°æ“ä½œ
func (bp *BatchIOProcessor) handleFlushOperation(op AsyncIOOperation) {
	bp.mutex.Lock()
	defer bp.mutex.Unlock()

	bp.stats.FlushOperations++
	bp.stats.LastFlush = time.Now()

	// åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒº
	for _, buffer := range bp.buffers {
		buffer.Flush()
	}
}

// åˆ·æ–°ç¼“å†²åŒº
func (bp *BatchIOProcessor) flushBuffers() {
	bp.mutex.Lock()
	defer bp.mutex.Unlock()

	for _, buffer := range bp.buffers {
		if buffer.size > 0 {
			buffer.Flush()
		}
	}
}

// å¯åŠ¨å®šæœŸåˆ·æ–°
func (io *IOOptimizer) startPeriodicFlush() {
	ticker := time.NewTicker(io.config.FlushInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			io.FlushAll()
		case <-io.stopChan:
			return
		}
	}
}

// å¼‚æ­¥è¯»æ“ä½œ
func (io *IOOptimizer) AsyncRead(id string, data []byte, callback func([]byte, error)) {
	if !io.config.Enabled || !io.config.AsyncIO {
		// åŒæ­¥è¯»æ“ä½œ
		if callback != nil {
			callback(data, nil)
		}
		return
	}

	op := AsyncIOOperation{
		ID:        id,
		Type:      "read",
		Data:      data,
		Callback:  callback,
		Timestamp: time.Now(),
	}

	select {
	case io.processor.operations <- op:
		// æ“ä½œå·²æäº¤
	default:
		// é˜Ÿåˆ—å·²æ»¡ï¼Œç›´æ¥æ‰§è¡ŒåŒæ­¥æ“ä½œ
		if callback != nil {
			callback(data, nil)
		}
	}
}

// å¼‚æ­¥å†™æ“ä½œ
func (io *IOOptimizer) AsyncWrite(id string, data []byte, callback func([]byte, error)) {
	if !io.config.Enabled || !io.config.AsyncIO {
		// åŒæ­¥å†™æ“ä½œ
		if callback != nil {
			callback(nil, nil)
		}
		return
	}

	op := AsyncIOOperation{
		ID:        id,
		Type:      "write",
		Data:      data,
		Callback:  callback,
		Timestamp: time.Now(),
	}

	select {
	case io.processor.operations <- op:
		// æ“ä½œå·²æäº¤
	default:
		// é˜Ÿåˆ—å·²æ»¡ï¼Œç›´æ¥æ‰§è¡ŒåŒæ­¥æ“ä½œ
		if callback != nil {
			callback(nil, nil)
		}
	}
}

// åˆ·æ–°æ‰€æœ‰ç¼“å†²åŒº
func (io *IOOptimizer) FlushAll() {
	io.mutex.Lock()
	defer io.mutex.Unlock()

	io.processor.flushBuffers()
	io.stats.FlushOperations++
	io.stats.LastFlush = time.Now()
}

// è·å–I/Oç»Ÿè®¡ä¿¡æ¯
func (io *IOOptimizer) GetStats() IOStats {
	io.mutex.RLock()
	defer io.mutex.RUnlock()

	// æ›´æ–°ååé‡
	if io.stats.ReadOperations > 0 || io.stats.WriteOperations > 0 {
		totalBytes := io.stats.BytesRead + io.stats.BytesWritten
		totalTime := io.stats.ReadLatency + io.stats.WriteLatency
		if totalTime > 0 {
			io.stats.Throughput = float64(totalBytes) / totalTime.Seconds()
		}
	}

	return io.stats
}

// åˆ›å»ºI/Oç¼“å†²åŒº
func NewIOBuffer(capacity int) *IOBuffer {
	return &IOBuffer{
		buffer:    make([]byte, capacity),
		capacity:  capacity,
		flushChan: make(chan bool, 1),
		stopChan:  make(chan bool),
	}
}

// å†™å…¥ç¼“å†²åŒº
func (buf *IOBuffer) Write(data []byte) (int, error) {
	buf.mutex.Lock()
	defer buf.mutex.Unlock()

	if buf.position+len(data) > buf.capacity {
		// ç¼“å†²åŒºå·²æ»¡ï¼Œéœ€è¦åˆ·æ–°
		buf.Flush()
	}

	n := copy(buf.buffer[buf.position:], data)
	buf.position += n
	buf.size += n

	return n, nil
}

// åˆ·æ–°ç¼“å†²åŒº
func (buf *IOBuffer) Flush() {
	buf.mutex.Lock()
	defer buf.mutex.Unlock()

	if buf.size > 0 {
		// è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„åˆ·æ–°æ“ä½œ
		buf.position = 0
		buf.size = 0
	}
}

// åˆ›å»ºæ–‡ä»¶ç›‘æ§å™¨
func NewFileMonitor(filePath string) *FileMonitor {
	return &FileMonitor{
		filePath:  filePath,
		callbacks: make([]func(string, []byte), 0),
		stopChan:  make(chan bool),
	}
}

// æ·»åŠ æ–‡ä»¶å˜åŒ–å›è°ƒ
func (fm *FileMonitor) AddCallback(callback func(string, []byte)) {
	fm.mutex.Lock()
	defer fm.mutex.Unlock()

	fm.callbacks = append(fm.callbacks, callback)
}

// å¯åŠ¨æ–‡ä»¶ç›‘æ§
func (fm *FileMonitor) Start() error {
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		return err
	}

	fm.watcher = watcher

	// æ·»åŠ æ–‡ä»¶ç›‘æ§
	if err := watcher.Add(fm.filePath); err != nil {
		return err
	}

	// å¯åŠ¨ç›‘æ§åç¨‹
	go fm.monitor()

	return nil
}

// ç›‘æ§æ–‡ä»¶å˜åŒ–
func (fm *FileMonitor) monitor() {
	for {
		select {
		case event := <-fm.watcher.Events:
			if event.Op&fsnotify.Write == fsnotify.Write {
				fm.handleFileChange()
			}
		case err := <-fm.watcher.Errors:
			if err != nil {
				fmt.Printf("æ–‡ä»¶ç›‘æ§é”™è¯¯: %v\n", err)
			}
		case <-fm.stopChan:
			return
		}
	}
}

// å¤„ç†æ–‡ä»¶å˜åŒ–
func (fm *FileMonitor) handleFileChange() {
	// è¯»å–æ–‡ä»¶å†…å®¹
	data, err := os.ReadFile(fm.filePath)
	if err != nil {
		return
	}

	// è°ƒç”¨æ‰€æœ‰å›è°ƒ
	fm.mutex.RLock()
	callbacks := make([]func(string, []byte), len(fm.callbacks))
	copy(callbacks, fm.callbacks)
	fm.mutex.RUnlock()

	for _, callback := range callbacks {
		callback(fm.filePath, data)
	}
}

// åœæ­¢æ–‡ä»¶ç›‘æ§
func (fm *FileMonitor) Stop() {
	close(fm.stopChan)
	if fm.watcher != nil {
		fm.watcher.Close()
	}
}

// I/Oç®¡ç†å‘½ä»¤å¤„ç†å‡½æ•°

// æ˜¾ç¤ºI/Oç»Ÿè®¡ä¿¡æ¯
func handleIOStats() {
	fmt.Println("ğŸ’¾ I/Oç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := ioOptimizer.GetStats()
	fmt.Printf("è¯»æ“ä½œæ¬¡æ•°: %d\n", stats.ReadOperations)
	fmt.Printf("å†™æ“ä½œæ¬¡æ•°: %d\n", stats.WriteOperations)
	fmt.Printf("è¯»å–å­—èŠ‚æ•°: %d\n", stats.BytesRead)
	fmt.Printf("å†™å…¥å­—èŠ‚æ•°: %d\n", stats.BytesWritten)
	fmt.Printf("è¯»å»¶è¿Ÿ: %v\n", stats.ReadLatency)
	fmt.Printf("å†™å»¶è¿Ÿ: %v\n", stats.WriteLatency)
	fmt.Printf("ç¼“å†²åŒºå‘½ä¸­: %d\n", stats.BufferHits)
	fmt.Printf("ç¼“å†²åŒºæœªå‘½ä¸­: %d\n", stats.BufferMisses)
	fmt.Printf("åˆ·æ–°æ“ä½œæ¬¡æ•°: %d\n", stats.FlushOperations)
	fmt.Printf("é”™è¯¯æ¬¡æ•°: %d\n", stats.ErrorCount)
	fmt.Printf("ä¸Šæ¬¡åˆ·æ–°: %v\n", stats.LastFlush.Format("2006-01-02 15:04:05"))
	fmt.Printf("ååé‡: %.2f å­—èŠ‚/ç§’\n", stats.Throughput)

	// æ˜¾ç¤ºé…ç½®ä¿¡æ¯
	fmt.Println("\nI/Oé…ç½®:")
	fmt.Printf("  ç¼“å†²åŒºå¤§å°: %d å­—èŠ‚\n", globalConfig.IO.BufferSize)
	fmt.Printf("  æ‰¹å¤„ç†å¤§å°: %d\n", globalConfig.IO.BatchSize)
	fmt.Printf("  åˆ·æ–°é—´éš”: %v\n", globalConfig.IO.FlushInterval)
	fmt.Printf("  å¼‚æ­¥I/O: %t\n", globalConfig.IO.AsyncIO)
	fmt.Printf("  é¢„è¯»å¤§å°: %d å­—èŠ‚\n", globalConfig.IO.ReadAhead)
	fmt.Printf("  å†™åç½®: %t\n", globalConfig.IO.WriteBehind)
	fmt.Printf("  å‹ç¼©: %t\n", globalConfig.IO.Compression)
	fmt.Printf("  å‹ç¼©çº§åˆ«: %d\n", globalConfig.IO.CompressionLevel)
	fmt.Printf("  ç¼“å­˜å¤§å°: %d å­—èŠ‚\n", globalConfig.IO.CacheSize)
	fmt.Printf("  å¯ç”¨çŠ¶æ€: %t\n", globalConfig.IO.Enabled)
}

// æµ‹è¯•I/Oä¼˜åŒ–åŠŸèƒ½
func handleIOTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•I/Oä¼˜åŒ–åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æµ‹è¯•I/Oç¼“å†²åŒº
	fmt.Println("1. æµ‹è¯•I/Oç¼“å†²åŒº...")
	buffer := NewIOBuffer(1024)

	testData := []byte("Hello, World!")
	n, err := buffer.Write(testData)
	if err != nil {
		fmt.Printf("   âŒ ç¼“å†²åŒºå†™å…¥å¤±è´¥: %v\n", err)
	} else {
		fmt.Printf("   âœ… ç¼“å†²åŒºå†™å…¥æˆåŠŸï¼Œå†™å…¥ %d å­—èŠ‚\n", n)
	}

	// æµ‹è¯•å¼‚æ­¥I/Oæ“ä½œ
	fmt.Println("2. æµ‹è¯•å¼‚æ­¥I/Oæ“ä½œ...")

	// å¼‚æ­¥è¯»æ“ä½œ
	ioOptimizer.AsyncRead("test_read", testData, func(data []byte, err error) {
		if err != nil {
			fmt.Printf("   âŒ å¼‚æ­¥è¯»æ“ä½œå¤±è´¥: %v\n", err)
		} else {
			fmt.Printf("   âœ… å¼‚æ­¥è¯»æ“ä½œæˆåŠŸï¼Œè¯»å– %d å­—èŠ‚\n", len(data))
		}
	})

	// å¼‚æ­¥å†™æ“ä½œ
	ioOptimizer.AsyncWrite("test_write", testData, func(data []byte, err error) {
		if err != nil {
			fmt.Printf("   âŒ å¼‚æ­¥å†™æ“ä½œå¤±è´¥: %v\n", err)
		} else {
			fmt.Println("   âœ… å¼‚æ­¥å†™æ“ä½œæˆåŠŸ")
		}
	})

	// ç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆ
	time.Sleep(100 * time.Millisecond)

	// æµ‹è¯•æ–‡ä»¶ç›‘æ§å™¨
	fmt.Println("3. æµ‹è¯•æ–‡ä»¶ç›‘æ§å™¨...")
	monitor := NewFileMonitor("/tmp/test.log")

	// æ·»åŠ å›è°ƒ
	monitor.AddCallback(func(filePath string, data []byte) {
		fmt.Printf("   ğŸ“ æ–‡ä»¶å˜åŒ–: %sï¼Œå¤§å°: %d å­—èŠ‚\n", filePath, len(data))
	})

	// å¯åŠ¨ç›‘æ§
	if err := monitor.Start(); err != nil {
		fmt.Printf("   âŒ æ–‡ä»¶ç›‘æ§å¯åŠ¨å¤±è´¥: %v\n", err)
	} else {
		fmt.Println("   âœ… æ–‡ä»¶ç›‘æ§å¯åŠ¨æˆåŠŸ")
		// åœæ­¢ç›‘æ§
		monitor.Stop()
		fmt.Println("   âœ… æ–‡ä»¶ç›‘æ§åœæ­¢æˆåŠŸ")
	}

	// æµ‹è¯•æ‰¹é‡åˆ·æ–°
	fmt.Println("4. æµ‹è¯•æ‰¹é‡åˆ·æ–°...")
	ioOptimizer.FlushAll()
	fmt.Println("   âœ… æ‰¹é‡åˆ·æ–°å®Œæˆ")

	// æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
	fmt.Println("\næœ€ç»ˆI/Oç»Ÿè®¡:")
	stats := ioOptimizer.GetStats()
	fmt.Printf("  è¯»æ“ä½œæ¬¡æ•°: %d\n", stats.ReadOperations)
	fmt.Printf("  å†™æ“ä½œæ¬¡æ•°: %d\n", stats.WriteOperations)
	fmt.Printf("  ååé‡: %.2f å­—èŠ‚/ç§’\n", stats.Throughput)

	fmt.Println("\nâœ… I/Oä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}

// å¼ºåˆ¶åˆ·æ–°I/Oç¼“å†²åŒº
func handleIOFlush() {
	fmt.Println("ğŸ”„ å¼ºåˆ¶åˆ·æ–°I/Oç¼“å†²åŒº...")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// è·å–åˆ·æ–°å‰ç»Ÿè®¡
	statsBefore := ioOptimizer.GetStats()
	fmt.Printf("åˆ·æ–°å‰ç»Ÿè®¡: è¯»æ“ä½œ %dï¼Œå†™æ“ä½œ %d\n",
		statsBefore.ReadOperations, statsBefore.WriteOperations)

	// å¼ºåˆ¶åˆ·æ–°
	start := time.Now()
	ioOptimizer.FlushAll()
	elapsed := time.Since(start)

	// è·å–åˆ·æ–°åç»Ÿè®¡
	statsAfter := ioOptimizer.GetStats()
	fmt.Printf("åˆ·æ–°åç»Ÿè®¡: è¯»æ“ä½œ %dï¼Œå†™æ“ä½œ %d\n",
		statsAfter.ReadOperations, statsAfter.WriteOperations)
	fmt.Printf("åˆ·æ–°æ—¶é—´: %v\n", elapsed)
	fmt.Printf("åˆ·æ–°æ“ä½œæ¬¡æ•°: %d\n", statsAfter.FlushOperations)

	fmt.Println("âœ… I/Oç¼“å†²åŒºåˆ·æ–°å®Œæˆ")
}

// ç”¨æˆ·ä½“éªŒç›¸å…³ç»“æ„

// è¾“å‡ºæ ¼å¼é…ç½®
type OutputFormat struct {
	Type     string `json:"type"`     // json, csv, table, custom
	Template string `json:"template"` // è‡ªå®šä¹‰æ¨¡æ¿
	Color    bool   `json:"color"`    // é¢œè‰²æ”¯æŒ
	Filter   string `json:"filter"`   // è¾“å‡ºè¿‡æ»¤
	Width    int    `json:"width"`    // è¡¨æ ¼å®½åº¦
	Headers  bool   `json:"headers"`  // æ˜¾ç¤ºè¡¨å¤´
}

// æ—¥å¿—çº§åˆ«é…ç½®
type LogLevelConfig struct {
	Level     string `json:"level"`      // debug, info, warn, error, fatal
	ShowDebug bool   `json:"show_debug"` // æ˜¾ç¤ºè°ƒè¯•æ—¥å¿—
	ShowInfo  bool   `json:"show_info"`  // æ˜¾ç¤ºä¿¡æ¯æ—¥å¿—
	ShowWarn  bool   `json:"show_warn"`  // æ˜¾ç¤ºè­¦å‘Šæ—¥å¿—
	ShowError bool   `json:"show_error"` // æ˜¾ç¤ºé”™è¯¯æ—¥å¿—
	ShowFatal bool   `json:"show_fatal"` // æ˜¾ç¤ºè‡´å‘½æ—¥å¿—
	MinLevel  string `json:"min_level"`  // æœ€å°æ—¥å¿—çº§åˆ«
	MaxLevel  string `json:"max_level"`  // æœ€å¤§æ—¥å¿—çº§åˆ«
	Enabled   bool   `json:"enabled"`    // æ˜¯å¦å¯ç”¨æ—¥å¿—çº§åˆ«è¿‡æ»¤
}

// é…ç½®å‘å¯¼
type ConfigWizard struct {
	steps       []WizardStep
	currentStep int
	config      Config
	responses   map[string]interface{}
	mutex       sync.RWMutex
}

// å‘å¯¼æ­¥éª¤
type WizardStep struct {
	ID          string                  `json:"id"`
	Title       string                  `json:"title"`
	Description string                  `json:"description"`
	Type        string                  `json:"type"` // input, select, confirm, file
	Options     []WizardOption          `json:"options"`
	Required    bool                    `json:"required"`
	Default     interface{}             `json:"default"`
	Validation  func(interface{}) error `json:"-"`
}

// å‘å¯¼é€‰é¡¹
type WizardOption struct {
	Value       string `json:"value"`
	Label       string `json:"label"`
	Description string `json:"description"`
}

// é…ç½®æ¨¡æ¿
type ConfigTemplate struct {
	Name        string `json:"name"`
	Description string `json:"description"`
	Config      Config `json:"config"`
	Category    string `json:"category"`
}

// è¾“å‡ºæ ¼å¼åŒ–å™¨
type OutputFormatter struct {
	format   OutputFormat
	template *template.Template
	mutex    sync.RWMutex
}

// é¢œè‰²æ”¯æŒ
type ColorSupport struct {
	Enabled bool
	Colors  map[string]string
}

// äº¤äº’å¼æç¤º
type InteractivePrompt struct {
	message   string
	options   []string
	validator func(string) error
}

// é…ç½®å‘å¯¼å®ç°

// åˆ›å»ºæ–°çš„é…ç½®å‘å¯¼
func NewConfigWizard() *ConfigWizard {
	wizard := &ConfigWizard{
		steps:       make([]WizardStep, 0),
		currentStep: 0,
		config:      defaultConfig,
		responses:   make(map[string]interface{}),
	}
	
	// åˆå§‹åŒ–å‘å¯¼æ­¥éª¤
	wizard.initSteps()
	
	return wizard
}

// åˆå§‹åŒ–å‘å¯¼æ­¥éª¤
func (w *ConfigWizard) initSteps() {
	w.steps = []WizardStep{
		{
			ID:          "ai_endpoint",
			Title:       "AIæœåŠ¡ç«¯ç‚¹é…ç½®",
			Description: "è¯·è¾“å…¥AIæœåŠ¡çš„APIç«¯ç‚¹URL",
			Type:        "input",
			Required:    true,
			Default:     "https://your-ai-server.com/api/v1/chat/completions",
			Validation:  validateURL,
		},
		{
			ID:          "ai_token",
			Title:       "API Tokené…ç½®",
			Description: "è¯·è¾“å…¥AIæœåŠ¡çš„API Token",
			Type:        "input",
			Required:    true,
			Default:     "your-api-token-here",
			Validation:  validateToken,
		},
		{
			ID:          "ai_model",
			Title:       "AIæ¨¡å‹é€‰æ‹©",
			Description: "è¯·é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹",
			Type:        "select",
			Required:    true,
			Default:     "gpt-4",
			Options: []WizardOption{
				{Value: "gpt-4", Label: "GPT-4", Description: "OpenAI GPT-4æ¨¡å‹"},
				{Value: "gpt-3.5-turbo", Label: "GPT-3.5 Turbo", Description: "OpenAI GPT-3.5 Turboæ¨¡å‹"},
				{Value: "claude-3", Label: "Claude 3", Description: "Anthropic Claude 3æ¨¡å‹"},
				{Value: "gemini-pro", Label: "Gemini Pro", Description: "Google Gemini Proæ¨¡å‹"},
			},
		},
		{
			ID:          "output_format",
			Title:       "è¾“å‡ºæ ¼å¼é€‰æ‹©",
			Description: "è¯·é€‰æ‹©æ—¥å¿—è¾“å‡ºæ ¼å¼",
			Type:        "select",
			Required:    true,
			Default:     "table",
			Options: []WizardOption{
				{Value: "table", Label: "è¡¨æ ¼æ ¼å¼", Description: "æ˜“è¯»çš„è¡¨æ ¼æ ¼å¼"},
				{Value: "json", Label: "JSONæ ¼å¼", Description: "æœºå™¨å¯è¯»çš„JSONæ ¼å¼"},
				{Value: "csv", Label: "CSVæ ¼å¼", Description: "é€—å·åˆ†éš”å€¼æ ¼å¼"},
				{Value: "custom", Label: "è‡ªå®šä¹‰æ ¼å¼", Description: "ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿"},
			},
		},
		{
			ID:          "log_level",
			Title:       "æ—¥å¿—çº§åˆ«é…ç½®",
			Description: "è¯·é€‰æ‹©è¦ç›‘æ§çš„æ—¥å¿—çº§åˆ«",
			Type:        "select",
			Required:    true,
			Default:     "info",
			Options: []WizardOption{
				{Value: "debug", Label: "DEBUG", Description: "æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—çº§åˆ«"},
				{Value: "info", Label: "INFO", Description: "æ˜¾ç¤ºä¿¡æ¯çº§åˆ«åŠä»¥ä¸Š"},
				{Value: "warn", Label: "WARN", Description: "æ˜¾ç¤ºè­¦å‘Šçº§åˆ«åŠä»¥ä¸Š"},
				{Value: "error", Label: "ERROR", Description: "åªæ˜¾ç¤ºé”™è¯¯çº§åˆ«"},
				{Value: "fatal", Label: "FATAL", Description: "åªæ˜¾ç¤ºè‡´å‘½é”™è¯¯"},
			},
		},
		{
			ID:          "enable_features",
			Title:       "åŠŸèƒ½å¯ç”¨é…ç½®",
			Description: "è¯·é€‰æ‹©è¦å¯ç”¨çš„åŠŸèƒ½",
			Type:        "select",
			Required:    false,
			Default:     "basic",
			Options: []WizardOption{
				{Value: "basic", Label: "åŸºç¡€åŠŸèƒ½", Description: "åªå¯ç”¨åŸºæœ¬æ—¥å¿—åˆ†æåŠŸèƒ½"},
				{Value: "advanced", Label: "é«˜çº§åŠŸèƒ½", Description: "å¯ç”¨æ‰€æœ‰é«˜çº§åŠŸèƒ½"},
				{Value: "enterprise", Label: "ä¼ä¸šåŠŸèƒ½", Description: "å¯ç”¨ä¼ä¸šçº§åŠŸèƒ½"},
			},
		},
		{
			ID:          "confirm_config",
			Title:       "é…ç½®ç¡®è®¤",
			Description: "è¯·ç¡®è®¤é…ç½®æ˜¯å¦æ­£ç¡®",
			Type:        "confirm",
			Required:    true,
			Default:     true,
		},
	}
}

// éªŒè¯URLå‡½æ•°
func validateURL(value interface{}) error {
	url, ok := value.(string)
	if !ok {
		return fmt.Errorf("URLå¿…é¡»æ˜¯å­—ç¬¦ä¸²")
	}
	
	if url == "" {
		return fmt.Errorf("URLä¸èƒ½ä¸ºç©º")
	}
	
	if !strings.HasPrefix(url, "http://") && !strings.HasPrefix(url, "https://") {
		return fmt.Errorf("URLå¿…é¡»ä»¥http://æˆ–https://å¼€å¤´")
	}
	
	return nil
}

// éªŒè¯Tokenå‡½æ•°
func validateToken(value interface{}) error {
	token, ok := value.(string)
	if !ok {
		return fmt.Errorf("Tokenå¿…é¡»æ˜¯å­—ç¬¦ä¸²")
	}
	
	if token == "" {
		return fmt.Errorf("Tokenä¸èƒ½ä¸ºç©º")
	}
	
	if len(token) < 10 {
		return fmt.Errorf("Tokené•¿åº¦è‡³å°‘10ä¸ªå­—ç¬¦")
	}
	
	return nil
}

// å¤„ç†é…ç½®å‘å¯¼
func handleConfigInit() {
	fmt.Println("ğŸ¯ å¯åŠ¨é…ç½®å‘å¯¼...")
	wizard := NewConfigWizard()
	if err := wizard.Start(); err != nil {
		fmt.Printf("âŒ é…ç½®å‘å¯¼å¤±è´¥: %v\n", err)
		os.Exit(1)
	}
}

// å¤„ç†é…ç½®æ¨¡æ¿
func handleConfigTemplate() {
	fmt.Println("ğŸ“‹ é…ç½®æ¨¡æ¿:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	
	// æ˜¾ç¤ºç¤ºä¾‹é…ç½®
	template := Config{
		AIEndpoint:   "https://your-ai-server.com/api/v1/chat/completions",
		Token:        "your-api-token-here",
		Model:        "gpt-4",
		CustomPrompt: "ä½ çš„è‡ªå®šä¹‰æç¤ºè¯",
		MaxRetries:   3,
		Timeout:      30,
		RateLimit:    100,
		LocalFilter:  true,
		OutputFormat: OutputFormat{
			Type:     "table",
			Color:    true,
			Width:    120,
			Headers:  true,
		},
		LogLevel: LogLevelConfig{
			Level:     "info",
			ShowInfo:  true,
			ShowWarn:  true,
			ShowError: true,
			ShowFatal: true,
			MinLevel:  "info",
			MaxLevel:  "fatal",
			Enabled:   true,
		},
	}
	
	data, err := json.MarshalIndent(template, "", "  ")
	if err != nil {
		fmt.Printf("âŒ ç”Ÿæˆæ¨¡æ¿å¤±è´¥: %v\n", err)
		os.Exit(1)
	}
	
	fmt.Println(string(data))
	fmt.Println("\nğŸ’¡ æç¤º:")
	fmt.Println("1. å°†ä¸Šè¿°é…ç½®ä¿å­˜åˆ° ~/.config/aipipe.json")
	fmt.Println("2. ä¿®æ”¹ AIEndpointã€Token å’Œ Model ä¸ºä½ çš„å®é™…å€¼")
	fmt.Println("3. ä½¿ç”¨ --config-init å¯åŠ¨äº¤äº’å¼é…ç½®å‘å¯¼")
}
