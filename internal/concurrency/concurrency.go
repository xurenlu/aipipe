package concurrency

import (
	"fmt"
	"os"
	"sync"
	"time"
)

// å¹¶å‘ç»Ÿè®¡
type ConcurrencyStats struct {
	TotalJobs        int64         `json:"total_jobs"`
	ProcessedJobs    int64         `json:"processed_jobs"`
	ActiveWorkers    int           `json:"active_workers"`
	BlockedJobs      int64         `json:"blocked_jobs"`
	RejectedJobs     int64         `json:"rejected_jobs"`
	AverageLatency   time.Duration `json:"average_latency"`
	Throughput       float64       `json:"throughput"`
	ErrorRate        float64       `json:"error_rate"`
	BackpressureRate float64       `json:"backpressure_rate"`
	LastUpdated      time.Time     `json:"last_updated"`
}

// å¹¶å‘æ§åˆ¶å™¨
type ConcurrencyController struct {
	config         ConcurrencyConfig
	backpressure   *BackpressureController
	loadBalancer   *LoadBalancer
	adaptiveScaler *AdaptiveScaler
	stats          ConcurrencyStats
	mutex          sync.RWMutex
	stopChan       chan bool
}

// å¹¶å‘æ§åˆ¶å™¨æ–¹æ³•

// åˆ›å»ºæ–°çš„å¹¶å‘æ§åˆ¶å™¨
func NewConcurrencyController(config ConcurrencyConfig) *ConcurrencyController {
	cc := &ConcurrencyController{
		config:   config,
		stopChan: make(chan bool),
	}

	// åˆ›å»ºèƒŒå‹æ§åˆ¶å™¨
	cc.backpressure = &BackpressureController{
		threshold: config.BackpressureThreshold,
		callbacks: make([]func(int64), 0),
	}

	// åˆ›å»ºè´Ÿè½½å‡è¡¡å™¨
	cc.loadBalancer = &LoadBalancer{
		strategy:    config.LoadBalanceStrategy,
		workers:     make([]*Worker, 0),
		workerStats: make(map[int]*WorkerStats),
	}

	// åˆ›å»ºè‡ªé€‚åº”æ‰©ç¼©å®¹å™¨
	cc.adaptiveScaler = &AdaptiveScaler{
		config:      config,
		workerStats: make(map[int]*WorkerStats),
	}

	// å¯åŠ¨è‡ªé€‚åº”æ‰©ç¼©å®¹
	if config.Enabled && config.AdaptiveScaling {
		go cc.startAdaptiveScaling()
	}

	return cc
}

// å¯åŠ¨è‡ªé€‚åº”æ‰©ç¼©å®¹
func (cc *ConcurrencyController) startAdaptiveScaling() {
	ticker := time.NewTicker(cc.config.ScalingInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			cc.checkAndScale()
		case <-cc.stopChan:
			return
		}
	}
}

// æ£€æŸ¥å¹¶æ‰§è¡Œæ‰©ç¼©å®¹
func (cc *ConcurrencyController) checkAndScale() {
	cc.mutex.Lock()
	defer cc.mutex.Unlock()

	// è®¡ç®—å½“å‰è´Ÿè½½
	currentLoad := cc.calculateCurrentLoad()

	// æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰©å®¹
	if currentLoad > cc.config.ScaleUpThreshold && cc.adaptiveScaler.currentWorkers < cc.config.MaxWorkers {
		cc.scaleUp()
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦ç¼©å®¹
	if currentLoad < cc.config.ScaleDownThreshold && cc.adaptiveScaler.currentWorkers > cc.config.MinWorkers {
		cc.scaleDown()
	}
}

// è®¡ç®—å½“å‰è´Ÿè½½
func (cc *ConcurrencyController) calculateCurrentLoad() float64 {
	if cc.adaptiveScaler.currentWorkers == 0 {
		return 0
	}

	totalLoad := int64(0)
	for _, stats := range cc.adaptiveScaler.workerStats {
		totalLoad += stats.CurrentLoad
	}

	return float64(totalLoad) / float64(cc.adaptiveScaler.currentWorkers)
}

// æ‰©å®¹
func (cc *ConcurrencyController) scaleUp() {
	if cc.adaptiveScaler.currentWorkers >= cc.config.MaxWorkers {
		return
	}

	// åˆ›å»ºæ–°çš„å·¥ä½œåç¨‹
	newWorker := NewWorker(cc.adaptiveScaler.currentWorkers, workerPool)
	cc.loadBalancer.workers = append(cc.loadBalancer.workers, newWorker)
	cc.adaptiveScaler.currentWorkers++

	// å¯åŠ¨å·¥ä½œåç¨‹
	newWorker.Start()

	// æ›´æ–°ç»Ÿè®¡
	cc.adaptiveScaler.workerStats[newWorker.ID] = &WorkerStats{
		ID:           newWorker.ID,
		LastActivity: time.Now(),
		IsHealthy:    true,
	}

	cc.adaptiveScaler.lastScaleTime = time.Now()
}

// ç¼©å®¹
func (cc *ConcurrencyController) scaleDown() {
	if cc.adaptiveScaler.currentWorkers <= cc.config.MinWorkers {
		return
	}

	// æ‰¾åˆ°è´Ÿè½½æœ€ä½çš„å·¥ä½œåç¨‹
	var targetWorker *Worker
	minLoad := int64(^uint64(0) >> 1)

	for _, worker := range cc.loadBalancer.workers {
		if stats, exists := cc.adaptiveScaler.workerStats[worker.ID]; exists {
			if stats.CurrentLoad < minLoad {
				minLoad = stats.CurrentLoad
				targetWorker = worker
			}
		}
	}

	if targetWorker != nil {
		// åœæ­¢å·¥ä½œåç¨‹
		targetWorker.Stop()

		// ä»è´Ÿè½½å‡è¡¡å™¨ä¸­ç§»é™¤
		for i, worker := range cc.loadBalancer.workers {
			if worker.ID == targetWorker.ID {
				cc.loadBalancer.workers = append(cc.loadBalancer.workers[:i], cc.loadBalancer.workers[i+1:]...)
				break
			}
		}

		// æ›´æ–°ç»Ÿè®¡
		delete(cc.adaptiveScaler.workerStats, targetWorker.ID)
		cc.adaptiveScaler.currentWorkers--
		cc.adaptiveScaler.lastScaleTime = time.Now()
	}
}

// å¹¶å‘æ§åˆ¶å‘½ä»¤å¤„ç†å‡½æ•°

// æ˜¾ç¤ºå¹¶å‘æ§åˆ¶ç»Ÿè®¡ä¿¡æ¯
func handleConcurrencyStats() {
	fmt.Println("âš¡ å¹¶å‘æ§åˆ¶ç»Ÿè®¡ä¿¡æ¯:")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	stats := concurrencyController.stats
	fmt.Printf("æ€»ä»»åŠ¡æ•°: %d\n", stats.TotalJobs)
	fmt.Printf("å·²å¤„ç†ä»»åŠ¡æ•°: %d\n", stats.ProcessedJobs)
	fmt.Printf("æ´»è·ƒå·¥ä½œåç¨‹æ•°: %d\n", stats.ActiveWorkers)
	fmt.Printf("é˜»å¡ä»»åŠ¡æ•°: %d\n", stats.BlockedJobs)
	fmt.Printf("æ‹’ç»ä»»åŠ¡æ•°: %d\n", stats.RejectedJobs)
	fmt.Printf("å¹³å‡å»¶è¿Ÿ: %v\n", stats.AverageLatency)
	fmt.Printf("ååé‡: %.2f ä»»åŠ¡/ç§’\n", stats.Throughput)
	fmt.Printf("é”™è¯¯ç‡: %.2f%%\n", stats.ErrorRate)
	fmt.Printf("èƒŒå‹ç‡: %.2f%%\n", stats.BackpressureRate)

	// æ˜¾ç¤ºé…ç½®ä¿¡æ¯
	fmt.Println("\nå¹¶å‘æ§åˆ¶é…ç½®:")
	fmt.Printf("  æœ€å¤§å¹¶å‘æ•°: %d\n", globalConfig.Concurrency.MaxConcurrency)
	fmt.Printf("  èƒŒå‹é˜ˆå€¼: %d\n", globalConfig.Concurrency.BackpressureThreshold)
	fmt.Printf("  è´Ÿè½½å‡è¡¡ç­–ç•¥: %s\n", globalConfig.Concurrency.LoadBalanceStrategy)
	fmt.Printf("  è‡ªé€‚åº”æ‰©ç¼©å®¹: %t\n", globalConfig.Concurrency.AdaptiveScaling)
	fmt.Printf("  æ‰©å®¹é˜ˆå€¼: %.2f\n", globalConfig.Concurrency.ScaleUpThreshold)
	fmt.Printf("  ç¼©å®¹é˜ˆå€¼: %.2f\n", globalConfig.Concurrency.ScaleDownThreshold)
	fmt.Printf("  æœ€å°å·¥ä½œåç¨‹æ•°: %d\n", globalConfig.Concurrency.MinWorkers)
	fmt.Printf("  æœ€å¤§å·¥ä½œåç¨‹æ•°: %d\n", globalConfig.Concurrency.MaxWorkers)
	fmt.Printf("  æ‰©ç¼©å®¹æ£€æŸ¥é—´éš”: %v\n", globalConfig.Concurrency.ScalingInterval)
	fmt.Printf("  å¯ç”¨çŠ¶æ€: %t\n", globalConfig.Concurrency.Enabled)
}

// æµ‹è¯•å¹¶å‘æ§åˆ¶åŠŸèƒ½
func handleConcurrencyTest() {
	fmt.Println("ğŸ§ª æµ‹è¯•å¹¶å‘æ§åˆ¶åŠŸèƒ½...")
	fmt.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// åŠ è½½é…ç½®
	if err := loadConfig(); err != nil {
		fmt.Printf("âŒ é…ç½®åŠ è½½å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æµ‹è¯•è´Ÿè½½å‡è¡¡å™¨
	fmt.Println("1. æµ‹è¯•è´Ÿè½½å‡è¡¡å™¨...")
	loadBalancer := NewLoadBalancer("round_robin")

	// åˆ›å»ºæµ‹è¯•å·¥ä½œåç¨‹
	testWorkers := make([]*Worker, 3)
	for i := 0; i < 3; i++ {
		worker := NewWorker(i, workerPool)
		testWorkers[i] = worker
		loadBalancer.workers = append(loadBalancer.workers, worker)
	}

	// æµ‹è¯•è½®è¯¢é€‰æ‹©
	for i := 0; i < 6; i++ {
		worker := loadBalancer.SelectWorker()
		if worker != nil {
			fmt.Printf("   âœ… è½®è¯¢é€‰æ‹©å·¥ä½œåç¨‹ %d\n", worker.ID)
		} else {
			fmt.Println("   âŒ è½®è¯¢é€‰æ‹©å¤±è´¥")
		}
	}

	// æµ‹è¯•ä¼˜å…ˆçº§é˜Ÿåˆ—
	fmt.Println("2. æµ‹è¯•ä¼˜å…ˆçº§é˜Ÿåˆ—...")
	priorityQueue := NewPriorityQueue()

	// æ·»åŠ ä¸åŒä¼˜å…ˆçº§çš„ä»»åŠ¡
	jobs := []ProcessingJob{
		{ID: "job1", Lines: []string{"test1"}, Priority: 1},
		{ID: "job2", Lines: []string{"test2"}, Priority: 3},
		{ID: "job3", Lines: []string{"test3"}, Priority: 2},
	}

	for i, job := range jobs {
		priority := TaskPriority(i + 1)
		priorityQueue.AddJob(job, priority)
		fmt.Printf("   âœ… æ·»åŠ ä»»åŠ¡ %s (ä¼˜å…ˆçº§ %d)\n", job.ID, priority)
	}

	// æŒ‰ä¼˜å…ˆçº§è·å–ä»»åŠ¡
	for i := 0; i < 3; i++ {
		job := priorityQueue.GetNextJob()
		if job != nil {
			fmt.Printf("   âœ… è·å–ä»»åŠ¡ %s\n", job.ID)
		} else {
			fmt.Println("   âŒ è·å–ä»»åŠ¡å¤±è´¥")
		}
	}

	// æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨
	fmt.Println("3. æµ‹è¯•ä»»åŠ¡è°ƒåº¦å™¨...")
	scheduler := NewTaskScheduler(testWorkers, loadBalancer)

	// æäº¤ä»»åŠ¡
	testJob := ProcessingJob{
		ID:     "test_job",
		Lines:  []string{"test line"},
		Format: "java",
	}

	if err := scheduler.SubmitTask(testJob, PriorityHigh); err != nil {
		fmt.Printf("   âŒ ä»»åŠ¡æäº¤å¤±è´¥: %v\n", err)
	} else {
		fmt.Println("   âœ… ä»»åŠ¡æäº¤æˆåŠŸ")
	}

	// æ˜¾ç¤ºç»Ÿè®¡
	stats := scheduler.GetStats()
	fmt.Printf("  æ€»ä»»åŠ¡æ•°: %d\n", stats.TotalJobs)

	fmt.Println("\nâœ… å¹¶å‘æ§åˆ¶åŠŸèƒ½æµ‹è¯•å®Œæˆ")
}
